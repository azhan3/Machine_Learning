{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X, Y = np.loadtxt(\"temp.txt\", skiprows=1, unpack=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13.,  2., 14., 23., 13., 13.,  1., 18.,  7., 10., 26.,  3.,  3.,\n",
       "       21., 22.,  2., 27.,  6., 10., 18., 15.,  9., 26.,  8., 15., 10.,\n",
       "       21.,  5.,  6., 13.])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([33., 16., 32., 51., 27., 25., 16., 34., 22., 17., 58., 15., 15.,\n",
       "       45., 47., 13., 63., 16., 21., 37., 30., 26., 56., 23., 39., 27.,\n",
       "       45., 17., 18., 23.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkkAAAHECAYAAAAtRr6vAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/P9b71AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA6nklEQVR4nO3df1xUdb7H8feAgCICoQYooLaZP5NMS2mzNDGzXVcX2Ertsdq2tf68orbt2t3V3Lv32q17FbtKuZWaW2rqUm3Z9ksRXcNCUVdrszRMNMB+rKCoQMO5f4yMjJzBAQbmB6/n4zEPmHO+c873cHLnved8v59jMQzDEAAAABwEeLoDAAAA3oiQBAAAYIKQBAAAYIKQBAAAYIKQBAAAYIKQBAAAYIKQBAAAYIKQBAAAYIKQBAAAYIKQBAAAYMInQ9Ljjz8ui8Xi8Ordu7d9/YULFzRjxgx17NhRYWFhSk1NVUlJiQd7DAAAfI1PhiRJ6tevn4qKiuyvv//97/Z1c+bM0RtvvKFNmzYpJydHX331lVJSUjzYWwAA4GvaeLoDjdWmTRvFxMTUWV5aWqoXXnhB69at0x133CFJWr16tfr06aPdu3dr6NChLd1VAADgg3w2JH3++efq0qWL2rZtq6SkJC1evFgJCQnau3evqqqqlJycbG/bu3dvJSQkKDc312lIqqioUEVFhf19dXW1vvvuO3Xs2FEWi6XZjwcAADSdYRg6c+aMunTpooCApt0w88mQNGTIEK1Zs0a9evVSUVGRFi1apGHDhunQoUMqLi5WcHCwIiMjHT4THR2t4uJip9tcvHixFi1a1Mw9BwAALaGwsFBxcXFN2oZPhqQxY8bYfx8wYICGDBmibt26aePGjWrXrl2jtjl//nzNnTvX/r60tFQJCQkqLCxUeHh4k/sMAACaX1lZmeLj49WhQ4cmb8snQ9LlIiMjdd111+nIkSMaNWqUKisrdfr0aYerSSUlJaZjmGqEhIQoJCSkzvLw8HBCEgAAPsYdQ2V8dnZbbWfPntXRo0cVGxurQYMGKSgoSFu3brWvP3z4sI4fP66kpCQP9hIAAPgSn7yS9Mgjj2js2LHq1q2bvvrqKy1cuFCBgYGaMGGCIiIi9OCDD2ru3LmKiopSeHi4Zs2apaSkJGa2AQAAl/lkSDpx4oQmTJigb7/9Vp07d9att96q3bt3q3PnzpKkpUuXKiAgQKmpqaqoqNDo0aOVmZnp4V4DAABfYjEMw/B0J7xRWVmZIiIiVFpaypgkAAB8hDu/v/1iTBIAAIC7EZIAAABMEJIAAABMEJIAAABMEJIAAABMEJIAAABMEJIAAABMEJIAAABMEJIAAABMEJIAAABM+OSz2wD4PqtV2rlTKiqSYmOlYcOkwEBP9woALiEkAWhxWVnS7NnSiROXlsXFScuWSSkpnusXANTG7TYALSorS0pLcwxIknTypG15VpZn+gUAlyMkAWgxVqvtCpJh1F1Xsyw93dYOADyNkASgxezcWfcKUm2GIRUW2toBgKcRkgC0mKIi97YDgOZESALQYmJj3dsOAJoTIQlAixk2zDaLzWIxX2+xSPHxtnYA4GmEJAAtJjDQNs1fqhuUat5nZFAvCYB3ICQBaFEpKdLmzVLXro7L4+Jsy6mTBMBbUEwSQItLSZHGjaPiNgDvRkgC4BGBgdLw4Z7uBQA4x+02AAAAE4QkAAAAE4QkAAAAE4xJAuBWlZVSZqZ09Kj0gx9I06dLwcGe7hUANBwhCYDbPPqotGSJ4wNqH3lEmjtXevJJz/ULABqDkATALR59VHrqqbrLrdZLywlKAHyJxTAMw9Od8EZlZWWKiIhQaWmpwsPDPd0dwKtVVkqhoY5XkC4XGCidO8etNwDNy53f3wzcBtBkmZn1ByTJtj4zs2X6AwDuQEgC0GRHj7q3HQB4A0ISgCb7wQ/c2w4AvAFjkpxgTBLgOsYkAfAWjEkC4FWCg23T/Oszdy4BCYBvoQQAALeomd5/eZ2kwEDqJAHwTdxuc4LbbUDjUHEbgCe58/ubK0kA3Co4WEpP93QvAKDpGJMEAABggpAEAABggpAEAABggpAEAABggpAEAABggpAEAABggpAEAABggpAEAABggpAEAABggpAEAABggpAEAABggpAEAABggpAEAABggpAEAABggpAEAABggpAEAABggpAEAABggpAEAABggpAEAABggpAEAABggpAEAABggpAEAABggpAEAABggpAEAABggpAEAABggpAEAABgwudD0hNPPCGLxaL09HT7sgsXLmjGjBnq2LGjwsLClJqaqpKSEs91EgAA+ByfDkl5eXlauXKlBgwY4LB8zpw5euONN7Rp0ybl5OToq6++UkpKiod6CQAAfJHPhqSzZ89q0qRJeu6553TVVVfZl5eWluqFF17QkiVLdMcdd2jQoEFavXq1PvjgA+3evduDPQYAAL7EZ0PSjBkz9KMf/UjJyckOy/fu3auqqiqH5b1791ZCQoJyc3Odbq+iokJlZWUOLwAA0Hq18XQHGmPDhg3Kz89XXl5enXXFxcUKDg5WZGSkw/Lo6GgVFxc73ebixYu1aNEid3cVAAD4KJ+7klRYWKjZs2fr5ZdfVtu2bd223fnz56u0tNT+KiwsdNu2AQCA7/G5K0l79+7VqVOndOONN9qXWa1W7dixQ8uXL9c777yjyspKnT592uFqUklJiWJiYpxuNyQkRCEhIc3ZdbRiVqu0c6dUVCTFxkrDhkmBgZ7uFQCgPj4XkkaOHKmDBw86LHvggQfUu3dv/eY3v1F8fLyCgoK0detWpaamSpIOHz6s48ePKykpyRNdRiuXlSXNni2dOHFpWVyctGyZxKRLAPBePheSOnTooP79+zssa9++vTp27Ghf/uCDD2ru3LmKiopSeHi4Zs2apaSkJA0dOtQTXUYrlpUlpaVJhuG4/ORJ2/LNmwlKAOCtfC4kuWLp0qUKCAhQamqqKioqNHr0aGVmZnq6W2hlrFbbFaTLA5JkW2axSOnp0rhx3HoDAG9kMQyz/wlHWVmZIiIiVFpaqvDwcE93Bz5o+3ZpxIgrt8vOloYPb+7eAEDr4M7vb5+b3Qb4iqIi97YDALQsQhLQTGJj3dsOANCyCElAMxk2zDaLzWIxX2+xSPHxtnYAAO9DSAKaSWCgbZq/VDco1bzPyGDQNgB4K0IS0IxSUmzT/Lt2dVweF8f0fwDwdn5ZAgDwJikptmn+VNwGAN9CSAJaQGAg0/wBwNdwuw0AAMAEIQkAAMAEIQkAAMAEY5IAP2W1MlgcAJqCkAT4oaws28N1T5y4tCwuzla3ibIDAOAabrcBfiYrS0pLcwxIknTypG15VpZn+gUAvoaQBPgRq9V2Bckw6q6rWZaebmsHAKgfIQnwIzt31r2CVJthSIWFtnYAgPoRkgA/UlTk3nYA0JoRkgA/Ehvr3nYA0JoRkgA/MmyYbRabxWK+3mKR4uNt7QAA9SMkAX4kMNA2zV+qG5Rq3mdkUC8JAFxBSAL8TEqKtHmz1LWr4/K4ONty6iQBgGsoJgn4oZQUadw4Km4DQFMQkgA/FRgoDR/u6V4AgO/idhsAAIAJQhIAAIAJQhIAAIAJQhIAAIAJQhIAAIAJQhIAAIAJQhIAAIAJQhIAAIAJQhIAAIAJQhIAAIAJHksC+CmrlWe3AUBTEJIAP5SVJc2eLZ04cWlZXJy0bJnt4bcAgCvjdhvgZ7KypLQ0x4AkSSdP2pZnZXmmXwDgawhJgB+xWm1XkAyj7rqaZenptnYAgPoRkgA/snNn3StItRmGVFhoawcAqB8hCfAjRUXubQcArRkhCfAjsbHubQcArRkhCfAjw4bZZrFZLObrLRYpPt7WDgBQP0ISYMJqlbZvl9avt/30lYHOgYG2af5S3aBU8z4jg3pJAOAKQhJwmawsqXt3acQIaeJE28/u3X1n6nxKirR5s9S1q+PyuDjbcuokAYBrLIZhNlkYZWVlioiIUGlpqcLDwz3dHbSQmhpDl/+rqLkK40shg4rbAFojd35/E5KcICS1Plar7YqRsyn0FovtakxBAWEDALyVO7+/ud0GXESNIQBAbYQk4CJqDAEAaiMkARdRYwgAUFsbT3cA8BY1NYZOnjR/9lnNmKTaNYYYHA0A/osrScBFDa0x5OulAgAA9SMkAbW4WmOoplTA5QO9T560LScoAYDvowSAE5QAaN3qu41GqQAA8F7u/P5mTBJgIjBQGj7cfF1DSgU42wYAwPtxuw1oIEoFAEDrQEgCGohSAQDQOhCSgAaqKRVw+Qy4GhaLFB/vWCoAAOB7CElAAzW0VAAAwDcRkoBGcLVUAADAdzG7DWiklBRp3DgqbgOAvyIkAU1QX6kAAIBv43YbAACACUISAACACUISAACACcYkAS2gvmfBAQC8k0sh6Q9/+EOz7HzBggWN+twzzzyjZ555RseOHZMk9evXTwsWLNCYMWMkSRcuXNC8efO0YcMGVVRUaPTo0crMzFR0dLS7ug64LCtLmj3b8XlvcXG2WkuUCgAA72UxDMO4UqOAgABZnJUXbgKr1dqoz73xxhsKDAxUz549ZRiGXnzxRT311FPat2+f+vXrp2nTpmnLli1as2aNIiIiNHPmTAUEBGjXrl0u78OdTxFG65WVJaWl2R56W1vNPydqKgGAe7nz+9vlkNQcqqur3batqKgoPfXUU0pLS1Pnzp21bt06paWlSZI+/fRT9enTR7m5uRo6dKhL2yMkoamsVql7d8crSLVZLLYrSgUF3HoDAHdx5/e3S+mnurq6WV7uYLVatWHDBpWXlyspKUl79+5VVVWVkpOT7W169+6thIQE5ebmOt1ORUWFysrKHF5AU+zc6TwgSbarS4WFtnYAAO/js7PbDh48qLCwMIWEhGjq1Kl69dVX1bdvXxUXFys4OFiRkZEO7aOjo1VcXOx0e4sXL1ZERIT9FR8f38xHAH9XVOTedgCAluWzIalXr17av3+/PvzwQ02bNk2TJ0/WJ5980ujtzZ8/X6WlpfZXYWGhG3uL1ig21r3tAAAty2dLAAQHB+vaa6+VJA0aNEh5eXlatmyZ7r33XlVWVur06dMOV5NKSkoUExPjdHshISEKCQlp7m6jFRk2zDbm6OTJugO3pUtjkoYNa/m+AQCuzGevJF2uurpaFRUVGjRokIKCgrR161b7usOHD+v48eNKSkryYA/R2gQG2qb5S5dms9WoeZ+RwaBtAPBWLl1JuuOOO9y+Y4vF4hBkGmL+/PkaM2aMEhISdObMGa1bt07bt2/XO++8o4iICD344IOaO3euoqKiFB4erlmzZikpKcnlmW2Au6Sk2Kb5m9VJyshg+j8AeDOXQtL27dtlsVjkQrWAK6rZTlPqLp06dUo///nPVVRUpIiICA0YMEDvvPOORo0aJUlaunSpAgIClJqa6lBMEvCElBRp3DgqbgOAr3GpTtLw4cObpZhkdna227fpLtRJAgDA97jz+9vlK0kAAACtid8M3AYAAHAnQhIAAIAJQhIAAIAJQhIAAIAJlwZuB16cq2yxWPT999/XWd4Yl28LAADAm7gUkpxVCXBH3SQAAABv5FJIWrhwYYOWAwAA+DqXikm2RhSTBADA97jz+5uB2wAAACZcut0GeIrV6plnnnlqvwAA70FIgtfKypJmz5ZOnLi0LC5OWrbM9tBYf9svAMC7NNvttm3btun+++9XYmKi+vXrp7vuukvLly9XRUVFc+0SfiQrS0pLcwwqknTypG15VpZ/7RcA4H0aPHB727Zteuqpp5SXl6eKigolJCRo/PjxmjdvnqKioiRJjzzyiJYuXWr6+Z49e+rdd99VQkJC03vfjBi47TlWq9S9e92gUsNisV3ZKShw7y0wT+0XAOA+7vz+blBIyszM1KxZsyRdqpFksVgkSf3799fOnTu1YcMGTZ06td7tDBw4UHl5eQoI8N5x44Qkz9m+XRox4srtsrOl4cN9f78AAPfxyOy2zz77THPmzJFkC0idOnXS4MGD1alTJxmGoUOHDikzM1P//d//LUmaOHGi9u3bp/Pnz+vMmTPatm2bbr31VknS/v37tXnz5iZ1HP6rqMi97bx9vwAA7+RySFq5cqWqqqoUFBSkVatW6dSpU/roo49UUlKi1atXKygoSE8++aSOHTumlJQUvfTSS0pMTFRISIjat2+v4cOH6/3331e/fv0kSZs2bWq2g4Jvi411bztv3y8AwDu5HJK2b98ui8WiadOmacqUKQ7rJk+erGnTpun06dOSpPT0dNNtBAcHa/r06TIMQ/n5+Y3tM/zcsGG2sT8X7+TWYbFI8fG2dv6wXwCAd3I5JH3xxReSpDFjxpiuv/vuu+2/JyYmOt3ODTfcIEk6deqUq7uGH7JabWOA1q+3/bRaL60LDLRNt5fqBpaa9xkZ7h887an9AgC8k8sh6cyZM5KkWCf3GqKjo+2/d+jQwel2agZRnTt3ztVdw89kZdlmkY0YIU2caPvZvbvj9PqUFGnzZqlrV8fPxsXZljdXvSJP7RcA4H1cLiZZXV0ti8WiQCf/N9rZcqC2mjpEl8+prKlDVDuIpKRI48a1fOVrT+0XAOBdqLiNFmO12ipZmxWdMAzbLa30dFtAqQkkgYGemW7vqf0CALyH9xYqgt/ZudN5oUbJFpQKC23tAADwtAZfScrLy9M333xTZ3lBQYH99507d8pZjcra7dC6UIcIAOBLGhySfvGLXzhdV1N9ezj3KWCCOkQAAF/SoJDUwMe8AQ5q6hCdPGk+Lqnm2WjeUIfIamXgNgC0di6HpIULFzZnP9AK1NQhSkuzBaLaQcmb6hBlZdkGmNcePxUXZ+s7JQAAoPVo0ANuWxMecNt8zEJIfLwtIHk6hDgrUVAT4qiVBADezZ3f34QkJwhJzcsbb2dZrbails5m4NXcDiwo8HxfAQDm3Pn9TZ0keIQ31iFqSIkCb+s7AMD9qJMEXESJAgBAbYQk4CJKFAAAaiMkARfVlCioGaR9OYvFNsDcG0oUAACaHyEJuKimRIFUNyh5U4kCAEDLICQBtaSk2Kb5d+3quDwujun/ANDaMLsNuExKijRunPeVKAAAtCxCEmDCG0sUAABaFrfbAAAATBCSAAAATDTodtvp06e1Y8cOSVJ8fLwGDhzo8mfz8/N14mI54xEjRqhDhw4N2TUAAECLalBIeuyxx7Ry5UqFhYVp9+7dDdpRu3btdP/996u8vFyzZ8/WkiVLGvR5+AZvfCZbY/jLcQAAGs/l220lJSV6/vnnJUl//OMf1adPnwbtqE+fPvqv//ovGYahzMxMffPNNw3rKbxeVpbtAbEjRkgTJ9p+du9uW+5L/OU4AABN43JIWrdunb7//nt17dpV06ZNa9TOpk6dqoSEBFVVVWndunWN2ga8U1aWlJZW9wGxJ0/alvtKwPCX4wAANJ3LISk7O1sWi0Wpqalq06ZxlQPatGmj1NRUGYahbdu2NWob8D5WqzR7tmQYddfVLEtPt7XzZv5yHAAA93A5JP3jH/+QJA1vYvGY2267TZJ04MCBJm0H3mPnzrpXXmozDKmw0NbOm/nLcQAA3MPlkPTtt99Kkrp06dKkHcZefIQ6Y5L8R1GRe9t5ir8cBwDAPVwOSdaL9xgMs3sRDWC5+KRQK/cs/MbF3Ou2dp7iL8cBAHAPl0NSp06dJElFTfy/0TWfr9kefIPVKm3fLq1fb/tZO+MOG2Z7AOzF/FuHxSLFx9vaeTN/OQ4AgHu4HJJ69OghSfZiko2Vk5PjsD14vytNiQ8MlJYts/1+ecCoeZ+R4f11hvzlOAAA7uFySBo5cqQMw9C6detUXl7eqJ2Vl5fr5ZdflsVi0ciRIxu1DbQsV6fEp6RImzdLXbs6touLsy1PSWmZ/jaVvxwHAKDpLIaLg4w+/fRT9e/fX4Zh6Je//KVWrlzZ4J09/PDDev755xUYGKhDhw6pV69eDd5GSykrK1NERIRKS0sVHh7u6e54hNVqu2LkbMaXxWILDwUFl66u+Eulan85DgBobdz5/e1ywaPevXtr4sSJeumll/T888/LYrFo6dKlateu3RU/e/78eaWnp9s/N2nSJK8OSLBpyJT4msoQgYGXfvdl/nIcAIDGc/l2myQtW7ZMPXv2lGEYeu6559SzZ08tWrRIeXl5qqqqcmhbVVWlvLw8Pf744+rZs6f9kSbXXXedMjIy3HYAaD5MiQcAtGYu326r8cUXX2js2LH65z//aZ/OL0kBAQGKiIhQ+/btVV5ertLSUlVXV0u6VDagT58+evPNN31i0Da322yz2EaMuHK77GyuugAAvIM7v78bdCVJkq655hrt2bNHs2bNUtu2bWUYhgzDkNVq1XfffacTJ07ou+++k9Vqta9r166d/u3f/k15eXk+EZBg4w1T4usrPQAAQHNq8JWk2r755htt2LBBOTk5OnDggL799ludOXNGHTp0UMeOHZWYmKjbb79d9913n8/VReJKkk3N7DbJ8ZlmNcGpOWd8ZWXZnqVWe1xUXJxtmj6zzAAAZtz5/d2kkOTPCEmXmIWV+HhbzaDmDEhpaXUfNtsS4QwA4Lt8PiTt27dPa9eu1dKlS1t61y4jJDlqySnxjSk9AACA5KMhqaioSC+99JL+/Oc/6+OPP5bk3c9vIyR5DgPGAQCN5ZE6SY1x/vx5ZWVlae3atdq2bZvDbDeLs9HAaPUoPQAA8AbNEpKys7O1du1aZWVl6ezZs5IulQGIjY3VT3/6U6WmpjbHruEHYmPd2w4AgMZwW0j69NNPtXbtWr388ss6cXEwSU0wiouLU2pqqtLS0nTLLbdwFQn1qik9cPJk3YHb0qUxSc1ZegAAgCaFpG+//Vbr16/X2rVrtXfvXkmXglFkZKROnz4ti8Wi//mf/9E999zT9N6iVQgMtE3zT0uzBSKz0gMZGQzaBgA0rwYXk6yqqlJWVpbGjx+vrl27avbs2dqzZ48Mw1BQUJDGjx+vzZs3q6gZB4wsXrxYN910kzp06KCrr75a48eP1+HDhx3aXLhwQTNmzFDHjh0VFham1NRUlZSUNFuf4F4pKbZp/l27Oi6Pi2P6PwCgZbh8JWn37t1au3atNm7cqH/961+SLg3A/uEPf6j7779f99xzj6666qpm62yNnJwczZgxQzfddJO+//57PfbYY7rzzjv1ySefqH379pKkOXPmaMuWLdq0aZMiIiI0c+ZMpaSkaNeuXc3eP7hHSoo0blzLlR4AAKA2l0sABAQEyGKx2G+n9erVS/fff78mTZqk7t271/uZ9evXN+vttq+//lpXX321cnJydNttt6m0tFSdO3fWunXrlHaxXPSnn36qPn36KDc3V0OHDr3iNikBAACA7/FoCYAOHTro6aef1uTJk5u0Y3cqLS2VJEVFRUmS9u7dq6qqKiUnJ9vb9O7dWwkJCU5DUkVFhSoqKuzvy8rKmrnXAADAmzVoTJJhGDp79qx+8Ytf6MYbb9SSJUuadeyRK6qrq5Wenq4f/vCH6t+/vySpuLhYwcHBioyMdGgbHR2t4uJi0+0sXrxYERER9ld8fHxzdx0AAHgxl0PS9u3bNWXKFIWFhckwDO3fv1+//vWvlZCQoFGjRmnt2rX2mkgtacaMGTp06JA2bNjQpO3Mnz9fpaWl9ldhYaGbeggAAHyRyyHptttu06pVq1RSUqKXX35Zo0ePVkBAgKxWq7Zt26YHHnhAMTExmjBhgt56660WeeTIzJkz9eabbyo7O1txcXH25TExMaqsrNTp06cd2peUlCgmJsZ0WyEhIQoPD3d4AQCA1qvBJQDatm2rCRMm6G9/+5sKCwv15JNP6vrrr5dhGDp37pw2btyosWPHKrYZyyEbhqGZM2fq1Vdf1bZt29SjRw+H9YMGDVJQUJC2bt1qX3b48GEdP35cSUlJzdYvAADgP9z2gNsDBw7oxRdf1Pr16+31iGoqa8fGxtorbg9zQ5nk6dOna926dXr99dfVq1cv+/KIiAi1a9dOkjRt2jS99dZbWrNmjcLDwzVr1ixJ0gcffODSPpjdBgCA73Hn97fbQlINq9Wqd955R2vXrtVf//pXXbhwwbaji4Hp6quvtj+7beTIkY3ah7PHmqxevVpTpkyRZCsmOW/ePK1fv14VFRUaPXq0MjMznd5uuxwhCQAA3+PVIam2srIyvfLKK/rzn/+sXbt22WssWSwWWSwWff/998216yYjJAEA4Ht8JiTVduzYMb344ot66aWXdPToUVkslhYZ3N1YhCQAAHyPO7+/Gzxwu7G6d++uhQsX6vPPP9fOnTv10EMPtdSuAQAAGqzFriT5Gq4kAQDgezz6WBL4F6uVB8gCAGCGkNSKZWVJs2dLJ05cWhYXJy1bJqWkeK5fAAB4gxYbkwTvkpUlpaU5BiRJOnnStjwryzP9AgDAWxCSWiGr1XYFyWw0Ws2y9HRbOwAAWitCUiu0c2fdK0i1GYZUWGhrBwBAa0VIaoWKitzbDgAAf0RIaoVcffZwMz6jGAAAr8fsNj/mbHr/sGG2WWwnT5qPS7JYbOvd8CziJqNEAQDAU7iS5KeysqTu3aURI6SJE20/u3e3LQ8MtE3zl2yBqLaa9xkZng8j9R0DAADNjZDkh1yZ3p+SIm3eLHXt6tgmLs623NN1kihRAADwNB5L4oSvPpbEarVdbXE2e63mVlpBge1KkTfezmroMQAAUIPHksCphkzvHz7cFjKGD2+p3rmmoccAAEBz4Habn/GH6f3+cAwAAN9HSPIz/jC93x+OAQDg+7jd1gSujudpyXE/DZ3e741jknypRAEAwH9xJamRXJ2e3tLT2Bsyvd9bp9j7SokCAIB/IyQ1gqvT0z01jd2V6f3ePsXe20sUAAD8HyUAnHA2hdDV6elHjkg/+IFnp7E7u5XmS1PsvfF2IADAe1ECwINcnZ6emen5aezOpvf70hR7byxRAABoHbjd1kCuTjs/etS923MnptgDAHBlhKQGcnXa+Q9+4N7tuRNT7AEAuDJCUgPVTE+/fNZVDYtFio+Xpk93rZ0nprG7egxMsQcAtGaEpAZydXp6cHDDp7FXVtqWzZpl+1lZ6d6+12CKPQAAV0ZIagRXp6c3ZBr7o49KoaHSnDnS8uW2n6GhtuWePAYAAForSgA44coUQndV3H70Uempp5z35de/lp58sokH5ART7AEA/sSdJQAISU64849cn8pK2xUjq9V5m8BA6dw52y08AADgnDu/v7nd5mGZmfUHJMm2PjOzZfoDAABsCEke5mo9JVfbAQAA9yAkeZir9ZRcbQcAANyDMUlOMCYJAADfw5gkPxIcLM2dW3+buXMJSAAAtDQecOsFaqb3L1nieEUpMNAWkJpr+j8AAHCO221OtNTtttoqK22z2I4etY1Bmj6dK0gAADSEO7+/uZLkRYKDpfR0T/cCAABIjEkCAAAwRUgCAAAwQUgCAAAwwZikFsBDZAEA8D2EpGaWlSXNni2dOHFpWVyctGyZlJLiuX4BAID6cbutGWVlSWlpjgFJkk6etC3PyvJMvwAAwJURkpqJ1Wq7gmRWhapmWXp6/Y8jAQAAnkNIaiY7d9a9glSbYUiFhbZ2AADA+xCSmklRkXvbAQCAlkVIaiaxse5tBwAAWhYhqZkMG2abxWaxmK+3WKT4eFs7AADgfQhJzSQw0DbNX6oblGreZ2RQLwkAAG9FSGpGKSnS5s1S166Oy+PibMupkwQAgPeimGQzS0mRxo2j4jYAAL6GkNQCAgOl4cM93QsAANAQ3G4DAAAwQUgCAAAwQUgCAAAwQUgCAAAwQUgCAAAwQUgCAAAwQUgCAAAwQUgCAAAwQUgCAAAwQUgCAAAwQUgCAAAw4ZMhaceOHRo7dqy6dOkii8Wi1157zWG9YRhasGCBYmNj1a5dOyUnJ+vzzz/3TGcBAIBP8smQVF5ersTERK1YscJ0/ZNPPqmnn35azz77rD788EO1b99eo0eP1oULF1q4pwAAwFe18XQHGmPMmDEaM2aM6TrDMJSRkaHf/e53GjdunCRp7dq1io6O1muvvab77ruvJbsKAAB8lE9eSapPQUGBiouLlZycbF8WERGhIUOGKDc31+nnKioqVFZW5vACAACtl9+FpOLiYklSdHS0w/Lo6Gj7OjOLFy9WRESE/RUfH9+s/QQAAN7N70JSY82fP1+lpaX2V2Fhoae7BAAAPMjvQlJMTIwkqaSkxGF5SUmJfZ2ZkJAQhYeHO7wAAEDr5XchqUePHoqJidHWrVvty8rKyvThhx8qKSnJgz0DAAC+xCdnt509e1ZHjhyxvy8oKND+/fsVFRWlhIQEpaen649//KN69uypHj166Pe//726dOmi8ePHe67TAADAp/hkSNqzZ49GjBhhfz937lxJ0uTJk7VmzRo9+uijKi8v18MPP6zTp0/r1ltv1dtvv622bdt6qssAAMDHWAzDMDzdCW9UVlamiIgIlZaWMj4JAAAf4c7vb78bkwQAAOAOhCQAAAAThCQAAAAThCQAAAAThCQAAAAThCQAAAAThCQAAAAThCQAAAAThCQAAAAThCQAAAAThCQAAAAThCQAAAAThCQAAAAThCQAAAAThCQAAAAThCQAAAAThCQAAAAThCQAAAAThCQAAAAThCQAAAAThCQAAAAThCQAAAAThCQAAAAThCQAAAAThCQAAAAThCQAAAAThCQAAAAThCQAAAAThCQAAAAThCQAAAAThCQAAAAThCQAAAAThCQAAAAThCQAAAAThCQAAAAThCQAAAAThCQAAAAThCQAAAAThCQAAAAThCQAAAAThCQAAAAThCQAAAAThCQAAAAThCQAAAAThCQAAAAThCQAAAAThCQAAAAThCQAAAAThCQAAAAThCQAAAAThCQAAAAThCQAAAAThCQAAAAThCQAAAAThCQAAAAThCQAAAAThCQAAAAThCQAAAAThCQAAAAThCQAAAAThCQAAAAThCQAAAAThCQAAAATfh2SVqxYoe7du6tt27YaMmSIPvroI093CQAA+Ai/DUmvvPKK5s6dq4ULFyo/P1+JiYkaPXq0Tp065emuAQAAH+C3IWnJkiV66KGH9MADD6hv37569tlnFRoaqlWrVnm6awAAwAe08XQHmkNlZaX27t2r+fPn25cFBAQoOTlZubm5pp+pqKhQRUWF/X1paakkqaysrHk7CwAA3Kbme9swjCZvyy9D0jfffCOr1aro6GiH5dHR0fr0009NP7N48WItWrSozvL4+Phm6SMAAGg+3377rSIiIpq0Db8MSY0xf/58zZ071/7+9OnT6tatm44fP97kPzKapqysTPHx8SosLFR4eLinu9OqcS68C+fDe3AuvEdpaakSEhIUFRXV5G35ZUjq1KmTAgMDVVJS4rC8pKREMTExpp8JCQlRSEhIneURERH8B+8lwsPDORdegnPhXTgf3oNz4T0CApo+7NovB24HBwdr0KBB2rp1q31ZdXW1tm7dqqSkJA/2DAAA+Aq/vJIkSXPnztXkyZM1ePBg3XzzzcrIyFB5ebkeeOABT3cNAAD4AL8NSffee6++/vprLViwQMXFxbrhhhv09ttv1xnM7UxISIgWLlxoegsOLYtz4T04F96F8+E9OBfew53nwmK4Y44cAACAn/HLMUkAAABNRUgCAAAwQUgCAAAwQUgCAAAwQUgysWLFCnXv3l1t27bVkCFD9NFHH3m6S63Cjh07NHbsWHXp0kUWi0Wvvfaaw3rDMLRgwQLFxsaqXbt2Sk5O1ueff+6Zzvq5xYsX66abblKHDh109dVXa/z48Tp8+LBDmwsXLmjGjBnq2LGjwsLClJqaWqeAK5rumWee0YABA+xFCpOSkvS3v/3Nvp7z4DlPPPGELBaL0tPT7cs4Hy3j8ccfl8VicXj17t3bvt5d54GQdJlXXnlFc+fO1cKFC5Wfn6/ExESNHj1ap06d8nTX/F55ebkSExO1YsUK0/VPPvmknn76aT377LP68MMP1b59e40ePVoXLlxo4Z76v5ycHM2YMUO7d+/We++9p6qqKt15550qLy+3t5kzZ47eeOMNbdq0STk5Ofrqq6+UkpLiwV77p7i4OD3xxBPau3ev9uzZozvuuEPjxo3Txx9/LInz4Cl5eXlauXKlBgwY4LCc89Fy+vXrp6KiIvvr73//u32d286DAQc333yzMWPGDPt7q9VqdOnSxVi8eLEHe9X6SDJeffVV+/vq6mojJibGeOqpp+zLTp8+bYSEhBjr16/3QA9bl1OnThmSjJycHMMwbH/7oKAgY9OmTfY2//znPw1JRm5urqe62WpcddVVxvPPP8958JAzZ84YPXv2NN577z3j9ttvN2bPnm0YBv8uWtLChQuNxMRE03XuPA9cSaqlsrJSe/fuVXJysn1ZQECAkpOTlZub68GeoaCgQMXFxQ7nJiIiQkOGDOHctIDS0lJJsj8wcu/evaqqqnI4H71791ZCQgLnoxlZrVZt2LBB5eXlSkpK4jx4yIwZM/SjH/3I4e8u8e+ipX3++efq0qWLrrnmGk2aNEnHjx+X5N7z4LcVtxvjm2++kdVqrVOVOzo6Wp9++qmHegVJKi4uliTTc1OzDs2jurpa6enp+uEPf6j+/ftLsp2P4OBgRUZGOrTlfDSPgwcPKikpSRcuXFBYWJheffVV9e3bV/v37+c8tLANGzYoPz9feXl5ddbx76LlDBkyRGvWrFGvXr1UVFSkRYsWadiwYTp06JBbzwMhCUC9ZsyYoUOHDjnc70fL6tWrl/bv36/S0lJt3rxZkydPVk5Ojqe71eoUFhZq9uzZeu+999S2bVtPd6dVGzNmjP33AQMGaMiQIerWrZs2btyodu3auW0/3G6rpVOnTgoMDKwzAr6kpEQxMTEe6hUk2f/+nJuWNXPmTL355pvKzs5WXFycfXlMTIwqKyt1+vRph/acj+YRHBysa6+9VoMGDdLixYuVmJioZcuWcR5a2N69e3Xq1CndeOONatOmjdq0aaOcnBw9/fTTatOmjaKjozkfHhIZGanrrrtOR44cceu/C0JSLcHBwRo0aJC2bt1qX1ZdXa2tW7cqKSnJgz1Djx49FBMT43BuysrK9OGHH3JumoFhGJo5c6ZeffVVbdu2TT169HBYP2jQIAUFBTmcj8OHD+v48eOcjxZQXV2tiooKzkMLGzlypA4ePKj9+/fbX4MHD9akSZPsv3M+POPs2bM6evSoYmNj3fvvogmDy/3Shg0bjJCQEGPNmjXGJ598Yjz88MNGZGSkUVxc7Omu+b0zZ84Y+/btM/bt22dIMpYsWWLs27fP+PLLLw3DMIwnnnjCiIyMNF5//XXjH//4hzFu3DijR48exvnz5z3cc/8zbdo0IyIiwti+fbtRVFRkf507d87eZurUqUZCQoKxbds2Y8+ePUZSUpKRlJTkwV77p9/+9rdGTk6OUVBQYPzjH/8wfvvb3xoWi8V49913DcPgPHha7dlthsH5aCnz5s0ztm/fbhQUFBi7du0ykpOTjU6dOhmnTp0yDMN954GQZOL//u//jISEBCM4ONi4+eabjd27d3u6S61Cdna2IanOa/LkyYZh2MoA/P73vzeio6ONkJAQY+TIkcbhw4c922k/ZXYeJBmrV6+2tzl//rwxffp046qrrjJCQ0ONn/70p0ZRUZHnOu2nfvGLXxjdunUzgoODjc6dOxsjR460ByTD4Dx42uUhifPRMu69914jNjbWCA4ONrp27Wrce++9xpEjR+zr3XUeLIZhGG640gUAAOBXGJMEAABggpAEAABggpAEAABggpAEAABggpAEAABggpAEAABggpAEAABggpAEAABggpAEeKljx47JYrE0+QUAaBxCEgB4UE2Yffzxxz3dFQCXaePpDgAw17VrVx08eNDp+uuvv16SNHjwYK1evbqlugUArQYhCfBSQUFB6t+//xXbtW/f3qV2AICG4XYbAACACUIS4Mfy8/M1depU9erVS2FhYWrfvr169eqladOm6bPPPnP6uTVr1tjHyhw7dkyVlZVasmSJBg8erIiICEVFRWn48OHasmWLw+fOnDmjJ598UgMHDlR4eLgiIyM1atQobd261em+tm/fbt/X9u3bVV1dreeee0633HKLoqKi1L59eyUmJmrx4sW6cOGCS8f92muv6Wc/+5kSEhLUtm1bRUZGavDgwVq0aJH+9a9/Of3clClTZLFY1L17d0lSUVGRfvOb36hfv37q0KGDvY81/vWvf2n16tW6//771bdvX4WFhSk4OFgxMTEaPXq0/vSnP6mystJ0X927d3cYWL9o0aI6g+6nTJliX3/5OXGm9oD/NWvWNPkYJclqterFF1/Uj3/8Y3Xp0kUhISHq2LGjbr31Vi1ZskTnz5932h/ApxkAfJIkQ5Jx++2311lntVqNOXPmGBaLxd7u8lebNm2MlStXmm579erV9nYHDhwwhgwZ4nQ7S5YsMQzDML788kujX79+pm0sFovx0ksvme4rOzvb3u6dd94x7rrrLqf76tu3r1FUVOT0b/Ldd98Zd9xxh9PPSzKuvvpqIzc31/TzkydPNiQZ3bp1M3Jzc41OnTrV+Xx2dra9fbdu3erdlyRj4MCBpn125bOTJ082PScFBQVO/wYFBQX2dqtXr27yMX755ZdGYmJivf289tprjcOHDzvtE+CrGJME+KFZs2YpMzNTknTbbbdpypQpuuaaaxQaGqoDBw4oIyNDH3/8sX71q18pJiZGP/nJT5xu6+GHH9bevXs1ffp0/fSnP9VVV12l/fv3a8GCBfrqq6/0yCOPaNSoUZoyZYq++OIL/fa3v9Vdd92l9u3ba9euXVq4cKFKS0s1bdo0jRo1SldffbXTff3ud79TXl6e7rzzTk2bNk3x8fEqLCxUZmam3nvvPX3yyScaO3asdu/ercDAQIfPVlRUKDk5Wfn5+QoMDNTEiRN19913q0ePHqqqqtKOHTu0ZMkSnTp1Snfffbf27dunbt26mfbj7NmzSk1N1YULF/Tv//7vGjVqlEJDQ3Xw4EHFxsba21mtVg0ZMkQ//vGPNXDgQEVHR6uyslIFBQV66aWX9Pbbb2vfvn2677776lydeffdd1VZWWkfgD9t2jRNnz7doc1VV13l9G/VVK4c47fffqtbb71VhYWFCgkJ0UMPPaTbb79d3bt319mzZ/Xuu+9q2bJlOnLkiMaMGaP8/HxFREQ0W5+BFufplAagceTkStK7775rX/f888+bfvb8+fP2Ky7dunUzqqqqHNbXvmphsViMV199tc42Dhw4YAQEBBiSjM6dOxshISHG7t2767TbsmVLnatOtdW+kiTJePjhh037/OCDD9rbrFixos76xx57zJBkREZGGnv27DHdxrFjx4zY2FhDkjFx4sQ662uuskgywsLCjP3795tup8Znn31W7/pVq1bZt/f++++btqlZv3Dhwnq35e4rSa4c48SJE+3/jXzxxRembfLz84327dsbkozHHnus3mMAfA1jkgA/88QTT0iSUlNT9eCDD5q2adu2rZYvXy5J+vLLL5Wdne10e/fcc4/Gjx9fZ/mAAQN06623SpK+/vprpaena8iQIXXa3X333fYrNjt37qy379HR0Vq6dKnpuoyMDHXu3FmS7FfJapw9e1YrVqyQJP3Hf/yHBg0aZLqNbt266fe//70kadOmTSovL3fal0cffVSJiYn19rdnz571rn/ggQd0ww03SLKNk/I29R3jsWPH9Morr0iSli9frh49epi2GzhwoGbMmCFJpmOgAF9GSAL8SFlZmf22TlpaWr1t+/Tpo06dOkmScnNznba77777nK6r/QVbX7sBAwZIkr744ot6+3TPPfcoNDTUdF1YWJjuueceSdLHH3+s4uJi+7qcnByVlpZKuvJx33bbbZKkqqoq7d2712m7SZMm1budyxmGoeLiYn322Wc6dOiQ/dW1a1dJ0oEDBxq0vZZQ3zFu2bJFVqtVoaGhGjNmTL3bqfmbfvXVVzp+/Lhb+wh4EmOSAD+yb98+VVdXS5ImTJigCRMmuPS52oHjctddd53TdZGRkQ1qd+bMmXr7cdNNN9W7/uabb7ZfMTp48KBiYmIkSXv27LG3qT1m6EqcHXdYWJiuueYal7axZcsWPfPMM9qxY0e9x/fNN9+43K+WcKVjrPmbnjt3Tm3auP5VUVxcrISEhCb3D/AGhCTAj5w6dapRnzt37pzTdc6u7EhSQEBAg9pZrdZ6+1HfoG7JdjuuxnfffWf/3d3HXTv8OWMYhh566CG98MILLu3L26bJX+kYm+O/JcDXEJIAP1I7hKxcuVK33HKLS59rzllUDdHYB/LWPu78/HwFBQW59Lm4uDjT5ZfPnDOzatUqe0C64YYb7GOyunbtqtDQUPs2fv7zn+vPf/6zDMNwqU8t5UrHWPM37dSpU71j1i7nbOwS4IsISYAf6dixo/330NBQn3tcSUlJicvro6Ki7L/XPu7OnTs7DT/u9Nxzz0mSrr32Wn3wwQdq166dabvaV7yaovZVu5pbqmbqG4zeEDV/0zNnzqhPnz4uBUfA3zBwG/AjN9xwg/1qzK5duzzcm4bLy8tzeX3tADhw4ED77y113B9//LEk6Sc/+YnTgGQYhvLz892yvw4dOth/r69qeH2V1Bui5m9aUVHhMOYLaE0ISYAf6dy5s4YOHSpJWrdunb7++msP96hhNm3a5HTsTnl5uTZu3ChJ6tu3r8MA7eTkZPuYqKeffrpFbm19//339n458/rrr6uoqKje7bRt21aSLYzUp/ZtrPpCy/r16+vdjqvGjh1rD9wZGRlu2SbgawhJgJ/53e9+J8lWDiAtLU2nT5922raiokIrVqxw+Zloza24uFjz5s0zXTd37lz7YOJp06Y5rIuMjNTMmTMlSR988IHmzJlT7y2pkpISPf/8803qa02NpDfeeMP0ltrRo0ft9YPqUxP2jh49Wm+7/v37228xLl++3DRUbdy4UZs2bbriPl3Rq1cv/exnP5MkbdiwQUuWLKm3fUFBgdsCGuAtCEmAn7n77rs1e/ZsSdKOHTvUp08fLVq0SFu3btX+/fu1a9cuvfjii/rlL3+p2NhYzZw5035VxNMGDx6sZ555RmPGjNHrr7+u/Px8vf7667rrrrv0pz/9SZLtNtDUqVPrfPYPf/iDvZjlsmXLdOONN2rFihXatWuX9u/fr+zsbC1fvlzjx49XQkKCnn322Sb19ec//7kkW22gpKQkrVq1Sh999JF27Nihxx9/XIMGDdJ3332nG2+8sd7t1Ayu/+tf/6qVK1fq0KFDOnLkiI4cOeIww6xNmzb61a9+JUk6dOiQ7rjjDr3++uvat2+f3n77bT344IOaMGGCy4P1XfHMM8/YywTMmzdPt99+u1544QXt3r1b+/bt0/vvv6///d//1ahRo3TttdfqL3/5i9v2DXgFj9b7BtBoqucBt9XV1caiRYuMNm3aXPEhqu3btzfOnTvn8HlXH4GxcOFCe7v61H6o6uUuf8DtnXfe6bSvvXv3Nk6ePOl0P2VlZUZKSsoVj1mSMWLEiAb183KVlZX19rVdu3bGxo0br7jNffv2GSEhIVd8wK1hGEZ5ebkxdOhQp/scPny4cejQIZcfcOuKoqIiY9iwYS79TR944AGXtgn4Cq4kAX7IYrFowYIF+uyzz/Too49q8ODBioqKUmBgoDp06KC+fftq0qRJevHFF1VUVOR04HFLCw4O1ltvvaXMzEwNHTpUkZGRCg0N1fXXX68//vGPys/PV5cuXZx+vkOHDvrLX/6inTt36pe//KV69eqlDh06qE2bNoqKitJNN92kGTNm6K233tJ7773XpL4GBQVpy5YtevrppzV48GCFhoaqXbt2uvbaazV16lTl5+fbb1fV54YbblBubq4mTJighIQEhYSEOG0bGhqqbdu26T//8z91/fXXq127dgoPD9dNN92k5cuX6/3331f79u2bdFyXi4mJ0Y4dO/Tmm29q0qRJ9gclBwUFqXPnzrrllls0b9485eTkaNWqVW7dN+BpFsPwsuIdAFqV7du3a8SIEZKk7OxsDR8+3LMdAoCLuJIEAABggpAEAABggpAEAABggpAEAABggpAEAABggtltAAAAJriSBAAAYIKQBAAAYIKQBAAAYIKQBAAAYIKQBAAAYIKQBAAAYIKQBAAAYIKQBAAAYIKQBAAAYOL/AQ1cbRVNn3uXAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.xlabel(\"Temperature\", fontsize=20)  \n",
    "plt.ylabel(\"AC Bill\", fontsize=20)        \n",
    "plt.axis([0, 50, 0, 50])                 \n",
    "plt.plot(X, Y, \"bo\")                    \n",
    "plt.show()    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction FUnction (Straight Line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, w, b):\n",
    "    return X * w + b"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Prediction where first argument is temperature. w and b are weight and bias for the regression line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.8"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(14, 1.2, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([28.8, 18. , 20.4])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperatures = np.array([14, 5, 7])\n",
    "predict(temperatures, 1.2, 12)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find Line with LOWEST ERROR (MEAN SQUARE ERROR) / LOSS (APPROXIMATION ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(X, Y, w, b):\n",
    "    predictions = predict(X, w, b)\n",
    "    \n",
    "    return np.average((predictions - Y) ** 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takes our model (line --> w and b) and some samples (X, Y) and calculates the error of the model. \n",
    "Lower loss --> better model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44.07866666666667"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(X, Y, 1.2, 12)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, Y, iterations, lr):\n",
    "    w = b = 0\n",
    "    for i in range(iterations):\n",
    "        current_loss = loss(X, Y, w, b)\n",
    "        print(\"Iteration %4d => Loss: %.6f\" % (i, current_loss))\n",
    "\n",
    "        if loss(X, Y, w - lr, b) < current_loss:\n",
    "            w -= lr\n",
    "        elif loss(X, Y, w + lr, b) < current_loss:\n",
    "            w += lr\n",
    "        elif loss(X, Y, w, b - lr) < current_loss:\n",
    "            b -= lr\n",
    "        elif loss(X, Y, w, b + lr) < current_loss:\n",
    "            b += lr\n",
    "        else:\n",
    "            return w, b\n",
    "\n",
    "    raise Exception(\"Couldn't find a result within %d iterations\" % iterations)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model --> set learning rate very low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration    0 => Loss: 1113.966667\n",
      "Iteration    1 => Loss: 1112.993419\n",
      "Iteration    2 => Loss: 1112.020609\n",
      "Iteration    3 => Loss: 1111.048236\n",
      "Iteration    4 => Loss: 1110.076301\n",
      "Iteration    5 => Loss: 1109.104803\n",
      "Iteration    6 => Loss: 1108.133743\n",
      "Iteration    7 => Loss: 1107.163121\n",
      "Iteration    8 => Loss: 1106.192937\n",
      "Iteration    9 => Loss: 1105.223189\n",
      "Iteration   10 => Loss: 1104.253880\n",
      "Iteration   11 => Loss: 1103.285008\n",
      "Iteration   12 => Loss: 1102.316574\n",
      "Iteration   13 => Loss: 1101.348577\n",
      "Iteration   14 => Loss: 1100.381018\n",
      "Iteration   15 => Loss: 1099.413897\n",
      "Iteration   16 => Loss: 1098.447213\n",
      "Iteration   17 => Loss: 1097.480967\n",
      "Iteration   18 => Loss: 1096.515158\n",
      "Iteration   19 => Loss: 1095.549787\n",
      "Iteration   20 => Loss: 1094.584853\n",
      "Iteration   21 => Loss: 1093.620357\n",
      "Iteration   22 => Loss: 1092.656299\n",
      "Iteration   23 => Loss: 1091.692679\n",
      "Iteration   24 => Loss: 1090.729495\n",
      "Iteration   25 => Loss: 1089.766750\n",
      "Iteration   26 => Loss: 1088.804442\n",
      "Iteration   27 => Loss: 1087.842572\n",
      "Iteration   28 => Loss: 1086.881139\n",
      "Iteration   29 => Loss: 1085.920144\n",
      "Iteration   30 => Loss: 1084.959587\n",
      "Iteration   31 => Loss: 1083.999467\n",
      "Iteration   32 => Loss: 1083.039785\n",
      "Iteration   33 => Loss: 1082.080540\n",
      "Iteration   34 => Loss: 1081.121733\n",
      "Iteration   35 => Loss: 1080.163363\n",
      "Iteration   36 => Loss: 1079.205431\n",
      "Iteration   37 => Loss: 1078.247937\n",
      "Iteration   38 => Loss: 1077.290881\n",
      "Iteration   39 => Loss: 1076.334261\n",
      "Iteration   40 => Loss: 1075.378080\n",
      "Iteration   41 => Loss: 1074.422336\n",
      "Iteration   42 => Loss: 1073.467030\n",
      "Iteration   43 => Loss: 1072.512161\n",
      "Iteration   44 => Loss: 1071.557730\n",
      "Iteration   45 => Loss: 1070.603737\n",
      "Iteration   46 => Loss: 1069.650181\n",
      "Iteration   47 => Loss: 1068.697063\n",
      "Iteration   48 => Loss: 1067.744382\n",
      "Iteration   49 => Loss: 1066.792139\n",
      "Iteration   50 => Loss: 1065.840333\n",
      "Iteration   51 => Loss: 1064.888965\n",
      "Iteration   52 => Loss: 1063.938035\n",
      "Iteration   53 => Loss: 1062.987543\n",
      "Iteration   54 => Loss: 1062.037487\n",
      "Iteration   55 => Loss: 1061.087870\n",
      "Iteration   56 => Loss: 1060.138690\n",
      "Iteration   57 => Loss: 1059.189948\n",
      "Iteration   58 => Loss: 1058.241643\n",
      "Iteration   59 => Loss: 1057.293776\n",
      "Iteration   60 => Loss: 1056.346347\n",
      "Iteration   61 => Loss: 1055.399355\n",
      "Iteration   62 => Loss: 1054.452801\n",
      "Iteration   63 => Loss: 1053.506684\n",
      "Iteration   64 => Loss: 1052.561005\n",
      "Iteration   65 => Loss: 1051.615763\n",
      "Iteration   66 => Loss: 1050.670959\n",
      "Iteration   67 => Loss: 1049.726593\n",
      "Iteration   68 => Loss: 1048.782665\n",
      "Iteration   69 => Loss: 1047.839173\n",
      "Iteration   70 => Loss: 1046.896120\n",
      "Iteration   71 => Loss: 1045.953504\n",
      "Iteration   72 => Loss: 1045.011326\n",
      "Iteration   73 => Loss: 1044.069585\n",
      "Iteration   74 => Loss: 1043.128282\n",
      "Iteration   75 => Loss: 1042.187417\n",
      "Iteration   76 => Loss: 1041.246989\n",
      "Iteration   77 => Loss: 1040.306999\n",
      "Iteration   78 => Loss: 1039.367446\n",
      "Iteration   79 => Loss: 1038.428331\n",
      "Iteration   80 => Loss: 1037.489653\n",
      "Iteration   81 => Loss: 1036.551413\n",
      "Iteration   82 => Loss: 1035.613611\n",
      "Iteration   83 => Loss: 1034.676247\n",
      "Iteration   84 => Loss: 1033.739319\n",
      "Iteration   85 => Loss: 1032.802830\n",
      "Iteration   86 => Loss: 1031.866778\n",
      "Iteration   87 => Loss: 1030.931164\n",
      "Iteration   88 => Loss: 1029.995987\n",
      "Iteration   89 => Loss: 1029.061248\n",
      "Iteration   90 => Loss: 1028.126947\n",
      "Iteration   91 => Loss: 1027.193083\n",
      "Iteration   92 => Loss: 1026.259657\n",
      "Iteration   93 => Loss: 1025.326668\n",
      "Iteration   94 => Loss: 1024.394117\n",
      "Iteration   95 => Loss: 1023.462003\n",
      "Iteration   96 => Loss: 1022.530327\n",
      "Iteration   97 => Loss: 1021.599089\n",
      "Iteration   98 => Loss: 1020.668289\n",
      "Iteration   99 => Loss: 1019.737925\n",
      "Iteration  100 => Loss: 1018.808000\n",
      "Iteration  101 => Loss: 1017.878512\n",
      "Iteration  102 => Loss: 1016.949462\n",
      "Iteration  103 => Loss: 1016.020849\n",
      "Iteration  104 => Loss: 1015.092674\n",
      "Iteration  105 => Loss: 1014.164937\n",
      "Iteration  106 => Loss: 1013.237637\n",
      "Iteration  107 => Loss: 1012.310775\n",
      "Iteration  108 => Loss: 1011.384350\n",
      "Iteration  109 => Loss: 1010.458363\n",
      "Iteration  110 => Loss: 1009.532813\n",
      "Iteration  111 => Loss: 1008.607701\n",
      "Iteration  112 => Loss: 1007.683027\n",
      "Iteration  113 => Loss: 1006.758791\n",
      "Iteration  114 => Loss: 1005.834991\n",
      "Iteration  115 => Loss: 1004.911630\n",
      "Iteration  116 => Loss: 1003.988706\n",
      "Iteration  117 => Loss: 1003.066220\n",
      "Iteration  118 => Loss: 1002.144171\n",
      "Iteration  119 => Loss: 1001.222560\n",
      "Iteration  120 => Loss: 1000.301387\n",
      "Iteration  121 => Loss: 999.380651\n",
      "Iteration  122 => Loss: 998.460353\n",
      "Iteration  123 => Loss: 997.540492\n",
      "Iteration  124 => Loss: 996.621069\n",
      "Iteration  125 => Loss: 995.702083\n",
      "Iteration  126 => Loss: 994.783535\n",
      "Iteration  127 => Loss: 993.865425\n",
      "Iteration  128 => Loss: 992.947753\n",
      "Iteration  129 => Loss: 992.030517\n",
      "Iteration  130 => Loss: 991.113720\n",
      "Iteration  131 => Loss: 990.197360\n",
      "Iteration  132 => Loss: 989.281438\n",
      "Iteration  133 => Loss: 988.365953\n",
      "Iteration  134 => Loss: 987.450906\n",
      "Iteration  135 => Loss: 986.536297\n",
      "Iteration  136 => Loss: 985.622125\n",
      "Iteration  137 => Loss: 984.708391\n",
      "Iteration  138 => Loss: 983.795094\n",
      "Iteration  139 => Loss: 982.882235\n",
      "Iteration  140 => Loss: 981.969813\n",
      "Iteration  141 => Loss: 981.057829\n",
      "Iteration  142 => Loss: 980.146283\n",
      "Iteration  143 => Loss: 979.235175\n",
      "Iteration  144 => Loss: 978.324503\n",
      "Iteration  145 => Loss: 977.414270\n",
      "Iteration  146 => Loss: 976.504474\n",
      "Iteration  147 => Loss: 975.595116\n",
      "Iteration  148 => Loss: 974.686195\n",
      "Iteration  149 => Loss: 973.777712\n",
      "Iteration  150 => Loss: 972.869667\n",
      "Iteration  151 => Loss: 971.962059\n",
      "Iteration  152 => Loss: 971.054889\n",
      "Iteration  153 => Loss: 970.148156\n",
      "Iteration  154 => Loss: 969.241861\n",
      "Iteration  155 => Loss: 968.336003\n",
      "Iteration  156 => Loss: 967.430583\n",
      "Iteration  157 => Loss: 966.525601\n",
      "Iteration  158 => Loss: 965.621057\n",
      "Iteration  159 => Loss: 964.716949\n",
      "Iteration  160 => Loss: 963.813280\n",
      "Iteration  161 => Loss: 962.910048\n",
      "Iteration  162 => Loss: 962.007254\n",
      "Iteration  163 => Loss: 961.104897\n",
      "Iteration  164 => Loss: 960.202978\n",
      "Iteration  165 => Loss: 959.301497\n",
      "Iteration  166 => Loss: 958.400453\n",
      "Iteration  167 => Loss: 957.499847\n",
      "Iteration  168 => Loss: 956.599678\n",
      "Iteration  169 => Loss: 955.699947\n",
      "Iteration  170 => Loss: 954.800653\n",
      "Iteration  171 => Loss: 953.901797\n",
      "Iteration  172 => Loss: 953.003379\n",
      "Iteration  173 => Loss: 952.105399\n",
      "Iteration  174 => Loss: 951.207855\n",
      "Iteration  175 => Loss: 950.310750\n",
      "Iteration  176 => Loss: 949.414082\n",
      "Iteration  177 => Loss: 948.517852\n",
      "Iteration  178 => Loss: 947.622059\n",
      "Iteration  179 => Loss: 946.726704\n",
      "Iteration  180 => Loss: 945.831787\n",
      "Iteration  181 => Loss: 944.937307\n",
      "Iteration  182 => Loss: 944.043265\n",
      "Iteration  183 => Loss: 943.149660\n",
      "Iteration  184 => Loss: 942.256493\n",
      "Iteration  185 => Loss: 941.363763\n",
      "Iteration  186 => Loss: 940.471471\n",
      "Iteration  187 => Loss: 939.579617\n",
      "Iteration  188 => Loss: 938.688201\n",
      "Iteration  189 => Loss: 937.797221\n",
      "Iteration  190 => Loss: 936.906680\n",
      "Iteration  191 => Loss: 936.016576\n",
      "Iteration  192 => Loss: 935.126910\n",
      "Iteration  193 => Loss: 934.237681\n",
      "Iteration  194 => Loss: 933.348890\n",
      "Iteration  195 => Loss: 932.460537\n",
      "Iteration  196 => Loss: 931.572621\n",
      "Iteration  197 => Loss: 930.685143\n",
      "Iteration  198 => Loss: 929.798102\n",
      "Iteration  199 => Loss: 928.911499\n",
      "Iteration  200 => Loss: 928.025333\n",
      "Iteration  201 => Loss: 927.139605\n",
      "Iteration  202 => Loss: 926.254315\n",
      "Iteration  203 => Loss: 925.369463\n",
      "Iteration  204 => Loss: 924.485047\n",
      "Iteration  205 => Loss: 923.601070\n",
      "Iteration  206 => Loss: 922.717530\n",
      "Iteration  207 => Loss: 921.834428\n",
      "Iteration  208 => Loss: 920.951763\n",
      "Iteration  209 => Loss: 920.069536\n",
      "Iteration  210 => Loss: 919.187747\n",
      "Iteration  211 => Loss: 918.306395\n",
      "Iteration  212 => Loss: 917.425481\n",
      "Iteration  213 => Loss: 916.545004\n",
      "Iteration  214 => Loss: 915.664965\n",
      "Iteration  215 => Loss: 914.785363\n",
      "Iteration  216 => Loss: 913.906199\n",
      "Iteration  217 => Loss: 913.027473\n",
      "Iteration  218 => Loss: 912.149185\n",
      "Iteration  219 => Loss: 911.271333\n",
      "Iteration  220 => Loss: 910.393920\n",
      "Iteration  221 => Loss: 909.516944\n",
      "Iteration  222 => Loss: 908.640406\n",
      "Iteration  223 => Loss: 907.764305\n",
      "Iteration  224 => Loss: 906.888642\n",
      "Iteration  225 => Loss: 906.013417\n",
      "Iteration  226 => Loss: 905.138629\n",
      "Iteration  227 => Loss: 904.264279\n",
      "Iteration  228 => Loss: 903.390366\n",
      "Iteration  229 => Loss: 902.516891\n",
      "Iteration  230 => Loss: 901.643853\n",
      "Iteration  231 => Loss: 900.771253\n",
      "Iteration  232 => Loss: 899.899091\n",
      "Iteration  233 => Loss: 899.027367\n",
      "Iteration  234 => Loss: 898.156079\n",
      "Iteration  235 => Loss: 897.285230\n",
      "Iteration  236 => Loss: 896.414818\n",
      "Iteration  237 => Loss: 895.544844\n",
      "Iteration  238 => Loss: 894.675307\n",
      "Iteration  239 => Loss: 893.806208\n",
      "Iteration  240 => Loss: 892.937547\n",
      "Iteration  241 => Loss: 892.069323\n",
      "Iteration  242 => Loss: 891.201537\n",
      "Iteration  243 => Loss: 890.334188\n",
      "Iteration  244 => Loss: 889.467277\n",
      "Iteration  245 => Loss: 888.600803\n",
      "Iteration  246 => Loss: 887.734767\n",
      "Iteration  247 => Loss: 886.869169\n",
      "Iteration  248 => Loss: 886.004009\n",
      "Iteration  249 => Loss: 885.139285\n",
      "Iteration  250 => Loss: 884.275000\n",
      "Iteration  251 => Loss: 883.411152\n",
      "Iteration  252 => Loss: 882.547742\n",
      "Iteration  253 => Loss: 881.684769\n",
      "Iteration  254 => Loss: 880.822234\n",
      "Iteration  255 => Loss: 879.960137\n",
      "Iteration  256 => Loss: 879.098477\n",
      "Iteration  257 => Loss: 878.237255\n",
      "Iteration  258 => Loss: 877.376470\n",
      "Iteration  259 => Loss: 876.516123\n",
      "Iteration  260 => Loss: 875.656213\n",
      "Iteration  261 => Loss: 874.796741\n",
      "Iteration  262 => Loss: 873.937707\n",
      "Iteration  263 => Loss: 873.079111\n",
      "Iteration  264 => Loss: 872.220951\n",
      "Iteration  265 => Loss: 871.363230\n",
      "Iteration  266 => Loss: 870.505946\n",
      "Iteration  267 => Loss: 869.649100\n",
      "Iteration  268 => Loss: 868.792691\n",
      "Iteration  269 => Loss: 867.936720\n",
      "Iteration  270 => Loss: 867.081187\n",
      "Iteration  271 => Loss: 866.226091\n",
      "Iteration  272 => Loss: 865.371433\n",
      "Iteration  273 => Loss: 864.517212\n",
      "Iteration  274 => Loss: 863.663429\n",
      "Iteration  275 => Loss: 862.810083\n",
      "Iteration  276 => Loss: 861.957175\n",
      "Iteration  277 => Loss: 861.104705\n",
      "Iteration  278 => Loss: 860.252673\n",
      "Iteration  279 => Loss: 859.401077\n",
      "Iteration  280 => Loss: 858.549920\n",
      "Iteration  281 => Loss: 857.699200\n",
      "Iteration  282 => Loss: 856.848918\n",
      "Iteration  283 => Loss: 855.999073\n",
      "Iteration  284 => Loss: 855.149666\n",
      "Iteration  285 => Loss: 854.300697\n",
      "Iteration  286 => Loss: 853.452165\n",
      "Iteration  287 => Loss: 852.604071\n",
      "Iteration  288 => Loss: 851.756414\n",
      "Iteration  289 => Loss: 850.909195\n",
      "Iteration  290 => Loss: 850.062413\n",
      "Iteration  291 => Loss: 849.216069\n",
      "Iteration  292 => Loss: 848.370163\n",
      "Iteration  293 => Loss: 847.524695\n",
      "Iteration  294 => Loss: 846.679663\n",
      "Iteration  295 => Loss: 845.835070\n",
      "Iteration  296 => Loss: 844.990914\n",
      "Iteration  297 => Loss: 844.147196\n",
      "Iteration  298 => Loss: 843.303915\n",
      "Iteration  299 => Loss: 842.461072\n",
      "Iteration  300 => Loss: 841.618667\n",
      "Iteration  301 => Loss: 840.776699\n",
      "Iteration  302 => Loss: 839.935169\n",
      "Iteration  303 => Loss: 839.094076\n",
      "Iteration  304 => Loss: 838.253421\n",
      "Iteration  305 => Loss: 837.413203\n",
      "Iteration  306 => Loss: 836.573423\n",
      "Iteration  307 => Loss: 835.734081\n",
      "Iteration  308 => Loss: 834.895177\n",
      "Iteration  309 => Loss: 834.056709\n",
      "Iteration  310 => Loss: 833.218680\n",
      "Iteration  311 => Loss: 832.381088\n",
      "Iteration  312 => Loss: 831.543934\n",
      "Iteration  313 => Loss: 830.707217\n",
      "Iteration  314 => Loss: 829.870938\n",
      "Iteration  315 => Loss: 829.035097\n",
      "Iteration  316 => Loss: 828.199693\n",
      "Iteration  317 => Loss: 827.364727\n",
      "Iteration  318 => Loss: 826.530198\n",
      "Iteration  319 => Loss: 825.696107\n",
      "Iteration  320 => Loss: 824.862453\n",
      "Iteration  321 => Loss: 824.029237\n",
      "Iteration  322 => Loss: 823.196459\n",
      "Iteration  323 => Loss: 822.364119\n",
      "Iteration  324 => Loss: 821.532215\n",
      "Iteration  325 => Loss: 820.700750\n",
      "Iteration  326 => Loss: 819.869722\n",
      "Iteration  327 => Loss: 819.039132\n",
      "Iteration  328 => Loss: 818.208979\n",
      "Iteration  329 => Loss: 817.379264\n",
      "Iteration  330 => Loss: 816.549987\n",
      "Iteration  331 => Loss: 815.721147\n",
      "Iteration  332 => Loss: 814.892745\n",
      "Iteration  333 => Loss: 814.064780\n",
      "Iteration  334 => Loss: 813.237253\n",
      "Iteration  335 => Loss: 812.410163\n",
      "Iteration  336 => Loss: 811.583511\n",
      "Iteration  337 => Loss: 810.757297\n",
      "Iteration  338 => Loss: 809.931521\n",
      "Iteration  339 => Loss: 809.106181\n",
      "Iteration  340 => Loss: 808.281280\n",
      "Iteration  341 => Loss: 807.456816\n",
      "Iteration  342 => Loss: 806.632790\n",
      "Iteration  343 => Loss: 805.809201\n",
      "Iteration  344 => Loss: 804.986050\n",
      "Iteration  345 => Loss: 804.163337\n",
      "Iteration  346 => Loss: 803.341061\n",
      "Iteration  347 => Loss: 802.519223\n",
      "Iteration  348 => Loss: 801.697822\n",
      "Iteration  349 => Loss: 800.876859\n",
      "Iteration  350 => Loss: 800.056333\n",
      "Iteration  351 => Loss: 799.236245\n",
      "Iteration  352 => Loss: 798.416595\n",
      "Iteration  353 => Loss: 797.597383\n",
      "Iteration  354 => Loss: 796.778607\n",
      "Iteration  355 => Loss: 795.960270\n",
      "Iteration  356 => Loss: 795.142370\n",
      "Iteration  357 => Loss: 794.324908\n",
      "Iteration  358 => Loss: 793.507883\n",
      "Iteration  359 => Loss: 792.691296\n",
      "Iteration  360 => Loss: 791.875147\n",
      "Iteration  361 => Loss: 791.059435\n",
      "Iteration  362 => Loss: 790.244161\n",
      "Iteration  363 => Loss: 789.429324\n",
      "Iteration  364 => Loss: 788.614925\n",
      "Iteration  365 => Loss: 787.800963\n",
      "Iteration  366 => Loss: 786.987439\n",
      "Iteration  367 => Loss: 786.174353\n",
      "Iteration  368 => Loss: 785.361705\n",
      "Iteration  369 => Loss: 784.549493\n",
      "Iteration  370 => Loss: 783.737720\n",
      "Iteration  371 => Loss: 782.926384\n",
      "Iteration  372 => Loss: 782.115486\n",
      "Iteration  373 => Loss: 781.305025\n",
      "Iteration  374 => Loss: 780.495002\n",
      "Iteration  375 => Loss: 779.685417\n",
      "Iteration  376 => Loss: 778.876269\n",
      "Iteration  377 => Loss: 778.067559\n",
      "Iteration  378 => Loss: 777.259286\n",
      "Iteration  379 => Loss: 776.451451\n",
      "Iteration  380 => Loss: 775.644053\n",
      "Iteration  381 => Loss: 774.837093\n",
      "Iteration  382 => Loss: 774.030571\n",
      "Iteration  383 => Loss: 773.224487\n",
      "Iteration  384 => Loss: 772.418839\n",
      "Iteration  385 => Loss: 771.613630\n",
      "Iteration  386 => Loss: 770.808858\n",
      "Iteration  387 => Loss: 770.004524\n",
      "Iteration  388 => Loss: 769.200627\n",
      "Iteration  389 => Loss: 768.397168\n",
      "Iteration  390 => Loss: 767.594147\n",
      "Iteration  391 => Loss: 766.791563\n",
      "Iteration  392 => Loss: 765.989417\n",
      "Iteration  393 => Loss: 765.187708\n",
      "Iteration  394 => Loss: 764.386437\n",
      "Iteration  395 => Loss: 763.585603\n",
      "Iteration  396 => Loss: 762.785207\n",
      "Iteration  397 => Loss: 761.985249\n",
      "Iteration  398 => Loss: 761.185729\n",
      "Iteration  399 => Loss: 760.386645\n",
      "Iteration  400 => Loss: 759.588000\n",
      "Iteration  401 => Loss: 758.789792\n",
      "Iteration  402 => Loss: 757.992022\n",
      "Iteration  403 => Loss: 757.194689\n",
      "Iteration  404 => Loss: 756.397794\n",
      "Iteration  405 => Loss: 755.601337\n",
      "Iteration  406 => Loss: 754.805317\n",
      "Iteration  407 => Loss: 754.009735\n",
      "Iteration  408 => Loss: 753.214590\n",
      "Iteration  409 => Loss: 752.419883\n",
      "Iteration  410 => Loss: 751.625613\n",
      "Iteration  411 => Loss: 750.831781\n",
      "Iteration  412 => Loss: 750.038387\n",
      "Iteration  413 => Loss: 749.245431\n",
      "Iteration  414 => Loss: 748.452911\n",
      "Iteration  415 => Loss: 747.660830\n",
      "Iteration  416 => Loss: 746.869186\n",
      "Iteration  417 => Loss: 746.077980\n",
      "Iteration  418 => Loss: 745.287211\n",
      "Iteration  419 => Loss: 744.496880\n",
      "Iteration  420 => Loss: 743.706987\n",
      "Iteration  421 => Loss: 742.917531\n",
      "Iteration  422 => Loss: 742.128513\n",
      "Iteration  423 => Loss: 741.339932\n",
      "Iteration  424 => Loss: 740.551789\n",
      "Iteration  425 => Loss: 739.764083\n",
      "Iteration  426 => Loss: 738.976815\n",
      "Iteration  427 => Loss: 738.189985\n",
      "Iteration  428 => Loss: 737.403593\n",
      "Iteration  429 => Loss: 736.617637\n",
      "Iteration  430 => Loss: 735.832120\n",
      "Iteration  431 => Loss: 735.047040\n",
      "Iteration  432 => Loss: 734.262398\n",
      "Iteration  433 => Loss: 733.478193\n",
      "Iteration  434 => Loss: 732.694426\n",
      "Iteration  435 => Loss: 731.911097\n",
      "Iteration  436 => Loss: 731.128205\n",
      "Iteration  437 => Loss: 730.345751\n",
      "Iteration  438 => Loss: 729.563734\n",
      "Iteration  439 => Loss: 728.782155\n",
      "Iteration  440 => Loss: 728.001013\n",
      "Iteration  441 => Loss: 727.220309\n",
      "Iteration  442 => Loss: 726.440043\n",
      "Iteration  443 => Loss: 725.660215\n",
      "Iteration  444 => Loss: 724.880823\n",
      "Iteration  445 => Loss: 724.101870\n",
      "Iteration  446 => Loss: 723.323354\n",
      "Iteration  447 => Loss: 722.545276\n",
      "Iteration  448 => Loss: 721.767635\n",
      "Iteration  449 => Loss: 720.990432\n",
      "Iteration  450 => Loss: 720.213667\n",
      "Iteration  451 => Loss: 719.437339\n",
      "Iteration  452 => Loss: 718.661449\n",
      "Iteration  453 => Loss: 717.885996\n",
      "Iteration  454 => Loss: 717.110981\n",
      "Iteration  455 => Loss: 716.336403\n",
      "Iteration  456 => Loss: 715.562263\n",
      "Iteration  457 => Loss: 714.788561\n",
      "Iteration  458 => Loss: 714.015297\n",
      "Iteration  459 => Loss: 713.242469\n",
      "Iteration  460 => Loss: 712.470080\n",
      "Iteration  461 => Loss: 711.698128\n",
      "Iteration  462 => Loss: 710.926614\n",
      "Iteration  463 => Loss: 710.155537\n",
      "Iteration  464 => Loss: 709.384898\n",
      "Iteration  465 => Loss: 708.614697\n",
      "Iteration  466 => Loss: 707.844933\n",
      "Iteration  467 => Loss: 707.075607\n",
      "Iteration  468 => Loss: 706.306718\n",
      "Iteration  469 => Loss: 705.538267\n",
      "Iteration  470 => Loss: 704.770253\n",
      "Iteration  471 => Loss: 704.002677\n",
      "Iteration  472 => Loss: 703.235539\n",
      "Iteration  473 => Loss: 702.468839\n",
      "Iteration  474 => Loss: 701.702575\n",
      "Iteration  475 => Loss: 700.936750\n",
      "Iteration  476 => Loss: 700.171362\n",
      "Iteration  477 => Loss: 699.406412\n",
      "Iteration  478 => Loss: 698.641899\n",
      "Iteration  479 => Loss: 697.877824\n",
      "Iteration  480 => Loss: 697.114187\n",
      "Iteration  481 => Loss: 696.350987\n",
      "Iteration  482 => Loss: 695.588225\n",
      "Iteration  483 => Loss: 694.825900\n",
      "Iteration  484 => Loss: 694.064013\n",
      "Iteration  485 => Loss: 693.302563\n",
      "Iteration  486 => Loss: 692.541551\n",
      "Iteration  487 => Loss: 691.780977\n",
      "Iteration  488 => Loss: 691.020841\n",
      "Iteration  489 => Loss: 690.261141\n",
      "Iteration  490 => Loss: 689.501880\n",
      "Iteration  491 => Loss: 688.743056\n",
      "Iteration  492 => Loss: 687.984670\n",
      "Iteration  493 => Loss: 687.226721\n",
      "Iteration  494 => Loss: 686.469210\n",
      "Iteration  495 => Loss: 685.712137\n",
      "Iteration  496 => Loss: 684.955501\n",
      "Iteration  497 => Loss: 684.199303\n",
      "Iteration  498 => Loss: 683.443542\n",
      "Iteration  499 => Loss: 682.688219\n",
      "Iteration  500 => Loss: 681.933333\n",
      "Iteration  501 => Loss: 681.178885\n",
      "Iteration  502 => Loss: 680.424875\n",
      "Iteration  503 => Loss: 679.671303\n",
      "Iteration  504 => Loss: 678.918167\n",
      "Iteration  505 => Loss: 678.165470\n",
      "Iteration  506 => Loss: 677.413210\n",
      "Iteration  507 => Loss: 676.661388\n",
      "Iteration  508 => Loss: 675.910003\n",
      "Iteration  509 => Loss: 675.159056\n",
      "Iteration  510 => Loss: 674.408547\n",
      "Iteration  511 => Loss: 673.658475\n",
      "Iteration  512 => Loss: 672.908841\n",
      "Iteration  513 => Loss: 672.159644\n",
      "Iteration  514 => Loss: 671.410885\n",
      "Iteration  515 => Loss: 670.662563\n",
      "Iteration  516 => Loss: 669.914679\n",
      "Iteration  517 => Loss: 669.167233\n",
      "Iteration  518 => Loss: 668.420225\n",
      "Iteration  519 => Loss: 667.673653\n",
      "Iteration  520 => Loss: 666.927520\n",
      "Iteration  521 => Loss: 666.181824\n",
      "Iteration  522 => Loss: 665.436566\n",
      "Iteration  523 => Loss: 664.691745\n",
      "Iteration  524 => Loss: 663.947362\n",
      "Iteration  525 => Loss: 663.203417\n",
      "Iteration  526 => Loss: 662.459909\n",
      "Iteration  527 => Loss: 661.716839\n",
      "Iteration  528 => Loss: 660.974206\n",
      "Iteration  529 => Loss: 660.232011\n",
      "Iteration  530 => Loss: 659.490253\n",
      "Iteration  531 => Loss: 658.748933\n",
      "Iteration  532 => Loss: 658.008051\n",
      "Iteration  533 => Loss: 657.267607\n",
      "Iteration  534 => Loss: 656.527599\n",
      "Iteration  535 => Loss: 655.788030\n",
      "Iteration  536 => Loss: 655.048898\n",
      "Iteration  537 => Loss: 654.310204\n",
      "Iteration  538 => Loss: 653.571947\n",
      "Iteration  539 => Loss: 652.834128\n",
      "Iteration  540 => Loss: 652.096747\n",
      "Iteration  541 => Loss: 651.359803\n",
      "Iteration  542 => Loss: 650.623297\n",
      "Iteration  543 => Loss: 649.887228\n",
      "Iteration  544 => Loss: 649.151597\n",
      "Iteration  545 => Loss: 648.416403\n",
      "Iteration  546 => Loss: 647.681647\n",
      "Iteration  547 => Loss: 646.947329\n",
      "Iteration  548 => Loss: 646.213449\n",
      "Iteration  549 => Loss: 645.480005\n",
      "Iteration  550 => Loss: 644.747000\n",
      "Iteration  551 => Loss: 644.014432\n",
      "Iteration  552 => Loss: 643.282302\n",
      "Iteration  553 => Loss: 642.550609\n",
      "Iteration  554 => Loss: 641.819354\n",
      "Iteration  555 => Loss: 641.088537\n",
      "Iteration  556 => Loss: 640.358157\n",
      "Iteration  557 => Loss: 639.628215\n",
      "Iteration  558 => Loss: 638.898710\n",
      "Iteration  559 => Loss: 638.169643\n",
      "Iteration  560 => Loss: 637.441013\n",
      "Iteration  561 => Loss: 636.712821\n",
      "Iteration  562 => Loss: 635.985067\n",
      "Iteration  563 => Loss: 635.257751\n",
      "Iteration  564 => Loss: 634.530871\n",
      "Iteration  565 => Loss: 633.804430\n",
      "Iteration  566 => Loss: 633.078426\n",
      "Iteration  567 => Loss: 632.352860\n",
      "Iteration  568 => Loss: 631.627731\n",
      "Iteration  569 => Loss: 630.903040\n",
      "Iteration  570 => Loss: 630.178787\n",
      "Iteration  571 => Loss: 629.454971\n",
      "Iteration  572 => Loss: 628.731593\n",
      "Iteration  573 => Loss: 628.008652\n",
      "Iteration  574 => Loss: 627.286149\n",
      "Iteration  575 => Loss: 626.564083\n",
      "Iteration  576 => Loss: 625.842455\n",
      "Iteration  577 => Loss: 625.121265\n",
      "Iteration  578 => Loss: 624.400513\n",
      "Iteration  579 => Loss: 623.680197\n",
      "Iteration  580 => Loss: 622.960320\n",
      "Iteration  581 => Loss: 622.240880\n",
      "Iteration  582 => Loss: 621.521878\n",
      "Iteration  583 => Loss: 620.803313\n",
      "Iteration  584 => Loss: 620.085186\n",
      "Iteration  585 => Loss: 619.367497\n",
      "Iteration  586 => Loss: 618.650245\n",
      "Iteration  587 => Loss: 617.933431\n",
      "Iteration  588 => Loss: 617.217054\n",
      "Iteration  589 => Loss: 616.501115\n",
      "Iteration  590 => Loss: 615.785613\n",
      "Iteration  591 => Loss: 615.070549\n",
      "Iteration  592 => Loss: 614.355923\n",
      "Iteration  593 => Loss: 613.641735\n",
      "Iteration  594 => Loss: 612.927983\n",
      "Iteration  595 => Loss: 612.214670\n",
      "Iteration  596 => Loss: 611.501794\n",
      "Iteration  597 => Loss: 610.789356\n",
      "Iteration  598 => Loss: 610.077355\n",
      "Iteration  599 => Loss: 609.365792\n",
      "Iteration  600 => Loss: 608.654667\n",
      "Iteration  601 => Loss: 607.943979\n",
      "Iteration  602 => Loss: 607.233729\n",
      "Iteration  603 => Loss: 606.523916\n",
      "Iteration  604 => Loss: 605.814541\n",
      "Iteration  605 => Loss: 605.105603\n",
      "Iteration  606 => Loss: 604.397103\n",
      "Iteration  607 => Loss: 603.689041\n",
      "Iteration  608 => Loss: 602.981417\n",
      "Iteration  609 => Loss: 602.274229\n",
      "Iteration  610 => Loss: 601.567480\n",
      "Iteration  611 => Loss: 600.861168\n",
      "Iteration  612 => Loss: 600.155294\n",
      "Iteration  613 => Loss: 599.449857\n",
      "Iteration  614 => Loss: 598.744858\n",
      "Iteration  615 => Loss: 598.040297\n",
      "Iteration  616 => Loss: 597.336173\n",
      "Iteration  617 => Loss: 596.632487\n",
      "Iteration  618 => Loss: 595.929238\n",
      "Iteration  619 => Loss: 595.226427\n",
      "Iteration  620 => Loss: 594.524053\n",
      "Iteration  621 => Loss: 593.822117\n",
      "Iteration  622 => Loss: 593.120619\n",
      "Iteration  623 => Loss: 592.419559\n",
      "Iteration  624 => Loss: 591.718935\n",
      "Iteration  625 => Loss: 591.018750\n",
      "Iteration  626 => Loss: 590.319002\n",
      "Iteration  627 => Loss: 589.619692\n",
      "Iteration  628 => Loss: 588.920819\n",
      "Iteration  629 => Loss: 588.222384\n",
      "Iteration  630 => Loss: 587.524387\n",
      "Iteration  631 => Loss: 586.826827\n",
      "Iteration  632 => Loss: 586.129705\n",
      "Iteration  633 => Loss: 585.433020\n",
      "Iteration  634 => Loss: 584.736773\n",
      "Iteration  635 => Loss: 584.040963\n",
      "Iteration  636 => Loss: 583.345591\n",
      "Iteration  637 => Loss: 582.650657\n",
      "Iteration  638 => Loss: 581.956161\n",
      "Iteration  639 => Loss: 581.262101\n",
      "Iteration  640 => Loss: 580.568480\n",
      "Iteration  641 => Loss: 579.875296\n",
      "Iteration  642 => Loss: 579.182550\n",
      "Iteration  643 => Loss: 578.490241\n",
      "Iteration  644 => Loss: 577.798370\n",
      "Iteration  645 => Loss: 577.106937\n",
      "Iteration  646 => Loss: 576.415941\n",
      "Iteration  647 => Loss: 575.725383\n",
      "Iteration  648 => Loss: 575.035262\n",
      "Iteration  649 => Loss: 574.345579\n",
      "Iteration  650 => Loss: 573.656333\n",
      "Iteration  651 => Loss: 572.967525\n",
      "Iteration  652 => Loss: 572.279155\n",
      "Iteration  653 => Loss: 571.591223\n",
      "Iteration  654 => Loss: 570.903727\n",
      "Iteration  655 => Loss: 570.216670\n",
      "Iteration  656 => Loss: 569.530050\n",
      "Iteration  657 => Loss: 568.843868\n",
      "Iteration  658 => Loss: 568.158123\n",
      "Iteration  659 => Loss: 567.472816\n",
      "Iteration  660 => Loss: 566.787947\n",
      "Iteration  661 => Loss: 566.103515\n",
      "Iteration  662 => Loss: 565.419521\n",
      "Iteration  663 => Loss: 564.735964\n",
      "Iteration  664 => Loss: 564.052845\n",
      "Iteration  665 => Loss: 563.370163\n",
      "Iteration  666 => Loss: 562.687919\n",
      "Iteration  667 => Loss: 562.006113\n",
      "Iteration  668 => Loss: 561.324745\n",
      "Iteration  669 => Loss: 560.643813\n",
      "Iteration  670 => Loss: 559.963320\n",
      "Iteration  671 => Loss: 559.283264\n",
      "Iteration  672 => Loss: 558.603646\n",
      "Iteration  673 => Loss: 557.924465\n",
      "Iteration  674 => Loss: 557.245722\n",
      "Iteration  675 => Loss: 556.567417\n",
      "Iteration  676 => Loss: 555.889549\n",
      "Iteration  677 => Loss: 555.212119\n",
      "Iteration  678 => Loss: 554.535126\n",
      "Iteration  679 => Loss: 553.858571\n",
      "Iteration  680 => Loss: 553.182453\n",
      "Iteration  681 => Loss: 552.506773\n",
      "Iteration  682 => Loss: 551.831531\n",
      "Iteration  683 => Loss: 551.156727\n",
      "Iteration  684 => Loss: 550.482359\n",
      "Iteration  685 => Loss: 549.808430\n",
      "Iteration  686 => Loss: 549.134938\n",
      "Iteration  687 => Loss: 548.461884\n",
      "Iteration  688 => Loss: 547.789267\n",
      "Iteration  689 => Loss: 547.117088\n",
      "Iteration  690 => Loss: 546.445347\n",
      "Iteration  691 => Loss: 545.774043\n",
      "Iteration  692 => Loss: 545.103177\n",
      "Iteration  693 => Loss: 544.432748\n",
      "Iteration  694 => Loss: 543.762757\n",
      "Iteration  695 => Loss: 543.093203\n",
      "Iteration  696 => Loss: 542.424087\n",
      "Iteration  697 => Loss: 541.755409\n",
      "Iteration  698 => Loss: 541.087169\n",
      "Iteration  699 => Loss: 540.419365\n",
      "Iteration  700 => Loss: 539.752000\n",
      "Iteration  701 => Loss: 539.085072\n",
      "Iteration  702 => Loss: 538.418582\n",
      "Iteration  703 => Loss: 537.752529\n",
      "Iteration  704 => Loss: 537.086914\n",
      "Iteration  705 => Loss: 536.421737\n",
      "Iteration  706 => Loss: 535.756997\n",
      "Iteration  707 => Loss: 535.092695\n",
      "Iteration  708 => Loss: 534.428830\n",
      "Iteration  709 => Loss: 533.765403\n",
      "Iteration  710 => Loss: 533.102413\n",
      "Iteration  711 => Loss: 532.439861\n",
      "Iteration  712 => Loss: 531.777747\n",
      "Iteration  713 => Loss: 531.116071\n",
      "Iteration  714 => Loss: 530.454831\n",
      "Iteration  715 => Loss: 529.794030\n",
      "Iteration  716 => Loss: 529.133666\n",
      "Iteration  717 => Loss: 528.473740\n",
      "Iteration  718 => Loss: 527.814251\n",
      "Iteration  719 => Loss: 527.155200\n",
      "Iteration  720 => Loss: 526.496587\n",
      "Iteration  721 => Loss: 525.838411\n",
      "Iteration  722 => Loss: 525.180673\n",
      "Iteration  723 => Loss: 524.523372\n",
      "Iteration  724 => Loss: 523.866509\n",
      "Iteration  725 => Loss: 523.210083\n",
      "Iteration  726 => Loss: 522.554095\n",
      "Iteration  727 => Loss: 521.898545\n",
      "Iteration  728 => Loss: 521.243433\n",
      "Iteration  729 => Loss: 520.588757\n",
      "Iteration  730 => Loss: 519.934520\n",
      "Iteration  731 => Loss: 519.280720\n",
      "Iteration  732 => Loss: 518.627358\n",
      "Iteration  733 => Loss: 517.974433\n",
      "Iteration  734 => Loss: 517.321946\n",
      "Iteration  735 => Loss: 516.669897\n",
      "Iteration  736 => Loss: 516.018285\n",
      "Iteration  737 => Loss: 515.367111\n",
      "Iteration  738 => Loss: 514.716374\n",
      "Iteration  739 => Loss: 514.066075\n",
      "Iteration  740 => Loss: 513.416213\n",
      "Iteration  741 => Loss: 512.766789\n",
      "Iteration  742 => Loss: 512.117803\n",
      "Iteration  743 => Loss: 511.469255\n",
      "Iteration  744 => Loss: 510.821143\n",
      "Iteration  745 => Loss: 510.173470\n",
      "Iteration  746 => Loss: 509.526234\n",
      "Iteration  747 => Loss: 508.879436\n",
      "Iteration  748 => Loss: 508.233075\n",
      "Iteration  749 => Loss: 507.587152\n",
      "Iteration  750 => Loss: 506.941667\n",
      "Iteration  751 => Loss: 506.296619\n",
      "Iteration  752 => Loss: 505.652009\n",
      "Iteration  753 => Loss: 505.007836\n",
      "Iteration  754 => Loss: 504.364101\n",
      "Iteration  755 => Loss: 503.720803\n",
      "Iteration  756 => Loss: 503.077943\n",
      "Iteration  757 => Loss: 502.435521\n",
      "Iteration  758 => Loss: 501.793537\n",
      "Iteration  759 => Loss: 501.151989\n",
      "Iteration  760 => Loss: 500.510880\n",
      "Iteration  761 => Loss: 499.870208\n",
      "Iteration  762 => Loss: 499.229974\n",
      "Iteration  763 => Loss: 498.590177\n",
      "Iteration  764 => Loss: 497.950818\n",
      "Iteration  765 => Loss: 497.311897\n",
      "Iteration  766 => Loss: 496.673413\n",
      "Iteration  767 => Loss: 496.035367\n",
      "Iteration  768 => Loss: 495.397758\n",
      "Iteration  769 => Loss: 494.760587\n",
      "Iteration  770 => Loss: 494.123853\n",
      "Iteration  771 => Loss: 493.487557\n",
      "Iteration  772 => Loss: 492.851699\n",
      "Iteration  773 => Loss: 492.216279\n",
      "Iteration  774 => Loss: 491.581295\n",
      "Iteration  775 => Loss: 490.946750\n",
      "Iteration  776 => Loss: 490.312642\n",
      "Iteration  777 => Loss: 489.678972\n",
      "Iteration  778 => Loss: 489.045739\n",
      "Iteration  779 => Loss: 488.412944\n",
      "Iteration  780 => Loss: 487.780587\n",
      "Iteration  781 => Loss: 487.148667\n",
      "Iteration  782 => Loss: 486.517185\n",
      "Iteration  783 => Loss: 485.886140\n",
      "Iteration  784 => Loss: 485.255533\n",
      "Iteration  785 => Loss: 484.625363\n",
      "Iteration  786 => Loss: 483.995631\n",
      "Iteration  787 => Loss: 483.366337\n",
      "Iteration  788 => Loss: 482.737481\n",
      "Iteration  789 => Loss: 482.109061\n",
      "Iteration  790 => Loss: 481.481080\n",
      "Iteration  791 => Loss: 480.853536\n",
      "Iteration  792 => Loss: 480.226430\n",
      "Iteration  793 => Loss: 479.599761\n",
      "Iteration  794 => Loss: 478.973530\n",
      "Iteration  795 => Loss: 478.347737\n",
      "Iteration  796 => Loss: 477.722381\n",
      "Iteration  797 => Loss: 477.097463\n",
      "Iteration  798 => Loss: 476.472982\n",
      "Iteration  799 => Loss: 475.848939\n",
      "Iteration  800 => Loss: 475.225333\n",
      "Iteration  801 => Loss: 474.602165\n",
      "Iteration  802 => Loss: 473.979435\n",
      "Iteration  803 => Loss: 473.357143\n",
      "Iteration  804 => Loss: 472.735287\n",
      "Iteration  805 => Loss: 472.113870\n",
      "Iteration  806 => Loss: 471.492890\n",
      "Iteration  807 => Loss: 470.872348\n",
      "Iteration  808 => Loss: 470.252243\n",
      "Iteration  809 => Loss: 469.632576\n",
      "Iteration  810 => Loss: 469.013347\n",
      "Iteration  811 => Loss: 468.394555\n",
      "Iteration  812 => Loss: 467.776201\n",
      "Iteration  813 => Loss: 467.158284\n",
      "Iteration  814 => Loss: 466.540805\n",
      "Iteration  815 => Loss: 465.923763\n",
      "Iteration  816 => Loss: 465.307159\n",
      "Iteration  817 => Loss: 464.690993\n",
      "Iteration  818 => Loss: 464.075265\n",
      "Iteration  819 => Loss: 463.459973\n",
      "Iteration  820 => Loss: 462.845120\n",
      "Iteration  821 => Loss: 462.230704\n",
      "Iteration  822 => Loss: 461.616726\n",
      "Iteration  823 => Loss: 461.003185\n",
      "Iteration  824 => Loss: 460.390082\n",
      "Iteration  825 => Loss: 459.777417\n",
      "Iteration  826 => Loss: 459.165189\n",
      "Iteration  827 => Loss: 458.553399\n",
      "Iteration  828 => Loss: 457.942046\n",
      "Iteration  829 => Loss: 457.331131\n",
      "Iteration  830 => Loss: 456.720653\n",
      "Iteration  831 => Loss: 456.110613\n",
      "Iteration  832 => Loss: 455.501011\n",
      "Iteration  833 => Loss: 454.891847\n",
      "Iteration  834 => Loss: 454.283119\n",
      "Iteration  835 => Loss: 453.674830\n",
      "Iteration  836 => Loss: 453.066978\n",
      "Iteration  837 => Loss: 452.459564\n",
      "Iteration  838 => Loss: 451.852587\n",
      "Iteration  839 => Loss: 451.246048\n",
      "Iteration  840 => Loss: 450.639947\n",
      "Iteration  841 => Loss: 450.034283\n",
      "Iteration  842 => Loss: 449.429057\n",
      "Iteration  843 => Loss: 448.824268\n",
      "Iteration  844 => Loss: 448.219917\n",
      "Iteration  845 => Loss: 447.616003\n",
      "Iteration  846 => Loss: 447.012527\n",
      "Iteration  847 => Loss: 446.409489\n",
      "Iteration  848 => Loss: 445.806889\n",
      "Iteration  849 => Loss: 445.204725\n",
      "Iteration  850 => Loss: 444.603000\n",
      "Iteration  851 => Loss: 444.001712\n",
      "Iteration  852 => Loss: 443.400862\n",
      "Iteration  853 => Loss: 442.800449\n",
      "Iteration  854 => Loss: 442.200474\n",
      "Iteration  855 => Loss: 441.600937\n",
      "Iteration  856 => Loss: 441.001837\n",
      "Iteration  857 => Loss: 440.403175\n",
      "Iteration  858 => Loss: 439.804950\n",
      "Iteration  859 => Loss: 439.207163\n",
      "Iteration  860 => Loss: 438.609813\n",
      "Iteration  861 => Loss: 438.012901\n",
      "Iteration  862 => Loss: 437.416427\n",
      "Iteration  863 => Loss: 436.820391\n",
      "Iteration  864 => Loss: 436.224791\n",
      "Iteration  865 => Loss: 435.629630\n",
      "Iteration  866 => Loss: 435.034906\n",
      "Iteration  867 => Loss: 434.440620\n",
      "Iteration  868 => Loss: 433.846771\n",
      "Iteration  869 => Loss: 433.253360\n",
      "Iteration  870 => Loss: 432.660387\n",
      "Iteration  871 => Loss: 432.067851\n",
      "Iteration  872 => Loss: 431.475753\n",
      "Iteration  873 => Loss: 430.884092\n",
      "Iteration  874 => Loss: 430.292869\n",
      "Iteration  875 => Loss: 429.702083\n",
      "Iteration  876 => Loss: 429.111735\n",
      "Iteration  877 => Loss: 428.521825\n",
      "Iteration  878 => Loss: 427.932353\n",
      "Iteration  879 => Loss: 427.343317\n",
      "Iteration  880 => Loss: 426.754720\n",
      "Iteration  881 => Loss: 426.166560\n",
      "Iteration  882 => Loss: 425.578838\n",
      "Iteration  883 => Loss: 424.991553\n",
      "Iteration  884 => Loss: 424.404706\n",
      "Iteration  885 => Loss: 423.818297\n",
      "Iteration  886 => Loss: 423.232325\n",
      "Iteration  887 => Loss: 422.646791\n",
      "Iteration  888 => Loss: 422.061694\n",
      "Iteration  889 => Loss: 421.477035\n",
      "Iteration  890 => Loss: 420.892813\n",
      "Iteration  891 => Loss: 420.309029\n",
      "Iteration  892 => Loss: 419.725683\n",
      "Iteration  893 => Loss: 419.142775\n",
      "Iteration  894 => Loss: 418.560303\n",
      "Iteration  895 => Loss: 417.978270\n",
      "Iteration  896 => Loss: 417.396674\n",
      "Iteration  897 => Loss: 416.815516\n",
      "Iteration  898 => Loss: 416.234795\n",
      "Iteration  899 => Loss: 415.654512\n",
      "Iteration  900 => Loss: 415.074667\n",
      "Iteration  901 => Loss: 414.495259\n",
      "Iteration  902 => Loss: 413.916289\n",
      "Iteration  903 => Loss: 413.337756\n",
      "Iteration  904 => Loss: 412.759661\n",
      "Iteration  905 => Loss: 412.182003\n",
      "Iteration  906 => Loss: 411.604783\n",
      "Iteration  907 => Loss: 411.028001\n",
      "Iteration  908 => Loss: 410.451657\n",
      "Iteration  909 => Loss: 409.875749\n",
      "Iteration  910 => Loss: 409.300280\n",
      "Iteration  911 => Loss: 408.725248\n",
      "Iteration  912 => Loss: 408.150654\n",
      "Iteration  913 => Loss: 407.576497\n",
      "Iteration  914 => Loss: 407.002778\n",
      "Iteration  915 => Loss: 406.429497\n",
      "Iteration  916 => Loss: 405.856653\n",
      "Iteration  917 => Loss: 405.284247\n",
      "Iteration  918 => Loss: 404.712278\n",
      "Iteration  919 => Loss: 404.140747\n",
      "Iteration  920 => Loss: 403.569653\n",
      "Iteration  921 => Loss: 402.998997\n",
      "Iteration  922 => Loss: 402.428779\n",
      "Iteration  923 => Loss: 401.858999\n",
      "Iteration  924 => Loss: 401.289655\n",
      "Iteration  925 => Loss: 400.720750\n",
      "Iteration  926 => Loss: 400.152282\n",
      "Iteration  927 => Loss: 399.584252\n",
      "Iteration  928 => Loss: 399.016659\n",
      "Iteration  929 => Loss: 398.449504\n",
      "Iteration  930 => Loss: 397.882787\n",
      "Iteration  931 => Loss: 397.316507\n",
      "Iteration  932 => Loss: 396.750665\n",
      "Iteration  933 => Loss: 396.185260\n",
      "Iteration  934 => Loss: 395.620293\n",
      "Iteration  935 => Loss: 395.055763\n",
      "Iteration  936 => Loss: 394.491671\n",
      "Iteration  937 => Loss: 393.928017\n",
      "Iteration  938 => Loss: 393.364801\n",
      "Iteration  939 => Loss: 392.802021\n",
      "Iteration  940 => Loss: 392.239680\n",
      "Iteration  941 => Loss: 391.677776\n",
      "Iteration  942 => Loss: 391.116310\n",
      "Iteration  943 => Loss: 390.555281\n",
      "Iteration  944 => Loss: 389.994690\n",
      "Iteration  945 => Loss: 389.434537\n",
      "Iteration  946 => Loss: 388.874821\n",
      "Iteration  947 => Loss: 388.315543\n",
      "Iteration  948 => Loss: 387.756702\n",
      "Iteration  949 => Loss: 387.198299\n",
      "Iteration  950 => Loss: 386.640333\n",
      "Iteration  951 => Loss: 386.082805\n",
      "Iteration  952 => Loss: 385.525715\n",
      "Iteration  953 => Loss: 384.969063\n",
      "Iteration  954 => Loss: 384.412847\n",
      "Iteration  955 => Loss: 383.857070\n",
      "Iteration  956 => Loss: 383.301730\n",
      "Iteration  957 => Loss: 382.746828\n",
      "Iteration  958 => Loss: 382.192363\n",
      "Iteration  959 => Loss: 381.638336\n",
      "Iteration  960 => Loss: 381.084747\n",
      "Iteration  961 => Loss: 380.531595\n",
      "Iteration  962 => Loss: 379.978881\n",
      "Iteration  963 => Loss: 379.426604\n",
      "Iteration  964 => Loss: 378.874765\n",
      "Iteration  965 => Loss: 378.323363\n",
      "Iteration  966 => Loss: 377.772399\n",
      "Iteration  967 => Loss: 377.221873\n",
      "Iteration  968 => Loss: 376.671785\n",
      "Iteration  969 => Loss: 376.122133\n",
      "Iteration  970 => Loss: 375.572920\n",
      "Iteration  971 => Loss: 375.024144\n",
      "Iteration  972 => Loss: 374.475806\n",
      "Iteration  973 => Loss: 373.927905\n",
      "Iteration  974 => Loss: 373.380442\n",
      "Iteration  975 => Loss: 372.833417\n",
      "Iteration  976 => Loss: 372.286829\n",
      "Iteration  977 => Loss: 371.740679\n",
      "Iteration  978 => Loss: 371.194966\n",
      "Iteration  979 => Loss: 370.649691\n",
      "Iteration  980 => Loss: 370.104853\n",
      "Iteration  981 => Loss: 369.560453\n",
      "Iteration  982 => Loss: 369.016491\n",
      "Iteration  983 => Loss: 368.472967\n",
      "Iteration  984 => Loss: 367.929879\n",
      "Iteration  985 => Loss: 367.387230\n",
      "Iteration  986 => Loss: 366.845018\n",
      "Iteration  987 => Loss: 366.303244\n",
      "Iteration  988 => Loss: 365.761907\n",
      "Iteration  989 => Loss: 365.221008\n",
      "Iteration  990 => Loss: 364.680547\n",
      "Iteration  991 => Loss: 364.140523\n",
      "Iteration  992 => Loss: 363.600937\n",
      "Iteration  993 => Loss: 363.061788\n",
      "Iteration  994 => Loss: 362.523077\n",
      "Iteration  995 => Loss: 361.984803\n",
      "Iteration  996 => Loss: 361.446967\n",
      "Iteration  997 => Loss: 360.909569\n",
      "Iteration  998 => Loss: 360.372609\n",
      "Iteration  999 => Loss: 359.836085\n",
      "Iteration 1000 => Loss: 359.300000\n",
      "Iteration 1001 => Loss: 358.764352\n",
      "Iteration 1002 => Loss: 358.229142\n",
      "Iteration 1003 => Loss: 357.694369\n",
      "Iteration 1004 => Loss: 357.160034\n",
      "Iteration 1005 => Loss: 356.626137\n",
      "Iteration 1006 => Loss: 356.092677\n",
      "Iteration 1007 => Loss: 355.559655\n",
      "Iteration 1008 => Loss: 355.027070\n",
      "Iteration 1009 => Loss: 354.494923\n",
      "Iteration 1010 => Loss: 353.963213\n",
      "Iteration 1011 => Loss: 353.431941\n",
      "Iteration 1012 => Loss: 352.901107\n",
      "Iteration 1013 => Loss: 352.370711\n",
      "Iteration 1014 => Loss: 351.840751\n",
      "Iteration 1015 => Loss: 351.311230\n",
      "Iteration 1016 => Loss: 350.782146\n",
      "Iteration 1017 => Loss: 350.253500\n",
      "Iteration 1018 => Loss: 349.725291\n",
      "Iteration 1019 => Loss: 349.197520\n",
      "Iteration 1020 => Loss: 348.670187\n",
      "Iteration 1021 => Loss: 348.143291\n",
      "Iteration 1022 => Loss: 347.616833\n",
      "Iteration 1023 => Loss: 347.090812\n",
      "Iteration 1024 => Loss: 346.565229\n",
      "Iteration 1025 => Loss: 346.040083\n",
      "Iteration 1026 => Loss: 345.515375\n",
      "Iteration 1027 => Loss: 344.991105\n",
      "Iteration 1028 => Loss: 344.467273\n",
      "Iteration 1029 => Loss: 343.943877\n",
      "Iteration 1030 => Loss: 343.420920\n",
      "Iteration 1031 => Loss: 342.898400\n",
      "Iteration 1032 => Loss: 342.376318\n",
      "Iteration 1033 => Loss: 341.854673\n",
      "Iteration 1034 => Loss: 341.333466\n",
      "Iteration 1035 => Loss: 340.812697\n",
      "Iteration 1036 => Loss: 340.292365\n",
      "Iteration 1037 => Loss: 339.772471\n",
      "Iteration 1038 => Loss: 339.253014\n",
      "Iteration 1039 => Loss: 338.733995\n",
      "Iteration 1040 => Loss: 338.215413\n",
      "Iteration 1041 => Loss: 337.697269\n",
      "Iteration 1042 => Loss: 337.179563\n",
      "Iteration 1043 => Loss: 336.662295\n",
      "Iteration 1044 => Loss: 336.145463\n",
      "Iteration 1045 => Loss: 335.629070\n",
      "Iteration 1046 => Loss: 335.113114\n",
      "Iteration 1047 => Loss: 334.597596\n",
      "Iteration 1048 => Loss: 334.082515\n",
      "Iteration 1049 => Loss: 333.567872\n",
      "Iteration 1050 => Loss: 333.053667\n",
      "Iteration 1051 => Loss: 332.539899\n",
      "Iteration 1052 => Loss: 332.026569\n",
      "Iteration 1053 => Loss: 331.513676\n",
      "Iteration 1054 => Loss: 331.001221\n",
      "Iteration 1055 => Loss: 330.489203\n",
      "Iteration 1056 => Loss: 329.977623\n",
      "Iteration 1057 => Loss: 329.466481\n",
      "Iteration 1058 => Loss: 328.955777\n",
      "Iteration 1059 => Loss: 328.445509\n",
      "Iteration 1060 => Loss: 327.935680\n",
      "Iteration 1061 => Loss: 327.426288\n",
      "Iteration 1062 => Loss: 326.917334\n",
      "Iteration 1063 => Loss: 326.408817\n",
      "Iteration 1064 => Loss: 325.900738\n",
      "Iteration 1065 => Loss: 325.393097\n",
      "Iteration 1066 => Loss: 324.885893\n",
      "Iteration 1067 => Loss: 324.379127\n",
      "Iteration 1068 => Loss: 323.872798\n",
      "Iteration 1069 => Loss: 323.366907\n",
      "Iteration 1070 => Loss: 322.861453\n",
      "Iteration 1071 => Loss: 322.356437\n",
      "Iteration 1072 => Loss: 321.851859\n",
      "Iteration 1073 => Loss: 321.347719\n",
      "Iteration 1074 => Loss: 320.844015\n",
      "Iteration 1075 => Loss: 320.340750\n",
      "Iteration 1076 => Loss: 319.837922\n",
      "Iteration 1077 => Loss: 319.335532\n",
      "Iteration 1078 => Loss: 318.833579\n",
      "Iteration 1079 => Loss: 318.332064\n",
      "Iteration 1080 => Loss: 317.830987\n",
      "Iteration 1081 => Loss: 317.330347\n",
      "Iteration 1082 => Loss: 316.830145\n",
      "Iteration 1083 => Loss: 316.330380\n",
      "Iteration 1084 => Loss: 315.831053\n",
      "Iteration 1085 => Loss: 315.332163\n",
      "Iteration 1086 => Loss: 314.833711\n",
      "Iteration 1087 => Loss: 314.335697\n",
      "Iteration 1088 => Loss: 313.838121\n",
      "Iteration 1089 => Loss: 313.340981\n",
      "Iteration 1090 => Loss: 312.844280\n",
      "Iteration 1091 => Loss: 312.348016\n",
      "Iteration 1092 => Loss: 311.852190\n",
      "Iteration 1093 => Loss: 311.356801\n",
      "Iteration 1094 => Loss: 310.861850\n",
      "Iteration 1095 => Loss: 310.367337\n",
      "Iteration 1096 => Loss: 309.873261\n",
      "Iteration 1097 => Loss: 309.379623\n",
      "Iteration 1098 => Loss: 308.886422\n",
      "Iteration 1099 => Loss: 308.393659\n",
      "Iteration 1100 => Loss: 307.901333\n",
      "Iteration 1101 => Loss: 307.409445\n",
      "Iteration 1102 => Loss: 306.917995\n",
      "Iteration 1103 => Loss: 306.426983\n",
      "Iteration 1104 => Loss: 305.936407\n",
      "Iteration 1105 => Loss: 305.446270\n",
      "Iteration 1106 => Loss: 304.956570\n",
      "Iteration 1107 => Loss: 304.467308\n",
      "Iteration 1108 => Loss: 303.978483\n",
      "Iteration 1109 => Loss: 303.490096\n",
      "Iteration 1110 => Loss: 303.002147\n",
      "Iteration 1111 => Loss: 302.514635\n",
      "Iteration 1112 => Loss: 302.027561\n",
      "Iteration 1113 => Loss: 301.540924\n",
      "Iteration 1114 => Loss: 301.054725\n",
      "Iteration 1115 => Loss: 300.568963\n",
      "Iteration 1116 => Loss: 300.083639\n",
      "Iteration 1117 => Loss: 299.598753\n",
      "Iteration 1118 => Loss: 299.114305\n",
      "Iteration 1119 => Loss: 298.630293\n",
      "Iteration 1120 => Loss: 298.146720\n",
      "Iteration 1121 => Loss: 297.663584\n",
      "Iteration 1122 => Loss: 297.180886\n",
      "Iteration 1123 => Loss: 296.698625\n",
      "Iteration 1124 => Loss: 296.216802\n",
      "Iteration 1125 => Loss: 295.735417\n",
      "Iteration 1126 => Loss: 295.254469\n",
      "Iteration 1127 => Loss: 294.773959\n",
      "Iteration 1128 => Loss: 294.293886\n",
      "Iteration 1129 => Loss: 293.814251\n",
      "Iteration 1130 => Loss: 293.335053\n",
      "Iteration 1131 => Loss: 292.856293\n",
      "Iteration 1132 => Loss: 292.377971\n",
      "Iteration 1133 => Loss: 291.900087\n",
      "Iteration 1134 => Loss: 291.422639\n",
      "Iteration 1135 => Loss: 290.945630\n",
      "Iteration 1136 => Loss: 290.469058\n",
      "Iteration 1137 => Loss: 289.992924\n",
      "Iteration 1138 => Loss: 289.517227\n",
      "Iteration 1139 => Loss: 289.041968\n",
      "Iteration 1140 => Loss: 288.567147\n",
      "Iteration 1141 => Loss: 288.092763\n",
      "Iteration 1142 => Loss: 287.618817\n",
      "Iteration 1143 => Loss: 287.145308\n",
      "Iteration 1144 => Loss: 286.672237\n",
      "Iteration 1145 => Loss: 286.199603\n",
      "Iteration 1146 => Loss: 285.727407\n",
      "Iteration 1147 => Loss: 285.255649\n",
      "Iteration 1148 => Loss: 284.784329\n",
      "Iteration 1149 => Loss: 284.313445\n",
      "Iteration 1150 => Loss: 283.843000\n",
      "Iteration 1151 => Loss: 283.372992\n",
      "Iteration 1152 => Loss: 282.903422\n",
      "Iteration 1153 => Loss: 282.434289\n",
      "Iteration 1154 => Loss: 281.965594\n",
      "Iteration 1155 => Loss: 281.497337\n",
      "Iteration 1156 => Loss: 281.029517\n",
      "Iteration 1157 => Loss: 280.562135\n",
      "Iteration 1158 => Loss: 280.095190\n",
      "Iteration 1159 => Loss: 279.628683\n",
      "Iteration 1160 => Loss: 279.162613\n",
      "Iteration 1161 => Loss: 278.696981\n",
      "Iteration 1162 => Loss: 278.231787\n",
      "Iteration 1163 => Loss: 277.767031\n",
      "Iteration 1164 => Loss: 277.302711\n",
      "Iteration 1165 => Loss: 276.838830\n",
      "Iteration 1166 => Loss: 276.375386\n",
      "Iteration 1167 => Loss: 275.912380\n",
      "Iteration 1168 => Loss: 275.449811\n",
      "Iteration 1169 => Loss: 274.987680\n",
      "Iteration 1170 => Loss: 274.525987\n",
      "Iteration 1171 => Loss: 274.064731\n",
      "Iteration 1172 => Loss: 273.603913\n",
      "Iteration 1173 => Loss: 273.143532\n",
      "Iteration 1174 => Loss: 272.683589\n",
      "Iteration 1175 => Loss: 272.224083\n",
      "Iteration 1176 => Loss: 271.765015\n",
      "Iteration 1177 => Loss: 271.306385\n",
      "Iteration 1178 => Loss: 270.848193\n",
      "Iteration 1179 => Loss: 270.390437\n",
      "Iteration 1180 => Loss: 269.933120\n",
      "Iteration 1181 => Loss: 269.476240\n",
      "Iteration 1182 => Loss: 269.019798\n",
      "Iteration 1183 => Loss: 268.563793\n",
      "Iteration 1184 => Loss: 268.108226\n",
      "Iteration 1185 => Loss: 267.653097\n",
      "Iteration 1186 => Loss: 267.198405\n",
      "Iteration 1187 => Loss: 266.744151\n",
      "Iteration 1188 => Loss: 266.290334\n",
      "Iteration 1189 => Loss: 265.836955\n",
      "Iteration 1190 => Loss: 265.384013\n",
      "Iteration 1191 => Loss: 264.931509\n",
      "Iteration 1192 => Loss: 264.479443\n",
      "Iteration 1193 => Loss: 264.027815\n",
      "Iteration 1194 => Loss: 263.576623\n",
      "Iteration 1195 => Loss: 263.125870\n",
      "Iteration 1196 => Loss: 262.675554\n",
      "Iteration 1197 => Loss: 262.225676\n",
      "Iteration 1198 => Loss: 261.776235\n",
      "Iteration 1199 => Loss: 261.327232\n",
      "Iteration 1200 => Loss: 260.878667\n",
      "Iteration 1201 => Loss: 260.430539\n",
      "Iteration 1202 => Loss: 259.982849\n",
      "Iteration 1203 => Loss: 259.535596\n",
      "Iteration 1204 => Loss: 259.088781\n",
      "Iteration 1205 => Loss: 258.642403\n",
      "Iteration 1206 => Loss: 258.196463\n",
      "Iteration 1207 => Loss: 257.750961\n",
      "Iteration 1208 => Loss: 257.305897\n",
      "Iteration 1209 => Loss: 256.861269\n",
      "Iteration 1210 => Loss: 256.417080\n",
      "Iteration 1211 => Loss: 255.973328\n",
      "Iteration 1212 => Loss: 255.530014\n",
      "Iteration 1213 => Loss: 255.087137\n",
      "Iteration 1214 => Loss: 254.644698\n",
      "Iteration 1215 => Loss: 254.202697\n",
      "Iteration 1216 => Loss: 253.761133\n",
      "Iteration 1217 => Loss: 253.320007\n",
      "Iteration 1218 => Loss: 252.879318\n",
      "Iteration 1219 => Loss: 252.439067\n",
      "Iteration 1220 => Loss: 251.999253\n",
      "Iteration 1221 => Loss: 251.559877\n",
      "Iteration 1222 => Loss: 251.120939\n",
      "Iteration 1223 => Loss: 250.682439\n",
      "Iteration 1224 => Loss: 250.244375\n",
      "Iteration 1225 => Loss: 249.806750\n",
      "Iteration 1226 => Loss: 249.369562\n",
      "Iteration 1227 => Loss: 248.932812\n",
      "Iteration 1228 => Loss: 248.496499\n",
      "Iteration 1229 => Loss: 248.060624\n",
      "Iteration 1230 => Loss: 247.625187\n",
      "Iteration 1231 => Loss: 247.190187\n",
      "Iteration 1232 => Loss: 246.755625\n",
      "Iteration 1233 => Loss: 246.321500\n",
      "Iteration 1234 => Loss: 245.887813\n",
      "Iteration 1235 => Loss: 245.454563\n",
      "Iteration 1236 => Loss: 245.021751\n",
      "Iteration 1237 => Loss: 244.589377\n",
      "Iteration 1238 => Loss: 244.157441\n",
      "Iteration 1239 => Loss: 243.725941\n",
      "Iteration 1240 => Loss: 243.294880\n",
      "Iteration 1241 => Loss: 242.864256\n",
      "Iteration 1242 => Loss: 242.434070\n",
      "Iteration 1243 => Loss: 242.004321\n",
      "Iteration 1244 => Loss: 241.575010\n",
      "Iteration 1245 => Loss: 241.146137\n",
      "Iteration 1246 => Loss: 240.717701\n",
      "Iteration 1247 => Loss: 240.289703\n",
      "Iteration 1248 => Loss: 239.862142\n",
      "Iteration 1249 => Loss: 239.435019\n",
      "Iteration 1250 => Loss: 239.008333\n",
      "Iteration 1251 => Loss: 238.582085\n",
      "Iteration 1252 => Loss: 238.156275\n",
      "Iteration 1253 => Loss: 237.730903\n",
      "Iteration 1254 => Loss: 237.305967\n",
      "Iteration 1255 => Loss: 236.881470\n",
      "Iteration 1256 => Loss: 236.457410\n",
      "Iteration 1257 => Loss: 236.033788\n",
      "Iteration 1258 => Loss: 235.610603\n",
      "Iteration 1259 => Loss: 235.187856\n",
      "Iteration 1260 => Loss: 234.765547\n",
      "Iteration 1261 => Loss: 234.343675\n",
      "Iteration 1262 => Loss: 233.922241\n",
      "Iteration 1263 => Loss: 233.501244\n",
      "Iteration 1264 => Loss: 233.080685\n",
      "Iteration 1265 => Loss: 232.660563\n",
      "Iteration 1266 => Loss: 232.240879\n",
      "Iteration 1267 => Loss: 231.821633\n",
      "Iteration 1268 => Loss: 231.402825\n",
      "Iteration 1269 => Loss: 230.984453\n",
      "Iteration 1270 => Loss: 230.566520\n",
      "Iteration 1271 => Loss: 230.149024\n",
      "Iteration 1272 => Loss: 229.731966\n",
      "Iteration 1273 => Loss: 229.315345\n",
      "Iteration 1274 => Loss: 228.899162\n",
      "Iteration 1275 => Loss: 228.483417\n",
      "Iteration 1276 => Loss: 228.068109\n",
      "Iteration 1277 => Loss: 227.653239\n",
      "Iteration 1278 => Loss: 227.238806\n",
      "Iteration 1279 => Loss: 226.824811\n",
      "Iteration 1280 => Loss: 226.411253\n",
      "Iteration 1281 => Loss: 225.998133\n",
      "Iteration 1282 => Loss: 225.585451\n",
      "Iteration 1283 => Loss: 225.173207\n",
      "Iteration 1284 => Loss: 224.761399\n",
      "Iteration 1285 => Loss: 224.350030\n",
      "Iteration 1286 => Loss: 223.939098\n",
      "Iteration 1287 => Loss: 223.528604\n",
      "Iteration 1288 => Loss: 223.118547\n",
      "Iteration 1289 => Loss: 222.708928\n",
      "Iteration 1290 => Loss: 222.299747\n",
      "Iteration 1291 => Loss: 221.891003\n",
      "Iteration 1292 => Loss: 221.482697\n",
      "Iteration 1293 => Loss: 221.074828\n",
      "Iteration 1294 => Loss: 220.667397\n",
      "Iteration 1295 => Loss: 220.260403\n",
      "Iteration 1296 => Loss: 219.853847\n",
      "Iteration 1297 => Loss: 219.447729\n",
      "Iteration 1298 => Loss: 219.042049\n",
      "Iteration 1299 => Loss: 218.636805\n",
      "Iteration 1300 => Loss: 218.232000\n",
      "Iteration 1301 => Loss: 217.827632\n",
      "Iteration 1302 => Loss: 217.423702\n",
      "Iteration 1303 => Loss: 217.020209\n",
      "Iteration 1304 => Loss: 216.617154\n",
      "Iteration 1305 => Loss: 216.214537\n",
      "Iteration 1306 => Loss: 215.812357\n",
      "Iteration 1307 => Loss: 215.410615\n",
      "Iteration 1308 => Loss: 215.009310\n",
      "Iteration 1309 => Loss: 214.608443\n",
      "Iteration 1310 => Loss: 214.208013\n",
      "Iteration 1311 => Loss: 213.808021\n",
      "Iteration 1312 => Loss: 213.408467\n",
      "Iteration 1313 => Loss: 213.009351\n",
      "Iteration 1314 => Loss: 212.610671\n",
      "Iteration 1315 => Loss: 212.212430\n",
      "Iteration 1316 => Loss: 211.814626\n",
      "Iteration 1317 => Loss: 211.417260\n",
      "Iteration 1318 => Loss: 211.020331\n",
      "Iteration 1319 => Loss: 210.623840\n",
      "Iteration 1320 => Loss: 210.227787\n",
      "Iteration 1321 => Loss: 209.832171\n",
      "Iteration 1322 => Loss: 209.436993\n",
      "Iteration 1323 => Loss: 209.042252\n",
      "Iteration 1324 => Loss: 208.647949\n",
      "Iteration 1325 => Loss: 208.254083\n",
      "Iteration 1326 => Loss: 207.860655\n",
      "Iteration 1327 => Loss: 207.467665\n",
      "Iteration 1328 => Loss: 207.075113\n",
      "Iteration 1329 => Loss: 206.682997\n",
      "Iteration 1330 => Loss: 206.291320\n",
      "Iteration 1331 => Loss: 205.900080\n",
      "Iteration 1332 => Loss: 205.509278\n",
      "Iteration 1333 => Loss: 205.118913\n",
      "Iteration 1334 => Loss: 204.728986\n",
      "Iteration 1335 => Loss: 204.339497\n",
      "Iteration 1336 => Loss: 203.950445\n",
      "Iteration 1337 => Loss: 203.561831\n",
      "Iteration 1338 => Loss: 203.173654\n",
      "Iteration 1339 => Loss: 202.785915\n",
      "Iteration 1340 => Loss: 202.398613\n",
      "Iteration 1341 => Loss: 202.011749\n",
      "Iteration 1342 => Loss: 201.625323\n",
      "Iteration 1343 => Loss: 201.239335\n",
      "Iteration 1344 => Loss: 200.853783\n",
      "Iteration 1345 => Loss: 200.468670\n",
      "Iteration 1346 => Loss: 200.083994\n",
      "Iteration 1347 => Loss: 199.699756\n",
      "Iteration 1348 => Loss: 199.315955\n",
      "Iteration 1349 => Loss: 198.932592\n",
      "Iteration 1350 => Loss: 198.549667\n",
      "Iteration 1351 => Loss: 198.167179\n",
      "Iteration 1352 => Loss: 197.785129\n",
      "Iteration 1353 => Loss: 197.403516\n",
      "Iteration 1354 => Loss: 197.022341\n",
      "Iteration 1355 => Loss: 196.641603\n",
      "Iteration 1356 => Loss: 196.261303\n",
      "Iteration 1357 => Loss: 195.881441\n",
      "Iteration 1358 => Loss: 195.502017\n",
      "Iteration 1359 => Loss: 195.123029\n",
      "Iteration 1360 => Loss: 194.744480\n",
      "Iteration 1361 => Loss: 194.366368\n",
      "Iteration 1362 => Loss: 193.988694\n",
      "Iteration 1363 => Loss: 193.611457\n",
      "Iteration 1364 => Loss: 193.234658\n",
      "Iteration 1365 => Loss: 192.858297\n",
      "Iteration 1366 => Loss: 192.482373\n",
      "Iteration 1367 => Loss: 192.106887\n",
      "Iteration 1368 => Loss: 191.731838\n",
      "Iteration 1369 => Loss: 191.357227\n",
      "Iteration 1370 => Loss: 190.983053\n",
      "Iteration 1371 => Loss: 190.609317\n",
      "Iteration 1372 => Loss: 190.236019\n",
      "Iteration 1373 => Loss: 189.863159\n",
      "Iteration 1374 => Loss: 189.490735\n",
      "Iteration 1375 => Loss: 189.118750\n",
      "Iteration 1376 => Loss: 188.747202\n",
      "Iteration 1377 => Loss: 188.376092\n",
      "Iteration 1378 => Loss: 188.005419\n",
      "Iteration 1379 => Loss: 187.635184\n",
      "Iteration 1380 => Loss: 187.265387\n",
      "Iteration 1381 => Loss: 186.896027\n",
      "Iteration 1382 => Loss: 186.527105\n",
      "Iteration 1383 => Loss: 186.158620\n",
      "Iteration 1384 => Loss: 185.790573\n",
      "Iteration 1385 => Loss: 185.422963\n",
      "Iteration 1386 => Loss: 185.055791\n",
      "Iteration 1387 => Loss: 184.689057\n",
      "Iteration 1388 => Loss: 184.322761\n",
      "Iteration 1389 => Loss: 183.956901\n",
      "Iteration 1390 => Loss: 183.591480\n",
      "Iteration 1391 => Loss: 183.226496\n",
      "Iteration 1392 => Loss: 182.861950\n",
      "Iteration 1393 => Loss: 182.497841\n",
      "Iteration 1394 => Loss: 182.134170\n",
      "Iteration 1395 => Loss: 181.770937\n",
      "Iteration 1396 => Loss: 181.408141\n",
      "Iteration 1397 => Loss: 181.045783\n",
      "Iteration 1398 => Loss: 180.683862\n",
      "Iteration 1399 => Loss: 180.322379\n",
      "Iteration 1400 => Loss: 179.961333\n",
      "Iteration 1401 => Loss: 179.600725\n",
      "Iteration 1402 => Loss: 179.240555\n",
      "Iteration 1403 => Loss: 178.880823\n",
      "Iteration 1404 => Loss: 178.521527\n",
      "Iteration 1405 => Loss: 178.162670\n",
      "Iteration 1406 => Loss: 177.804250\n",
      "Iteration 1407 => Loss: 177.446268\n",
      "Iteration 1408 => Loss: 177.088723\n",
      "Iteration 1409 => Loss: 176.731616\n",
      "Iteration 1410 => Loss: 176.374947\n",
      "Iteration 1411 => Loss: 176.018715\n",
      "Iteration 1412 => Loss: 175.662921\n",
      "Iteration 1413 => Loss: 175.307564\n",
      "Iteration 1414 => Loss: 174.952645\n",
      "Iteration 1415 => Loss: 174.598163\n",
      "Iteration 1416 => Loss: 174.244119\n",
      "Iteration 1417 => Loss: 173.890513\n",
      "Iteration 1418 => Loss: 173.537345\n",
      "Iteration 1419 => Loss: 173.184613\n",
      "Iteration 1420 => Loss: 172.832320\n",
      "Iteration 1421 => Loss: 172.480464\n",
      "Iteration 1422 => Loss: 172.129046\n",
      "Iteration 1423 => Loss: 171.778065\n",
      "Iteration 1424 => Loss: 171.427522\n",
      "Iteration 1425 => Loss: 171.077417\n",
      "Iteration 1426 => Loss: 170.727749\n",
      "Iteration 1427 => Loss: 170.378519\n",
      "Iteration 1428 => Loss: 170.029726\n",
      "Iteration 1429 => Loss: 169.681371\n",
      "Iteration 1430 => Loss: 169.333453\n",
      "Iteration 1431 => Loss: 168.985973\n",
      "Iteration 1432 => Loss: 168.638931\n",
      "Iteration 1433 => Loss: 168.292327\n",
      "Iteration 1434 => Loss: 167.946159\n",
      "Iteration 1435 => Loss: 167.600430\n",
      "Iteration 1436 => Loss: 167.255138\n",
      "Iteration 1437 => Loss: 166.910284\n",
      "Iteration 1438 => Loss: 166.565867\n",
      "Iteration 1439 => Loss: 166.221888\n",
      "Iteration 1440 => Loss: 165.878347\n",
      "Iteration 1441 => Loss: 165.535243\n",
      "Iteration 1442 => Loss: 165.192577\n",
      "Iteration 1443 => Loss: 164.850348\n",
      "Iteration 1444 => Loss: 164.508557\n",
      "Iteration 1445 => Loss: 164.167203\n",
      "Iteration 1446 => Loss: 163.826287\n",
      "Iteration 1447 => Loss: 163.485809\n",
      "Iteration 1448 => Loss: 163.145769\n",
      "Iteration 1449 => Loss: 162.806165\n",
      "Iteration 1450 => Loss: 162.467000\n",
      "Iteration 1451 => Loss: 162.128272\n",
      "Iteration 1452 => Loss: 161.789982\n",
      "Iteration 1453 => Loss: 161.452129\n",
      "Iteration 1454 => Loss: 161.114714\n",
      "Iteration 1455 => Loss: 160.777737\n",
      "Iteration 1456 => Loss: 160.441197\n",
      "Iteration 1457 => Loss: 160.105095\n",
      "Iteration 1458 => Loss: 159.769430\n",
      "Iteration 1459 => Loss: 159.434203\n",
      "Iteration 1460 => Loss: 159.099413\n",
      "Iteration 1461 => Loss: 158.765061\n",
      "Iteration 1462 => Loss: 158.431147\n",
      "Iteration 1463 => Loss: 158.097671\n",
      "Iteration 1464 => Loss: 157.764631\n",
      "Iteration 1465 => Loss: 157.432030\n",
      "Iteration 1466 => Loss: 157.099866\n",
      "Iteration 1467 => Loss: 156.768140\n",
      "Iteration 1468 => Loss: 156.436851\n",
      "Iteration 1469 => Loss: 156.106000\n",
      "Iteration 1470 => Loss: 155.775587\n",
      "Iteration 1471 => Loss: 155.445611\n",
      "Iteration 1472 => Loss: 155.116073\n",
      "Iteration 1473 => Loss: 154.786972\n",
      "Iteration 1474 => Loss: 154.458309\n",
      "Iteration 1475 => Loss: 154.130083\n",
      "Iteration 1476 => Loss: 153.802295\n",
      "Iteration 1477 => Loss: 153.474945\n",
      "Iteration 1478 => Loss: 153.148033\n",
      "Iteration 1479 => Loss: 152.821557\n",
      "Iteration 1480 => Loss: 152.495520\n",
      "Iteration 1481 => Loss: 152.169920\n",
      "Iteration 1482 => Loss: 151.844758\n",
      "Iteration 1483 => Loss: 151.520033\n",
      "Iteration 1484 => Loss: 151.195746\n",
      "Iteration 1485 => Loss: 150.871897\n",
      "Iteration 1486 => Loss: 150.548485\n",
      "Iteration 1487 => Loss: 150.225511\n",
      "Iteration 1488 => Loss: 149.902974\n",
      "Iteration 1489 => Loss: 149.580875\n",
      "Iteration 1490 => Loss: 149.259213\n",
      "Iteration 1491 => Loss: 148.937989\n",
      "Iteration 1492 => Loss: 148.617203\n",
      "Iteration 1493 => Loss: 148.296855\n",
      "Iteration 1494 => Loss: 147.976943\n",
      "Iteration 1495 => Loss: 147.657470\n",
      "Iteration 1496 => Loss: 147.338434\n",
      "Iteration 1497 => Loss: 147.019836\n",
      "Iteration 1498 => Loss: 146.701675\n",
      "Iteration 1499 => Loss: 146.383952\n",
      "Iteration 1500 => Loss: 146.066667\n",
      "Iteration 1501 => Loss: 145.749819\n",
      "Iteration 1502 => Loss: 145.433409\n",
      "Iteration 1503 => Loss: 145.117436\n",
      "Iteration 1504 => Loss: 144.801901\n",
      "Iteration 1505 => Loss: 144.486803\n",
      "Iteration 1506 => Loss: 144.172143\n",
      "Iteration 1507 => Loss: 143.857921\n",
      "Iteration 1508 => Loss: 143.544137\n",
      "Iteration 1509 => Loss: 143.230789\n",
      "Iteration 1510 => Loss: 142.917880\n",
      "Iteration 1511 => Loss: 142.605408\n",
      "Iteration 1512 => Loss: 142.293374\n",
      "Iteration 1513 => Loss: 141.981777\n",
      "Iteration 1514 => Loss: 141.670618\n",
      "Iteration 1515 => Loss: 141.359897\n",
      "Iteration 1516 => Loss: 141.049613\n",
      "Iteration 1517 => Loss: 140.739767\n",
      "Iteration 1518 => Loss: 140.430358\n",
      "Iteration 1519 => Loss: 140.121387\n",
      "Iteration 1520 => Loss: 139.812853\n",
      "Iteration 1521 => Loss: 139.504757\n",
      "Iteration 1522 => Loss: 139.197099\n",
      "Iteration 1523 => Loss: 138.889879\n",
      "Iteration 1524 => Loss: 138.583095\n",
      "Iteration 1525 => Loss: 138.276750\n",
      "Iteration 1526 => Loss: 137.970842\n",
      "Iteration 1527 => Loss: 137.665372\n",
      "Iteration 1528 => Loss: 137.360339\n",
      "Iteration 1529 => Loss: 137.055744\n",
      "Iteration 1530 => Loss: 136.751587\n",
      "Iteration 1531 => Loss: 136.447867\n",
      "Iteration 1532 => Loss: 136.144585\n",
      "Iteration 1533 => Loss: 135.841740\n",
      "Iteration 1534 => Loss: 135.539333\n",
      "Iteration 1535 => Loss: 135.237363\n",
      "Iteration 1536 => Loss: 134.935831\n",
      "Iteration 1537 => Loss: 134.634737\n",
      "Iteration 1538 => Loss: 134.334081\n",
      "Iteration 1539 => Loss: 134.033861\n",
      "Iteration 1540 => Loss: 133.734080\n",
      "Iteration 1541 => Loss: 133.434736\n",
      "Iteration 1542 => Loss: 133.135830\n",
      "Iteration 1543 => Loss: 132.837361\n",
      "Iteration 1544 => Loss: 132.539330\n",
      "Iteration 1545 => Loss: 132.241737\n",
      "Iteration 1546 => Loss: 131.944581\n",
      "Iteration 1547 => Loss: 131.647863\n",
      "Iteration 1548 => Loss: 131.351582\n",
      "Iteration 1549 => Loss: 131.055739\n",
      "Iteration 1550 => Loss: 130.760333\n",
      "Iteration 1551 => Loss: 130.465365\n",
      "Iteration 1552 => Loss: 130.170835\n",
      "Iteration 1553 => Loss: 129.876743\n",
      "Iteration 1554 => Loss: 129.583087\n",
      "Iteration 1555 => Loss: 129.289870\n",
      "Iteration 1556 => Loss: 128.997090\n",
      "Iteration 1557 => Loss: 128.704748\n",
      "Iteration 1558 => Loss: 128.412843\n",
      "Iteration 1559 => Loss: 128.121376\n",
      "Iteration 1560 => Loss: 127.830347\n",
      "Iteration 1561 => Loss: 127.539755\n",
      "Iteration 1562 => Loss: 127.249601\n",
      "Iteration 1563 => Loss: 126.959884\n",
      "Iteration 1564 => Loss: 126.670605\n",
      "Iteration 1565 => Loss: 126.381763\n",
      "Iteration 1566 => Loss: 126.093359\n",
      "Iteration 1567 => Loss: 125.805393\n",
      "Iteration 1568 => Loss: 125.517865\n",
      "Iteration 1569 => Loss: 125.230773\n",
      "Iteration 1570 => Loss: 124.944120\n",
      "Iteration 1571 => Loss: 124.657904\n",
      "Iteration 1572 => Loss: 124.372126\n",
      "Iteration 1573 => Loss: 124.086785\n",
      "Iteration 1574 => Loss: 123.801882\n",
      "Iteration 1575 => Loss: 123.517417\n",
      "Iteration 1576 => Loss: 123.233389\n",
      "Iteration 1577 => Loss: 122.949799\n",
      "Iteration 1578 => Loss: 122.666646\n",
      "Iteration 1579 => Loss: 122.383931\n",
      "Iteration 1580 => Loss: 122.101653\n",
      "Iteration 1581 => Loss: 121.819813\n",
      "Iteration 1582 => Loss: 121.538411\n",
      "Iteration 1583 => Loss: 121.257447\n",
      "Iteration 1584 => Loss: 120.976919\n",
      "Iteration 1585 => Loss: 120.696830\n",
      "Iteration 1586 => Loss: 120.417178\n",
      "Iteration 1587 => Loss: 120.137964\n",
      "Iteration 1588 => Loss: 119.859187\n",
      "Iteration 1589 => Loss: 119.580848\n",
      "Iteration 1590 => Loss: 119.302947\n",
      "Iteration 1591 => Loss: 119.025483\n",
      "Iteration 1592 => Loss: 118.748457\n",
      "Iteration 1593 => Loss: 118.471868\n",
      "Iteration 1594 => Loss: 118.195717\n",
      "Iteration 1595 => Loss: 117.920003\n",
      "Iteration 1596 => Loss: 117.644727\n",
      "Iteration 1597 => Loss: 117.369889\n",
      "Iteration 1598 => Loss: 117.095489\n",
      "Iteration 1599 => Loss: 116.821525\n",
      "Iteration 1600 => Loss: 116.548000\n",
      "Iteration 1601 => Loss: 116.274912\n",
      "Iteration 1602 => Loss: 116.002262\n",
      "Iteration 1603 => Loss: 115.730049\n",
      "Iteration 1604 => Loss: 115.458274\n",
      "Iteration 1605 => Loss: 115.186937\n",
      "Iteration 1606 => Loss: 114.916037\n",
      "Iteration 1607 => Loss: 114.645575\n",
      "Iteration 1608 => Loss: 114.375550\n",
      "Iteration 1609 => Loss: 114.105963\n",
      "Iteration 1610 => Loss: 113.836813\n",
      "Iteration 1611 => Loss: 113.568101\n",
      "Iteration 1612 => Loss: 113.299827\n",
      "Iteration 1613 => Loss: 113.031991\n",
      "Iteration 1614 => Loss: 112.764591\n",
      "Iteration 1615 => Loss: 112.497630\n",
      "Iteration 1616 => Loss: 112.231106\n",
      "Iteration 1617 => Loss: 111.965020\n",
      "Iteration 1618 => Loss: 111.699371\n",
      "Iteration 1619 => Loss: 111.434160\n",
      "Iteration 1620 => Loss: 111.169387\n",
      "Iteration 1621 => Loss: 110.905051\n",
      "Iteration 1622 => Loss: 110.641153\n",
      "Iteration 1623 => Loss: 110.377692\n",
      "Iteration 1624 => Loss: 110.114669\n",
      "Iteration 1625 => Loss: 109.852083\n",
      "Iteration 1626 => Loss: 109.589935\n",
      "Iteration 1627 => Loss: 109.328225\n",
      "Iteration 1628 => Loss: 109.066953\n",
      "Iteration 1629 => Loss: 108.806117\n",
      "Iteration 1630 => Loss: 108.545720\n",
      "Iteration 1631 => Loss: 108.285760\n",
      "Iteration 1632 => Loss: 108.026238\n",
      "Iteration 1633 => Loss: 107.767153\n",
      "Iteration 1634 => Loss: 107.508506\n",
      "Iteration 1635 => Loss: 107.250297\n",
      "Iteration 1636 => Loss: 106.992525\n",
      "Iteration 1637 => Loss: 106.735191\n",
      "Iteration 1638 => Loss: 106.478294\n",
      "Iteration 1639 => Loss: 106.221835\n",
      "Iteration 1640 => Loss: 105.965813\n",
      "Iteration 1641 => Loss: 105.710229\n",
      "Iteration 1642 => Loss: 105.455083\n",
      "Iteration 1643 => Loss: 105.200375\n",
      "Iteration 1644 => Loss: 104.946103\n",
      "Iteration 1645 => Loss: 104.692270\n",
      "Iteration 1646 => Loss: 104.438874\n",
      "Iteration 1647 => Loss: 104.185916\n",
      "Iteration 1648 => Loss: 103.933395\n",
      "Iteration 1649 => Loss: 103.681312\n",
      "Iteration 1650 => Loss: 103.429667\n",
      "Iteration 1651 => Loss: 103.178459\n",
      "Iteration 1652 => Loss: 102.927689\n",
      "Iteration 1653 => Loss: 102.677356\n",
      "Iteration 1654 => Loss: 102.427461\n",
      "Iteration 1655 => Loss: 102.178003\n",
      "Iteration 1656 => Loss: 101.928983\n",
      "Iteration 1657 => Loss: 101.680401\n",
      "Iteration 1658 => Loss: 101.432257\n",
      "Iteration 1659 => Loss: 101.184549\n",
      "Iteration 1660 => Loss: 100.937280\n",
      "Iteration 1661 => Loss: 100.690448\n",
      "Iteration 1662 => Loss: 100.444054\n",
      "Iteration 1663 => Loss: 100.198097\n",
      "Iteration 1664 => Loss: 99.952578\n",
      "Iteration 1665 => Loss: 99.707497\n",
      "Iteration 1666 => Loss: 99.462853\n",
      "Iteration 1667 => Loss: 99.218647\n",
      "Iteration 1668 => Loss: 98.974878\n",
      "Iteration 1669 => Loss: 98.731547\n",
      "Iteration 1670 => Loss: 98.488653\n",
      "Iteration 1671 => Loss: 98.246197\n",
      "Iteration 1672 => Loss: 98.004179\n",
      "Iteration 1673 => Loss: 97.762599\n",
      "Iteration 1674 => Loss: 97.521455\n",
      "Iteration 1675 => Loss: 97.280750\n",
      "Iteration 1676 => Loss: 97.040482\n",
      "Iteration 1677 => Loss: 96.800652\n",
      "Iteration 1678 => Loss: 96.561259\n",
      "Iteration 1679 => Loss: 96.322304\n",
      "Iteration 1680 => Loss: 96.083787\n",
      "Iteration 1681 => Loss: 95.845707\n",
      "Iteration 1682 => Loss: 95.608065\n",
      "Iteration 1683 => Loss: 95.370860\n",
      "Iteration 1684 => Loss: 95.134093\n",
      "Iteration 1685 => Loss: 94.897763\n",
      "Iteration 1686 => Loss: 94.661871\n",
      "Iteration 1687 => Loss: 94.426417\n",
      "Iteration 1688 => Loss: 94.191401\n",
      "Iteration 1689 => Loss: 93.956821\n",
      "Iteration 1690 => Loss: 93.722680\n",
      "Iteration 1691 => Loss: 93.488976\n",
      "Iteration 1692 => Loss: 93.255710\n",
      "Iteration 1693 => Loss: 93.022881\n",
      "Iteration 1694 => Loss: 92.790490\n",
      "Iteration 1695 => Loss: 92.558537\n",
      "Iteration 1696 => Loss: 92.327021\n",
      "Iteration 1697 => Loss: 92.095943\n",
      "Iteration 1698 => Loss: 91.865302\n",
      "Iteration 1699 => Loss: 91.635099\n",
      "Iteration 1700 => Loss: 91.405333\n",
      "Iteration 1701 => Loss: 91.176005\n",
      "Iteration 1702 => Loss: 90.947115\n",
      "Iteration 1703 => Loss: 90.718663\n",
      "Iteration 1704 => Loss: 90.490647\n",
      "Iteration 1705 => Loss: 90.263070\n",
      "Iteration 1706 => Loss: 90.035930\n",
      "Iteration 1707 => Loss: 89.809228\n",
      "Iteration 1708 => Loss: 89.582963\n",
      "Iteration 1709 => Loss: 89.357136\n",
      "Iteration 1710 => Loss: 89.131747\n",
      "Iteration 1711 => Loss: 88.906795\n",
      "Iteration 1712 => Loss: 88.682281\n",
      "Iteration 1713 => Loss: 88.458204\n",
      "Iteration 1714 => Loss: 88.234565\n",
      "Iteration 1715 => Loss: 88.011363\n",
      "Iteration 1716 => Loss: 87.788599\n",
      "Iteration 1717 => Loss: 87.566273\n",
      "Iteration 1718 => Loss: 87.344385\n",
      "Iteration 1719 => Loss: 87.122933\n",
      "Iteration 1720 => Loss: 86.901920\n",
      "Iteration 1721 => Loss: 86.681344\n",
      "Iteration 1722 => Loss: 86.461206\n",
      "Iteration 1723 => Loss: 86.241505\n",
      "Iteration 1724 => Loss: 86.022242\n",
      "Iteration 1725 => Loss: 85.803417\n",
      "Iteration 1726 => Loss: 85.585029\n",
      "Iteration 1727 => Loss: 85.367079\n",
      "Iteration 1728 => Loss: 85.149566\n",
      "Iteration 1729 => Loss: 84.932491\n",
      "Iteration 1730 => Loss: 84.715853\n",
      "Iteration 1731 => Loss: 84.499653\n",
      "Iteration 1732 => Loss: 84.283891\n",
      "Iteration 1733 => Loss: 84.068567\n",
      "Iteration 1734 => Loss: 83.853679\n",
      "Iteration 1735 => Loss: 83.639230\n",
      "Iteration 1736 => Loss: 83.425218\n",
      "Iteration 1737 => Loss: 83.211644\n",
      "Iteration 1738 => Loss: 82.998507\n",
      "Iteration 1739 => Loss: 82.785808\n",
      "Iteration 1740 => Loss: 82.573547\n",
      "Iteration 1741 => Loss: 82.361723\n",
      "Iteration 1742 => Loss: 82.150337\n",
      "Iteration 1743 => Loss: 81.939388\n",
      "Iteration 1744 => Loss: 81.728877\n",
      "Iteration 1745 => Loss: 81.518803\n",
      "Iteration 1746 => Loss: 81.309167\n",
      "Iteration 1747 => Loss: 81.099969\n",
      "Iteration 1748 => Loss: 80.891209\n",
      "Iteration 1749 => Loss: 80.682885\n",
      "Iteration 1750 => Loss: 80.475000\n",
      "Iteration 1751 => Loss: 80.267552\n",
      "Iteration 1752 => Loss: 80.060542\n",
      "Iteration 1753 => Loss: 79.853969\n",
      "Iteration 1754 => Loss: 79.647834\n",
      "Iteration 1755 => Loss: 79.442137\n",
      "Iteration 1756 => Loss: 79.236877\n",
      "Iteration 1757 => Loss: 79.032055\n",
      "Iteration 1758 => Loss: 78.827670\n",
      "Iteration 1759 => Loss: 78.623723\n",
      "Iteration 1760 => Loss: 78.420213\n",
      "Iteration 1761 => Loss: 78.217141\n",
      "Iteration 1762 => Loss: 78.014507\n",
      "Iteration 1763 => Loss: 77.812311\n",
      "Iteration 1764 => Loss: 77.610551\n",
      "Iteration 1765 => Loss: 77.409230\n",
      "Iteration 1766 => Loss: 77.208346\n",
      "Iteration 1767 => Loss: 77.007900\n",
      "Iteration 1768 => Loss: 76.807891\n",
      "Iteration 1769 => Loss: 76.608320\n",
      "Iteration 1770 => Loss: 76.409187\n",
      "Iteration 1771 => Loss: 76.210491\n",
      "Iteration 1772 => Loss: 76.012233\n",
      "Iteration 1773 => Loss: 75.814412\n",
      "Iteration 1774 => Loss: 75.617029\n",
      "Iteration 1775 => Loss: 75.420083\n",
      "Iteration 1776 => Loss: 75.223575\n",
      "Iteration 1777 => Loss: 75.027505\n",
      "Iteration 1778 => Loss: 74.831873\n",
      "Iteration 1779 => Loss: 74.636677\n",
      "Iteration 1780 => Loss: 74.441920\n",
      "Iteration 1781 => Loss: 74.247600\n",
      "Iteration 1782 => Loss: 74.053718\n",
      "Iteration 1783 => Loss: 73.860273\n",
      "Iteration 1784 => Loss: 73.667266\n",
      "Iteration 1785 => Loss: 73.474697\n",
      "Iteration 1786 => Loss: 73.282565\n",
      "Iteration 1787 => Loss: 73.090871\n",
      "Iteration 1788 => Loss: 72.899614\n",
      "Iteration 1789 => Loss: 72.708795\n",
      "Iteration 1790 => Loss: 72.518413\n",
      "Iteration 1791 => Loss: 72.328469\n",
      "Iteration 1792 => Loss: 72.138963\n",
      "Iteration 1793 => Loss: 71.949895\n",
      "Iteration 1794 => Loss: 71.761263\n",
      "Iteration 1795 => Loss: 71.573070\n",
      "Iteration 1796 => Loss: 71.385314\n",
      "Iteration 1797 => Loss: 71.197996\n",
      "Iteration 1798 => Loss: 71.011115\n",
      "Iteration 1799 => Loss: 70.824672\n",
      "Iteration 1800 => Loss: 70.638667\n",
      "Iteration 1801 => Loss: 70.453099\n",
      "Iteration 1802 => Loss: 70.267969\n",
      "Iteration 1803 => Loss: 70.083276\n",
      "Iteration 1804 => Loss: 69.899021\n",
      "Iteration 1805 => Loss: 69.715203\n",
      "Iteration 1806 => Loss: 69.531823\n",
      "Iteration 1807 => Loss: 69.348881\n",
      "Iteration 1808 => Loss: 69.166377\n",
      "Iteration 1809 => Loss: 68.984309\n",
      "Iteration 1810 => Loss: 68.802680\n",
      "Iteration 1811 => Loss: 68.621488\n",
      "Iteration 1812 => Loss: 68.440734\n",
      "Iteration 1813 => Loss: 68.260417\n",
      "Iteration 1814 => Loss: 68.080538\n",
      "Iteration 1815 => Loss: 67.901097\n",
      "Iteration 1816 => Loss: 67.722093\n",
      "Iteration 1817 => Loss: 67.543527\n",
      "Iteration 1818 => Loss: 67.365398\n",
      "Iteration 1819 => Loss: 67.187707\n",
      "Iteration 1820 => Loss: 67.010453\n",
      "Iteration 1821 => Loss: 66.833637\n",
      "Iteration 1822 => Loss: 66.657259\n",
      "Iteration 1823 => Loss: 66.481319\n",
      "Iteration 1824 => Loss: 66.305815\n",
      "Iteration 1825 => Loss: 66.130750\n",
      "Iteration 1826 => Loss: 65.956122\n",
      "Iteration 1827 => Loss: 65.781932\n",
      "Iteration 1828 => Loss: 65.608179\n",
      "Iteration 1829 => Loss: 65.434864\n",
      "Iteration 1830 => Loss: 65.261987\n",
      "Iteration 1831 => Loss: 65.089547\n",
      "Iteration 1832 => Loss: 64.917545\n",
      "Iteration 1833 => Loss: 64.745980\n",
      "Iteration 1834 => Loss: 64.574853\n",
      "Iteration 1835 => Loss: 64.404163\n",
      "Iteration 1836 => Loss: 64.233911\n",
      "Iteration 1837 => Loss: 64.064097\n",
      "Iteration 1838 => Loss: 63.894721\n",
      "Iteration 1839 => Loss: 63.725781\n",
      "Iteration 1840 => Loss: 63.557280\n",
      "Iteration 1841 => Loss: 63.389216\n",
      "Iteration 1842 => Loss: 63.221590\n",
      "Iteration 1843 => Loss: 63.054401\n",
      "Iteration 1844 => Loss: 62.887650\n",
      "Iteration 1845 => Loss: 62.721337\n",
      "Iteration 1846 => Loss: 62.555461\n",
      "Iteration 1847 => Loss: 62.390023\n",
      "Iteration 1848 => Loss: 62.225022\n",
      "Iteration 1849 => Loss: 62.060459\n",
      "Iteration 1850 => Loss: 61.896333\n",
      "Iteration 1851 => Loss: 61.732645\n",
      "Iteration 1852 => Loss: 61.569395\n",
      "Iteration 1853 => Loss: 61.406583\n",
      "Iteration 1854 => Loss: 61.244207\n",
      "Iteration 1855 => Loss: 61.082270\n",
      "Iteration 1856 => Loss: 60.920770\n",
      "Iteration 1857 => Loss: 60.759708\n",
      "Iteration 1858 => Loss: 60.599083\n",
      "Iteration 1859 => Loss: 60.438896\n",
      "Iteration 1860 => Loss: 60.279147\n",
      "Iteration 1861 => Loss: 60.119835\n",
      "Iteration 1862 => Loss: 59.960961\n",
      "Iteration 1863 => Loss: 59.802524\n",
      "Iteration 1864 => Loss: 59.644525\n",
      "Iteration 1865 => Loss: 59.486963\n",
      "Iteration 1866 => Loss: 59.329839\n",
      "Iteration 1867 => Loss: 59.173153\n",
      "Iteration 1868 => Loss: 59.016905\n",
      "Iteration 1869 => Loss: 58.861093\n",
      "Iteration 1870 => Loss: 58.705720\n",
      "Iteration 1871 => Loss: 58.550784\n",
      "Iteration 1872 => Loss: 58.396286\n",
      "Iteration 1873 => Loss: 58.242225\n",
      "Iteration 1874 => Loss: 58.088602\n",
      "Iteration 1875 => Loss: 57.935417\n",
      "Iteration 1876 => Loss: 57.782669\n",
      "Iteration 1877 => Loss: 57.630359\n",
      "Iteration 1878 => Loss: 57.478486\n",
      "Iteration 1879 => Loss: 57.327051\n",
      "Iteration 1880 => Loss: 57.176053\n",
      "Iteration 1881 => Loss: 57.025493\n",
      "Iteration 1882 => Loss: 56.875371\n",
      "Iteration 1883 => Loss: 56.725687\n",
      "Iteration 1884 => Loss: 56.576439\n",
      "Iteration 1885 => Loss: 56.427630\n",
      "Iteration 1886 => Loss: 56.279258\n",
      "Iteration 1887 => Loss: 56.131324\n",
      "Iteration 1888 => Loss: 55.983827\n",
      "Iteration 1889 => Loss: 55.836768\n",
      "Iteration 1890 => Loss: 55.690147\n",
      "Iteration 1891 => Loss: 55.543963\n",
      "Iteration 1892 => Loss: 55.398217\n",
      "Iteration 1893 => Loss: 55.252908\n",
      "Iteration 1894 => Loss: 55.108037\n",
      "Iteration 1895 => Loss: 54.963603\n",
      "Iteration 1896 => Loss: 54.819607\n",
      "Iteration 1897 => Loss: 54.676049\n",
      "Iteration 1898 => Loss: 54.532929\n",
      "Iteration 1899 => Loss: 54.390245\n",
      "Iteration 1900 => Loss: 54.248000\n",
      "Iteration 1901 => Loss: 54.106192\n",
      "Iteration 1902 => Loss: 53.964822\n",
      "Iteration 1903 => Loss: 53.823889\n",
      "Iteration 1904 => Loss: 53.683394\n",
      "Iteration 1905 => Loss: 53.543337\n",
      "Iteration 1906 => Loss: 53.403717\n",
      "Iteration 1907 => Loss: 53.264535\n",
      "Iteration 1908 => Loss: 53.125790\n",
      "Iteration 1909 => Loss: 52.987483\n",
      "Iteration 1910 => Loss: 52.849613\n",
      "Iteration 1911 => Loss: 52.712181\n",
      "Iteration 1912 => Loss: 52.575187\n",
      "Iteration 1913 => Loss: 52.438631\n",
      "Iteration 1914 => Loss: 52.302511\n",
      "Iteration 1915 => Loss: 52.166830\n",
      "Iteration 1916 => Loss: 52.031586\n",
      "Iteration 1917 => Loss: 51.896780\n",
      "Iteration 1918 => Loss: 51.762411\n",
      "Iteration 1919 => Loss: 51.628480\n",
      "Iteration 1920 => Loss: 51.494987\n",
      "Iteration 1921 => Loss: 51.361931\n",
      "Iteration 1922 => Loss: 51.229313\n",
      "Iteration 1923 => Loss: 51.097132\n",
      "Iteration 1924 => Loss: 50.965389\n",
      "Iteration 1925 => Loss: 50.834083\n",
      "Iteration 1926 => Loss: 50.703215\n",
      "Iteration 1927 => Loss: 50.572785\n",
      "Iteration 1928 => Loss: 50.442793\n",
      "Iteration 1929 => Loss: 50.313237\n",
      "Iteration 1930 => Loss: 50.184120\n",
      "Iteration 1931 => Loss: 50.055440\n",
      "Iteration 1932 => Loss: 49.927198\n",
      "Iteration 1933 => Loss: 49.799393\n",
      "Iteration 1934 => Loss: 49.672026\n",
      "Iteration 1935 => Loss: 49.545097\n",
      "Iteration 1936 => Loss: 49.418605\n",
      "Iteration 1937 => Loss: 49.292551\n",
      "Iteration 1938 => Loss: 49.166934\n",
      "Iteration 1939 => Loss: 49.041755\n",
      "Iteration 1940 => Loss: 48.917013\n",
      "Iteration 1941 => Loss: 48.792709\n",
      "Iteration 1942 => Loss: 48.668843\n",
      "Iteration 1943 => Loss: 48.545415\n",
      "Iteration 1944 => Loss: 48.422423\n",
      "Iteration 1945 => Loss: 48.299870\n",
      "Iteration 1946 => Loss: 48.177754\n",
      "Iteration 1947 => Loss: 48.056076\n",
      "Iteration 1948 => Loss: 47.934835\n",
      "Iteration 1949 => Loss: 47.814032\n",
      "Iteration 1950 => Loss: 47.693667\n",
      "Iteration 1951 => Loss: 47.573739\n",
      "Iteration 1952 => Loss: 47.454249\n",
      "Iteration 1953 => Loss: 47.335196\n",
      "Iteration 1954 => Loss: 47.216581\n",
      "Iteration 1955 => Loss: 47.098403\n",
      "Iteration 1956 => Loss: 46.980663\n",
      "Iteration 1957 => Loss: 46.863361\n",
      "Iteration 1958 => Loss: 46.746497\n",
      "Iteration 1959 => Loss: 46.630069\n",
      "Iteration 1960 => Loss: 46.514080\n",
      "Iteration 1961 => Loss: 46.398528\n",
      "Iteration 1962 => Loss: 46.283414\n",
      "Iteration 1963 => Loss: 46.168737\n",
      "Iteration 1964 => Loss: 46.054498\n",
      "Iteration 1965 => Loss: 45.940697\n",
      "Iteration 1966 => Loss: 45.827333\n",
      "Iteration 1967 => Loss: 45.714407\n",
      "Iteration 1968 => Loss: 45.601918\n",
      "Iteration 1969 => Loss: 45.489867\n",
      "Iteration 1970 => Loss: 45.378253\n",
      "Iteration 1971 => Loss: 45.267077\n",
      "Iteration 1972 => Loss: 45.156339\n",
      "Iteration 1973 => Loss: 45.046039\n",
      "Iteration 1974 => Loss: 44.936175\n",
      "Iteration 1975 => Loss: 44.826750\n",
      "Iteration 1976 => Loss: 44.717762\n",
      "Iteration 1977 => Loss: 44.609212\n",
      "Iteration 1978 => Loss: 44.501099\n",
      "Iteration 1979 => Loss: 44.393424\n",
      "Iteration 1980 => Loss: 44.286187\n",
      "Iteration 1981 => Loss: 44.179387\n",
      "Iteration 1982 => Loss: 44.073025\n",
      "Iteration 1983 => Loss: 43.967100\n",
      "Iteration 1984 => Loss: 43.861613\n",
      "Iteration 1985 => Loss: 43.756563\n",
      "Iteration 1986 => Loss: 43.651951\n",
      "Iteration 1987 => Loss: 43.547777\n",
      "Iteration 1988 => Loss: 43.444041\n",
      "Iteration 1989 => Loss: 43.340741\n",
      "Iteration 1990 => Loss: 43.237880\n",
      "Iteration 1991 => Loss: 43.135456\n",
      "Iteration 1992 => Loss: 43.033470\n",
      "Iteration 1993 => Loss: 42.931921\n",
      "Iteration 1994 => Loss: 42.830810\n",
      "Iteration 1995 => Loss: 42.730137\n",
      "Iteration 1996 => Loss: 42.629901\n",
      "Iteration 1997 => Loss: 42.530103\n",
      "Iteration 1998 => Loss: 42.430742\n",
      "Iteration 1999 => Loss: 42.331819\n",
      "Iteration 2000 => Loss: 42.233333\n",
      "Iteration 2001 => Loss: 42.135285\n",
      "Iteration 2002 => Loss: 42.037675\n",
      "Iteration 2003 => Loss: 41.940503\n",
      "Iteration 2004 => Loss: 41.843767\n",
      "Iteration 2005 => Loss: 41.747470\n",
      "Iteration 2006 => Loss: 41.651610\n",
      "Iteration 2007 => Loss: 41.556188\n",
      "Iteration 2008 => Loss: 41.461203\n",
      "Iteration 2009 => Loss: 41.366656\n",
      "Iteration 2010 => Loss: 41.272547\n",
      "Iteration 2011 => Loss: 41.178875\n",
      "Iteration 2012 => Loss: 41.085641\n",
      "Iteration 2013 => Loss: 40.992844\n",
      "Iteration 2014 => Loss: 40.900485\n",
      "Iteration 2015 => Loss: 40.808563\n",
      "Iteration 2016 => Loss: 40.717079\n",
      "Iteration 2017 => Loss: 40.626033\n",
      "Iteration 2018 => Loss: 40.535425\n",
      "Iteration 2019 => Loss: 40.445253\n",
      "Iteration 2020 => Loss: 40.355520\n",
      "Iteration 2021 => Loss: 40.266224\n",
      "Iteration 2022 => Loss: 40.177366\n",
      "Iteration 2023 => Loss: 40.088945\n",
      "Iteration 2024 => Loss: 40.000962\n",
      "Iteration 2025 => Loss: 39.913417\n",
      "Iteration 2026 => Loss: 39.826309\n",
      "Iteration 2027 => Loss: 39.739639\n",
      "Iteration 2028 => Loss: 39.653406\n",
      "Iteration 2029 => Loss: 39.567611\n",
      "Iteration 2030 => Loss: 39.482253\n",
      "Iteration 2031 => Loss: 39.397333\n",
      "Iteration 2032 => Loss: 39.312851\n",
      "Iteration 2033 => Loss: 39.228807\n",
      "Iteration 2034 => Loss: 39.145199\n",
      "Iteration 2035 => Loss: 39.062030\n",
      "Iteration 2036 => Loss: 38.979298\n",
      "Iteration 2037 => Loss: 38.897004\n",
      "Iteration 2038 => Loss: 38.815147\n",
      "Iteration 2039 => Loss: 38.733728\n",
      "Iteration 2040 => Loss: 38.652747\n",
      "Iteration 2041 => Loss: 38.572203\n",
      "Iteration 2042 => Loss: 38.492097\n",
      "Iteration 2043 => Loss: 38.412428\n",
      "Iteration 2044 => Loss: 38.333197\n",
      "Iteration 2045 => Loss: 38.254403\n",
      "Iteration 2046 => Loss: 38.176047\n",
      "Iteration 2047 => Loss: 38.098129\n",
      "Iteration 2048 => Loss: 38.020649\n",
      "Iteration 2049 => Loss: 37.943605\n",
      "Iteration 2050 => Loss: 37.867000\n",
      "Iteration 2051 => Loss: 37.790832\n",
      "Iteration 2052 => Loss: 37.715102\n",
      "Iteration 2053 => Loss: 37.639809\n",
      "Iteration 2054 => Loss: 37.564954\n",
      "Iteration 2055 => Loss: 37.490537\n",
      "Iteration 2056 => Loss: 37.416557\n",
      "Iteration 2057 => Loss: 37.343015\n",
      "Iteration 2058 => Loss: 37.269910\n",
      "Iteration 2059 => Loss: 37.197243\n",
      "Iteration 2060 => Loss: 37.125013\n",
      "Iteration 2061 => Loss: 37.053221\n",
      "Iteration 2062 => Loss: 36.981867\n",
      "Iteration 2063 => Loss: 36.910951\n",
      "Iteration 2064 => Loss: 36.840471\n",
      "Iteration 2065 => Loss: 36.770430\n",
      "Iteration 2066 => Loss: 36.700826\n",
      "Iteration 2067 => Loss: 36.631660\n",
      "Iteration 2068 => Loss: 36.562931\n",
      "Iteration 2069 => Loss: 36.494640\n",
      "Iteration 2070 => Loss: 36.426787\n",
      "Iteration 2071 => Loss: 36.359371\n",
      "Iteration 2072 => Loss: 36.292393\n",
      "Iteration 2073 => Loss: 36.225852\n",
      "Iteration 2074 => Loss: 36.159749\n",
      "Iteration 2075 => Loss: 36.094083\n",
      "Iteration 2076 => Loss: 36.028855\n",
      "Iteration 2077 => Loss: 35.964065\n",
      "Iteration 2078 => Loss: 35.899713\n",
      "Iteration 2079 => Loss: 35.835797\n",
      "Iteration 2080 => Loss: 35.772320\n",
      "Iteration 2081 => Loss: 35.709280\n",
      "Iteration 2082 => Loss: 35.646678\n",
      "Iteration 2083 => Loss: 35.584513\n",
      "Iteration 2084 => Loss: 35.522786\n",
      "Iteration 2085 => Loss: 35.461497\n",
      "Iteration 2086 => Loss: 35.400645\n",
      "Iteration 2087 => Loss: 35.340231\n",
      "Iteration 2088 => Loss: 35.280254\n",
      "Iteration 2089 => Loss: 35.220715\n",
      "Iteration 2090 => Loss: 35.161613\n",
      "Iteration 2091 => Loss: 35.102949\n",
      "Iteration 2092 => Loss: 35.044723\n",
      "Iteration 2093 => Loss: 34.986935\n",
      "Iteration 2094 => Loss: 34.929583\n",
      "Iteration 2095 => Loss: 34.872670\n",
      "Iteration 2096 => Loss: 34.816194\n",
      "Iteration 2097 => Loss: 34.760156\n",
      "Iteration 2098 => Loss: 34.704555\n",
      "Iteration 2099 => Loss: 34.649392\n",
      "Iteration 2100 => Loss: 34.594667\n",
      "Iteration 2101 => Loss: 34.540379\n",
      "Iteration 2102 => Loss: 34.486529\n",
      "Iteration 2103 => Loss: 34.433116\n",
      "Iteration 2104 => Loss: 34.380141\n",
      "Iteration 2105 => Loss: 34.327603\n",
      "Iteration 2106 => Loss: 34.275503\n",
      "Iteration 2107 => Loss: 34.223841\n",
      "Iteration 2108 => Loss: 34.172617\n",
      "Iteration 2109 => Loss: 34.121829\n",
      "Iteration 2110 => Loss: 34.071480\n",
      "Iteration 2111 => Loss: 34.021568\n",
      "Iteration 2112 => Loss: 33.972094\n",
      "Iteration 2113 => Loss: 33.923057\n",
      "Iteration 2114 => Loss: 33.874458\n",
      "Iteration 2115 => Loss: 33.826297\n",
      "Iteration 2116 => Loss: 33.778573\n",
      "Iteration 2117 => Loss: 33.731287\n",
      "Iteration 2118 => Loss: 33.684438\n",
      "Iteration 2119 => Loss: 33.638027\n",
      "Iteration 2120 => Loss: 33.592053\n",
      "Iteration 2121 => Loss: 33.546517\n",
      "Iteration 2122 => Loss: 33.501419\n",
      "Iteration 2123 => Loss: 33.456759\n",
      "Iteration 2124 => Loss: 33.412535\n",
      "Iteration 2125 => Loss: 33.368750\n",
      "Iteration 2126 => Loss: 33.325402\n",
      "Iteration 2127 => Loss: 33.282492\n",
      "Iteration 2128 => Loss: 33.240019\n",
      "Iteration 2129 => Loss: 33.197984\n",
      "Iteration 2130 => Loss: 33.156387\n",
      "Iteration 2131 => Loss: 33.115227\n",
      "Iteration 2132 => Loss: 33.074505\n",
      "Iteration 2133 => Loss: 33.034220\n",
      "Iteration 2134 => Loss: 32.994373\n",
      "Iteration 2135 => Loss: 32.954963\n",
      "Iteration 2136 => Loss: 32.915991\n",
      "Iteration 2137 => Loss: 32.877457\n",
      "Iteration 2138 => Loss: 32.839361\n",
      "Iteration 2139 => Loss: 32.801701\n",
      "Iteration 2140 => Loss: 32.764480\n",
      "Iteration 2141 => Loss: 32.727696\n",
      "Iteration 2142 => Loss: 32.691350\n",
      "Iteration 2143 => Loss: 32.655441\n",
      "Iteration 2144 => Loss: 32.619970\n",
      "Iteration 2145 => Loss: 32.584937\n",
      "Iteration 2146 => Loss: 32.550341\n",
      "Iteration 2147 => Loss: 32.516183\n",
      "Iteration 2148 => Loss: 32.482462\n",
      "Iteration 2149 => Loss: 32.449179\n",
      "Iteration 2150 => Loss: 32.416333\n",
      "Iteration 2151 => Loss: 32.383925\n",
      "Iteration 2152 => Loss: 32.351955\n",
      "Iteration 2153 => Loss: 32.320423\n",
      "Iteration 2154 => Loss: 32.289327\n",
      "Iteration 2155 => Loss: 32.258670\n",
      "Iteration 2156 => Loss: 32.228450\n",
      "Iteration 2157 => Loss: 32.198668\n",
      "Iteration 2158 => Loss: 32.169323\n",
      "Iteration 2159 => Loss: 32.140416\n",
      "Iteration 2160 => Loss: 32.111947\n",
      "Iteration 2161 => Loss: 32.083915\n",
      "Iteration 2162 => Loss: 32.056321\n",
      "Iteration 2163 => Loss: 32.029164\n",
      "Iteration 2164 => Loss: 32.002445\n",
      "Iteration 2165 => Loss: 31.976163\n",
      "Iteration 2166 => Loss: 31.950319\n",
      "Iteration 2167 => Loss: 31.924913\n",
      "Iteration 2168 => Loss: 31.899945\n",
      "Iteration 2169 => Loss: 31.875413\n",
      "Iteration 2170 => Loss: 31.851320\n",
      "Iteration 2171 => Loss: 31.827664\n",
      "Iteration 2172 => Loss: 31.804446\n",
      "Iteration 2173 => Loss: 31.781665\n",
      "Iteration 2174 => Loss: 31.759322\n",
      "Iteration 2175 => Loss: 31.737417\n",
      "Iteration 2176 => Loss: 31.715949\n",
      "Iteration 2177 => Loss: 31.694919\n",
      "Iteration 2178 => Loss: 31.674326\n",
      "Iteration 2179 => Loss: 31.654171\n",
      "Iteration 2180 => Loss: 31.634453\n",
      "Iteration 2181 => Loss: 31.615173\n",
      "Iteration 2182 => Loss: 31.596331\n",
      "Iteration 2183 => Loss: 31.577927\n",
      "Iteration 2184 => Loss: 31.559959\n",
      "Iteration 2185 => Loss: 31.542430\n",
      "Iteration 2186 => Loss: 31.525338\n",
      "Iteration 2187 => Loss: 31.508684\n",
      "Iteration 2188 => Loss: 31.492467\n",
      "Iteration 2189 => Loss: 31.476688\n",
      "Iteration 2190 => Loss: 31.461347\n",
      "Iteration 2191 => Loss: 31.446443\n",
      "Iteration 2192 => Loss: 31.431977\n",
      "Iteration 2193 => Loss: 31.417948\n",
      "Iteration 2194 => Loss: 31.404357\n",
      "Iteration 2195 => Loss: 31.391203\n",
      "Iteration 2196 => Loss: 31.378487\n",
      "Iteration 2197 => Loss: 31.366209\n",
      "Iteration 2198 => Loss: 31.354369\n",
      "Iteration 2199 => Loss: 31.342965\n",
      "Iteration 2200 => Loss: 31.332000\n",
      "Iteration 2201 => Loss: 31.321472\n",
      "Iteration 2202 => Loss: 31.311382\n",
      "Iteration 2203 => Loss: 31.301729\n",
      "Iteration 2204 => Loss: 31.292514\n",
      "Iteration 2205 => Loss: 31.283737\n",
      "Iteration 2206 => Loss: 31.275397\n",
      "Iteration 2207 => Loss: 31.267495\n",
      "Iteration 2208 => Loss: 31.260030\n",
      "Iteration 2209 => Loss: 31.253003\n",
      "Iteration 2210 => Loss: 31.246413\n",
      "Iteration 2211 => Loss: 31.240261\n",
      "Iteration 2212 => Loss: 31.234547\n",
      "Iteration 2213 => Loss: 31.229271\n",
      "Iteration 2214 => Loss: 31.224431\n",
      "Iteration 2215 => Loss: 31.220030\n",
      "Iteration 2216 => Loss: 31.216066\n",
      "Iteration 2217 => Loss: 31.212540\n",
      "Iteration 2218 => Loss: 31.209451\n",
      "Iteration 2219 => Loss: 31.206800\n",
      "Iteration 2220 => Loss: 31.204587\n",
      "Iteration 2221 => Loss: 31.202811\n",
      "Iteration 2222 => Loss: 31.201473\n",
      "Iteration 2223 => Loss: 31.200572\n",
      "Iteration 2224 => Loss: 31.200109\n",
      "Iteration 2225 => Loss: 31.200083\n",
      "Iteration 2226 => Loss: 31.195984\n",
      "Iteration 2227 => Loss: 31.191887\n",
      "Iteration 2228 => Loss: 31.191862\n",
      "Iteration 2229 => Loss: 31.187742\n",
      "Iteration 2230 => Loss: 31.183623\n",
      "Iteration 2231 => Loss: 31.179507\n",
      "Iteration 2232 => Loss: 31.175393\n",
      "Iteration 2233 => Loss: 31.171280\n",
      "Iteration 2234 => Loss: 31.167170\n",
      "Iteration 2235 => Loss: 31.163062\n",
      "Iteration 2236 => Loss: 31.158955\n",
      "Iteration 2237 => Loss: 31.154851\n",
      "Iteration 2238 => Loss: 31.150749\n",
      "Iteration 2239 => Loss: 31.146648\n",
      "Iteration 2240 => Loss: 31.142550\n",
      "Iteration 2241 => Loss: 31.138454\n",
      "Iteration 2242 => Loss: 31.134359\n",
      "Iteration 2243 => Loss: 31.130267\n",
      "Iteration 2244 => Loss: 31.126177\n",
      "Iteration 2245 => Loss: 31.122088\n",
      "Iteration 2246 => Loss: 31.122070\n",
      "Iteration 2247 => Loss: 31.117959\n",
      "Iteration 2248 => Loss: 31.113849\n",
      "Iteration 2249 => Loss: 31.109741\n",
      "Iteration 2250 => Loss: 31.105636\n",
      "Iteration 2251 => Loss: 31.101532\n",
      "Iteration 2252 => Loss: 31.097430\n",
      "Iteration 2253 => Loss: 31.093331\n",
      "Iteration 2254 => Loss: 31.089233\n",
      "Iteration 2255 => Loss: 31.085137\n",
      "Iteration 2256 => Loss: 31.081044\n",
      "Iteration 2257 => Loss: 31.076952\n",
      "Iteration 2258 => Loss: 31.072862\n",
      "Iteration 2259 => Loss: 31.068775\n",
      "Iteration 2260 => Loss: 31.064689\n",
      "Iteration 2261 => Loss: 31.060605\n",
      "Iteration 2262 => Loss: 31.056524\n",
      "Iteration 2263 => Loss: 31.052444\n",
      "Iteration 2264 => Loss: 31.052433\n",
      "Iteration 2265 => Loss: 31.048330\n",
      "Iteration 2266 => Loss: 31.044229\n",
      "Iteration 2267 => Loss: 31.040130\n",
      "Iteration 2268 => Loss: 31.036033\n",
      "Iteration 2269 => Loss: 31.031938\n",
      "Iteration 2270 => Loss: 31.027845\n",
      "Iteration 2271 => Loss: 31.023754\n",
      "Iteration 2272 => Loss: 31.019665\n",
      "Iteration 2273 => Loss: 31.015578\n",
      "Iteration 2274 => Loss: 31.011493\n",
      "Iteration 2275 => Loss: 31.007410\n",
      "Iteration 2276 => Loss: 31.003329\n",
      "Iteration 2277 => Loss: 30.999250\n",
      "Iteration 2278 => Loss: 30.995173\n",
      "Iteration 2279 => Loss: 30.991098\n",
      "Iteration 2280 => Loss: 30.987025\n",
      "Iteration 2281 => Loss: 30.982954\n",
      "Iteration 2282 => Loss: 30.982949\n",
      "Iteration 2283 => Loss: 30.978855\n",
      "Iteration 2284 => Loss: 30.974762\n",
      "Iteration 2285 => Loss: 30.970672\n",
      "Iteration 2286 => Loss: 30.966584\n",
      "Iteration 2287 => Loss: 30.962497\n",
      "Iteration 2288 => Loss: 30.958413\n",
      "Iteration 2289 => Loss: 30.954331\n",
      "Iteration 2290 => Loss: 30.950250\n",
      "Iteration 2291 => Loss: 30.946172\n",
      "Iteration 2292 => Loss: 30.942096\n",
      "Iteration 2293 => Loss: 30.938021\n",
      "Iteration 2294 => Loss: 30.933949\n",
      "Iteration 2295 => Loss: 30.929879\n",
      "Iteration 2296 => Loss: 30.925810\n",
      "Iteration 2297 => Loss: 30.921744\n",
      "Iteration 2298 => Loss: 30.917680\n",
      "Iteration 2299 => Loss: 30.913617\n",
      "Iteration 2300 => Loss: 30.909557\n",
      "Iteration 2301 => Loss: 30.909534\n",
      "Iteration 2302 => Loss: 30.905451\n",
      "Iteration 2303 => Loss: 30.901369\n",
      "Iteration 2304 => Loss: 30.897289\n",
      "Iteration 2305 => Loss: 30.893212\n",
      "Iteration 2306 => Loss: 30.889136\n",
      "Iteration 2307 => Loss: 30.885062\n",
      "Iteration 2308 => Loss: 30.880991\n",
      "Iteration 2309 => Loss: 30.876921\n",
      "Iteration 2310 => Loss: 30.872853\n",
      "Iteration 2311 => Loss: 30.868788\n",
      "Iteration 2312 => Loss: 30.864724\n",
      "Iteration 2313 => Loss: 30.860662\n",
      "Iteration 2314 => Loss: 30.856603\n",
      "Iteration 2315 => Loss: 30.852545\n",
      "Iteration 2316 => Loss: 30.848489\n",
      "Iteration 2317 => Loss: 30.844436\n",
      "Iteration 2318 => Loss: 30.840384\n",
      "Iteration 2319 => Loss: 30.840368\n",
      "Iteration 2320 => Loss: 30.836293\n",
      "Iteration 2321 => Loss: 30.832220\n",
      "Iteration 2322 => Loss: 30.828149\n",
      "Iteration 2323 => Loss: 30.824080\n",
      "Iteration 2324 => Loss: 30.820013\n",
      "Iteration 2325 => Loss: 30.815948\n",
      "Iteration 2326 => Loss: 30.811885\n",
      "Iteration 2327 => Loss: 30.807824\n",
      "Iteration 2328 => Loss: 30.803765\n",
      "Iteration 2329 => Loss: 30.799708\n",
      "Iteration 2330 => Loss: 30.795653\n",
      "Iteration 2331 => Loss: 30.791600\n",
      "Iteration 2332 => Loss: 30.787549\n",
      "Iteration 2333 => Loss: 30.783500\n",
      "Iteration 2334 => Loss: 30.779453\n",
      "Iteration 2335 => Loss: 30.775408\n",
      "Iteration 2336 => Loss: 30.771365\n",
      "Iteration 2337 => Loss: 30.771356\n",
      "Iteration 2338 => Loss: 30.767290\n",
      "Iteration 2339 => Loss: 30.763226\n",
      "Iteration 2340 => Loss: 30.759163\n",
      "Iteration 2341 => Loss: 30.755103\n",
      "Iteration 2342 => Loss: 30.751045\n",
      "Iteration 2343 => Loss: 30.746988\n",
      "Iteration 2344 => Loss: 30.742934\n",
      "Iteration 2345 => Loss: 30.738882\n",
      "Iteration 2346 => Loss: 30.734831\n",
      "Iteration 2347 => Loss: 30.730783\n",
      "Iteration 2348 => Loss: 30.726737\n",
      "Iteration 2349 => Loss: 30.722692\n",
      "Iteration 2350 => Loss: 30.718650\n",
      "Iteration 2351 => Loss: 30.714610\n",
      "Iteration 2352 => Loss: 30.710571\n",
      "Iteration 2353 => Loss: 30.706535\n",
      "Iteration 2354 => Loss: 30.702501\n",
      "Iteration 2355 => Loss: 30.702499\n",
      "Iteration 2356 => Loss: 30.698441\n",
      "Iteration 2357 => Loss: 30.694385\n",
      "Iteration 2358 => Loss: 30.690332\n",
      "Iteration 2359 => Loss: 30.686280\n",
      "Iteration 2360 => Loss: 30.682230\n",
      "Iteration 2361 => Loss: 30.678183\n",
      "Iteration 2362 => Loss: 30.674137\n",
      "Iteration 2363 => Loss: 30.670093\n",
      "Iteration 2364 => Loss: 30.666052\n",
      "Iteration 2365 => Loss: 30.662012\n",
      "Iteration 2366 => Loss: 30.657974\n",
      "Iteration 2367 => Loss: 30.653939\n",
      "Iteration 2368 => Loss: 30.649905\n",
      "Iteration 2369 => Loss: 30.645873\n",
      "Iteration 2370 => Loss: 30.641844\n",
      "Iteration 2371 => Loss: 30.637816\n",
      "Iteration 2372 => Loss: 30.633790\n",
      "Iteration 2373 => Loss: 30.629767\n",
      "Iteration 2374 => Loss: 30.629746\n",
      "Iteration 2375 => Loss: 30.625699\n",
      "Iteration 2376 => Loss: 30.621654\n",
      "Iteration 2377 => Loss: 30.617611\n",
      "Iteration 2378 => Loss: 30.613570\n",
      "Iteration 2379 => Loss: 30.609531\n",
      "Iteration 2380 => Loss: 30.605494\n",
      "Iteration 2381 => Loss: 30.601459\n",
      "Iteration 2382 => Loss: 30.597426\n",
      "Iteration 2383 => Loss: 30.593395\n",
      "Iteration 2384 => Loss: 30.589366\n",
      "Iteration 2385 => Loss: 30.585339\n",
      "Iteration 2386 => Loss: 30.581314\n",
      "Iteration 2387 => Loss: 30.577291\n",
      "Iteration 2388 => Loss: 30.573270\n",
      "Iteration 2389 => Loss: 30.569251\n",
      "Iteration 2390 => Loss: 30.565234\n",
      "Iteration 2391 => Loss: 30.561219\n",
      "Iteration 2392 => Loss: 30.561206\n",
      "Iteration 2393 => Loss: 30.557167\n",
      "Iteration 2394 => Loss: 30.553131\n",
      "Iteration 2395 => Loss: 30.549097\n",
      "Iteration 2396 => Loss: 30.545064\n",
      "Iteration 2397 => Loss: 30.541034\n",
      "Iteration 2398 => Loss: 30.537006\n",
      "Iteration 2399 => Loss: 30.532979\n",
      "Iteration 2400 => Loss: 30.528955\n",
      "Iteration 2401 => Loss: 30.524933\n",
      "Iteration 2402 => Loss: 30.520912\n",
      "Iteration 2403 => Loss: 30.516894\n",
      "Iteration 2404 => Loss: 30.512878\n",
      "Iteration 2405 => Loss: 30.508863\n",
      "Iteration 2406 => Loss: 30.504851\n",
      "Iteration 2407 => Loss: 30.500841\n",
      "Iteration 2408 => Loss: 30.496832\n",
      "Iteration 2409 => Loss: 30.492826\n",
      "Iteration 2410 => Loss: 30.492819\n",
      "Iteration 2411 => Loss: 30.488790\n",
      "Iteration 2412 => Loss: 30.484762\n",
      "Iteration 2413 => Loss: 30.480736\n",
      "Iteration 2414 => Loss: 30.476713\n",
      "Iteration 2415 => Loss: 30.472691\n",
      "Iteration 2416 => Loss: 30.468671\n",
      "Iteration 2417 => Loss: 30.464654\n",
      "Iteration 2418 => Loss: 30.460638\n",
      "Iteration 2419 => Loss: 30.456624\n",
      "Iteration 2420 => Loss: 30.452613\n",
      "Iteration 2421 => Loss: 30.448603\n",
      "Iteration 2422 => Loss: 30.444595\n",
      "Iteration 2423 => Loss: 30.440590\n",
      "Iteration 2424 => Loss: 30.436586\n",
      "Iteration 2425 => Loss: 30.432584\n",
      "Iteration 2426 => Loss: 30.428585\n",
      "Iteration 2427 => Loss: 30.424587\n",
      "Iteration 2428 => Loss: 30.420591\n",
      "Iteration 2429 => Loss: 30.420567\n",
      "Iteration 2430 => Loss: 30.416548\n",
      "Iteration 2431 => Loss: 30.412531\n",
      "Iteration 2432 => Loss: 30.408516\n",
      "Iteration 2433 => Loss: 30.404503\n",
      "Iteration 2434 => Loss: 30.400492\n",
      "Iteration 2435 => Loss: 30.396483\n",
      "Iteration 2436 => Loss: 30.392476\n",
      "Iteration 2437 => Loss: 30.388471\n",
      "Iteration 2438 => Loss: 30.384468\n",
      "Iteration 2439 => Loss: 30.380467\n",
      "Iteration 2440 => Loss: 30.376468\n",
      "Iteration 2441 => Loss: 30.372471\n",
      "Iteration 2442 => Loss: 30.368476\n",
      "Iteration 2443 => Loss: 30.364483\n",
      "Iteration 2444 => Loss: 30.360492\n",
      "Iteration 2445 => Loss: 30.356503\n",
      "Iteration 2446 => Loss: 30.352516\n",
      "Iteration 2447 => Loss: 30.352498\n",
      "Iteration 2448 => Loss: 30.348487\n",
      "Iteration 2449 => Loss: 30.344479\n",
      "Iteration 2450 => Loss: 30.340473\n",
      "Iteration 2451 => Loss: 30.336468\n",
      "Iteration 2452 => Loss: 30.332466\n",
      "Iteration 2453 => Loss: 30.328466\n",
      "Iteration 2454 => Loss: 30.324467\n",
      "Iteration 2455 => Loss: 30.320471\n",
      "Iteration 2456 => Loss: 30.316477\n",
      "Iteration 2457 => Loss: 30.312484\n",
      "Iteration 2458 => Loss: 30.308494\n",
      "Iteration 2459 => Loss: 30.304506\n",
      "Iteration 2460 => Loss: 30.300519\n",
      "Iteration 2461 => Loss: 30.296535\n",
      "Iteration 2462 => Loss: 30.292553\n",
      "Iteration 2463 => Loss: 30.288572\n",
      "Iteration 2464 => Loss: 30.284594\n",
      "Iteration 2465 => Loss: 30.284583\n",
      "Iteration 2466 => Loss: 30.280581\n",
      "Iteration 2467 => Loss: 30.276581\n",
      "Iteration 2468 => Loss: 30.272584\n",
      "Iteration 2469 => Loss: 30.268588\n",
      "Iteration 2470 => Loss: 30.264594\n",
      "Iteration 2471 => Loss: 30.260603\n",
      "Iteration 2472 => Loss: 30.256613\n",
      "Iteration 2473 => Loss: 30.252625\n",
      "Iteration 2474 => Loss: 30.248640\n",
      "Iteration 2475 => Loss: 30.244656\n",
      "Iteration 2476 => Loss: 30.240674\n",
      "Iteration 2477 => Loss: 30.236695\n",
      "Iteration 2478 => Loss: 30.232717\n",
      "Iteration 2479 => Loss: 30.228741\n",
      "Iteration 2480 => Loss: 30.224768\n",
      "Iteration 2481 => Loss: 30.220796\n",
      "Iteration 2482 => Loss: 30.216826\n",
      "Iteration 2483 => Loss: 30.216822\n",
      "Iteration 2484 => Loss: 30.212829\n",
      "Iteration 2485 => Loss: 30.208838\n",
      "Iteration 2486 => Loss: 30.204849\n",
      "Iteration 2487 => Loss: 30.200862\n",
      "Iteration 2488 => Loss: 30.196877\n",
      "Iteration 2489 => Loss: 30.192894\n",
      "Iteration 2490 => Loss: 30.188913\n",
      "Iteration 2491 => Loss: 30.184934\n",
      "Iteration 2492 => Loss: 30.180957\n",
      "Iteration 2493 => Loss: 30.176982\n",
      "Iteration 2494 => Loss: 30.173009\n",
      "Iteration 2495 => Loss: 30.169038\n",
      "Iteration 2496 => Loss: 30.165069\n",
      "Iteration 2497 => Loss: 30.161102\n",
      "Iteration 2498 => Loss: 30.157137\n",
      "Iteration 2499 => Loss: 30.153174\n",
      "Iteration 2500 => Loss: 30.149213\n",
      "Iteration 2501 => Loss: 30.145254\n",
      "Iteration 2502 => Loss: 30.145232\n",
      "Iteration 2503 => Loss: 30.141249\n",
      "Iteration 2504 => Loss: 30.137269\n",
      "Iteration 2505 => Loss: 30.133291\n",
      "Iteration 2506 => Loss: 30.129314\n",
      "Iteration 2507 => Loss: 30.125340\n",
      "Iteration 2508 => Loss: 30.121368\n",
      "Iteration 2509 => Loss: 30.117397\n",
      "Iteration 2510 => Loss: 30.113429\n",
      "Iteration 2511 => Loss: 30.109463\n",
      "Iteration 2512 => Loss: 30.105498\n",
      "Iteration 2513 => Loss: 30.101536\n",
      "Iteration 2514 => Loss: 30.097576\n",
      "Iteration 2515 => Loss: 30.093617\n",
      "Iteration 2516 => Loss: 30.089661\n",
      "Iteration 2517 => Loss: 30.085707\n",
      "Iteration 2518 => Loss: 30.081754\n",
      "Iteration 2519 => Loss: 30.077804\n",
      "Iteration 2520 => Loss: 30.077789\n",
      "Iteration 2521 => Loss: 30.073815\n",
      "Iteration 2522 => Loss: 30.069843\n",
      "Iteration 2523 => Loss: 30.065874\n",
      "Iteration 2524 => Loss: 30.061906\n",
      "Iteration 2525 => Loss: 30.057940\n",
      "Iteration 2526 => Loss: 30.053977\n",
      "Iteration 2527 => Loss: 30.050015\n",
      "Iteration 2528 => Loss: 30.046055\n",
      "Iteration 2529 => Loss: 30.042098\n",
      "Iteration 2530 => Loss: 30.038142\n",
      "Iteration 2531 => Loss: 30.034188\n",
      "Iteration 2532 => Loss: 30.030237\n",
      "Iteration 2533 => Loss: 30.026287\n",
      "Iteration 2534 => Loss: 30.022339\n",
      "Iteration 2535 => Loss: 30.018394\n",
      "Iteration 2536 => Loss: 30.014450\n",
      "Iteration 2537 => Loss: 30.010508\n",
      "Iteration 2538 => Loss: 30.010500\n",
      "Iteration 2539 => Loss: 30.006535\n",
      "Iteration 2540 => Loss: 30.002572\n",
      "Iteration 2541 => Loss: 29.998611\n",
      "Iteration 2542 => Loss: 29.994652\n",
      "Iteration 2543 => Loss: 29.990695\n",
      "Iteration 2544 => Loss: 29.986740\n",
      "Iteration 2545 => Loss: 29.982787\n",
      "Iteration 2546 => Loss: 29.978836\n",
      "Iteration 2547 => Loss: 29.974887\n",
      "Iteration 2548 => Loss: 29.970940\n",
      "Iteration 2549 => Loss: 29.966995\n",
      "Iteration 2550 => Loss: 29.963052\n",
      "Iteration 2551 => Loss: 29.959111\n",
      "Iteration 2552 => Loss: 29.955172\n",
      "Iteration 2553 => Loss: 29.951235\n",
      "Iteration 2554 => Loss: 29.947300\n",
      "Iteration 2555 => Loss: 29.943367\n",
      "Iteration 2556 => Loss: 29.943365\n",
      "Iteration 2557 => Loss: 29.939408\n",
      "Iteration 2558 => Loss: 29.935454\n",
      "Iteration 2559 => Loss: 29.931502\n",
      "Iteration 2560 => Loss: 29.927551\n",
      "Iteration 2561 => Loss: 29.923603\n",
      "Iteration 2562 => Loss: 29.919657\n",
      "Iteration 2563 => Loss: 29.915712\n",
      "Iteration 2564 => Loss: 29.911770\n",
      "Iteration 2565 => Loss: 29.907830\n",
      "Iteration 2566 => Loss: 29.903891\n",
      "Iteration 2567 => Loss: 29.899955\n",
      "Iteration 2568 => Loss: 29.896021\n",
      "Iteration 2569 => Loss: 29.892088\n",
      "Iteration 2570 => Loss: 29.888158\n",
      "Iteration 2571 => Loss: 29.884230\n",
      "Iteration 2572 => Loss: 29.880303\n",
      "Iteration 2573 => Loss: 29.876379\n",
      "Iteration 2574 => Loss: 29.872457\n",
      "Iteration 2575 => Loss: 29.872437\n",
      "Iteration 2576 => Loss: 29.868491\n",
      "Iteration 2577 => Loss: 29.864547\n",
      "Iteration 2578 => Loss: 29.860606\n",
      "Iteration 2579 => Loss: 29.856666\n",
      "Iteration 2580 => Loss: 29.852728\n",
      "Iteration 2581 => Loss: 29.848793\n",
      "Iteration 2582 => Loss: 29.844859\n",
      "Iteration 2583 => Loss: 29.840927\n",
      "Iteration 2584 => Loss: 29.836998\n",
      "Iteration 2585 => Loss: 29.833070\n",
      "Iteration 2586 => Loss: 29.829144\n",
      "Iteration 2587 => Loss: 29.825221\n",
      "Iteration 2588 => Loss: 29.821299\n",
      "Iteration 2589 => Loss: 29.817379\n",
      "Iteration 2590 => Loss: 29.813462\n",
      "Iteration 2591 => Loss: 29.809546\n",
      "Iteration 2592 => Loss: 29.805632\n",
      "Iteration 2593 => Loss: 29.805619\n",
      "Iteration 2594 => Loss: 29.801682\n",
      "Iteration 2595 => Loss: 29.797747\n",
      "Iteration 2596 => Loss: 29.793814\n",
      "Iteration 2597 => Loss: 29.789883\n",
      "Iteration 2598 => Loss: 29.785954\n",
      "Iteration 2599 => Loss: 29.782027\n",
      "Iteration 2600 => Loss: 29.778102\n",
      "Iteration 2601 => Loss: 29.774179\n",
      "Iteration 2602 => Loss: 29.770258\n",
      "Iteration 2603 => Loss: 29.766339\n",
      "Iteration 2604 => Loss: 29.762422\n",
      "Iteration 2605 => Loss: 29.758507\n",
      "Iteration 2606 => Loss: 29.754594\n",
      "Iteration 2607 => Loss: 29.750683\n",
      "Iteration 2608 => Loss: 29.746774\n",
      "Iteration 2609 => Loss: 29.742867\n",
      "Iteration 2610 => Loss: 29.738962\n",
      "Iteration 2611 => Loss: 29.738956\n",
      "Iteration 2612 => Loss: 29.735028\n",
      "Iteration 2613 => Loss: 29.731101\n",
      "Iteration 2614 => Loss: 29.727177\n",
      "Iteration 2615 => Loss: 29.723255\n",
      "Iteration 2616 => Loss: 29.719334\n",
      "Iteration 2617 => Loss: 29.715416\n",
      "Iteration 2618 => Loss: 29.711500\n",
      "Iteration 2619 => Loss: 29.707585\n",
      "Iteration 2620 => Loss: 29.703673\n",
      "Iteration 2621 => Loss: 29.699763\n",
      "Iteration 2622 => Loss: 29.695854\n",
      "Iteration 2623 => Loss: 29.691948\n",
      "Iteration 2624 => Loss: 29.688044\n",
      "Iteration 2625 => Loss: 29.684141\n",
      "Iteration 2626 => Loss: 29.680241\n",
      "Iteration 2627 => Loss: 29.676343\n",
      "Iteration 2628 => Loss: 29.672446\n",
      "Iteration 2629 => Loss: 29.668552\n",
      "Iteration 2630 => Loss: 29.668527\n",
      "Iteration 2631 => Loss: 29.664610\n",
      "Iteration 2632 => Loss: 29.660694\n",
      "Iteration 2633 => Loss: 29.656780\n",
      "Iteration 2634 => Loss: 29.652869\n",
      "Iteration 2635 => Loss: 29.648959\n",
      "Iteration 2636 => Loss: 29.645051\n",
      "Iteration 2637 => Loss: 29.641146\n",
      "Iteration 2638 => Loss: 29.637242\n",
      "Iteration 2639 => Loss: 29.633340\n",
      "Iteration 2640 => Loss: 29.629441\n",
      "Iteration 2641 => Loss: 29.625543\n",
      "Iteration 2642 => Loss: 29.621647\n",
      "Iteration 2643 => Loss: 29.617754\n",
      "Iteration 2644 => Loss: 29.613862\n",
      "Iteration 2645 => Loss: 29.609972\n",
      "Iteration 2646 => Loss: 29.606085\n",
      "Iteration 2647 => Loss: 29.602199\n",
      "Iteration 2648 => Loss: 29.602181\n",
      "Iteration 2649 => Loss: 29.598272\n",
      "Iteration 2650 => Loss: 29.594365\n",
      "Iteration 2651 => Loss: 29.590460\n",
      "Iteration 2652 => Loss: 29.586557\n",
      "Iteration 2653 => Loss: 29.582656\n",
      "Iteration 2654 => Loss: 29.578757\n",
      "Iteration 2655 => Loss: 29.574860\n",
      "Iteration 2656 => Loss: 29.570965\n",
      "Iteration 2657 => Loss: 29.567072\n",
      "Iteration 2658 => Loss: 29.563181\n",
      "Iteration 2659 => Loss: 29.559292\n",
      "Iteration 2660 => Loss: 29.555405\n",
      "Iteration 2661 => Loss: 29.551520\n",
      "Iteration 2662 => Loss: 29.547637\n",
      "Iteration 2663 => Loss: 29.543756\n",
      "Iteration 2664 => Loss: 29.539877\n",
      "Iteration 2665 => Loss: 29.536000\n",
      "Iteration 2666 => Loss: 29.535989\n",
      "Iteration 2667 => Loss: 29.532089\n",
      "Iteration 2668 => Loss: 29.528191\n",
      "Iteration 2669 => Loss: 29.524294\n",
      "Iteration 2670 => Loss: 29.520400\n",
      "Iteration 2671 => Loss: 29.516508\n",
      "Iteration 2672 => Loss: 29.512617\n",
      "Iteration 2673 => Loss: 29.508729\n",
      "Iteration 2674 => Loss: 29.504843\n",
      "Iteration 2675 => Loss: 29.500958\n",
      "Iteration 2676 => Loss: 29.497076\n",
      "Iteration 2677 => Loss: 29.493196\n",
      "Iteration 2678 => Loss: 29.489317\n",
      "Iteration 2679 => Loss: 29.485441\n",
      "Iteration 2680 => Loss: 29.481567\n",
      "Iteration 2681 => Loss: 29.477694\n",
      "Iteration 2682 => Loss: 29.473824\n",
      "Iteration 2683 => Loss: 29.469956\n",
      "Iteration 2684 => Loss: 29.469952\n",
      "Iteration 2685 => Loss: 29.466060\n",
      "Iteration 2686 => Loss: 29.462170\n",
      "Iteration 2687 => Loss: 29.458283\n",
      "Iteration 2688 => Loss: 29.454397\n",
      "Iteration 2689 => Loss: 29.450513\n",
      "Iteration 2690 => Loss: 29.446632\n",
      "Iteration 2691 => Loss: 29.442752\n",
      "Iteration 2692 => Loss: 29.438874\n",
      "Iteration 2693 => Loss: 29.434999\n",
      "Iteration 2694 => Loss: 29.431125\n",
      "Iteration 2695 => Loss: 29.427253\n",
      "Iteration 2696 => Loss: 29.423384\n",
      "Iteration 2697 => Loss: 29.419516\n",
      "Iteration 2698 => Loss: 29.415650\n",
      "Iteration 2699 => Loss: 29.411787\n",
      "Iteration 2700 => Loss: 29.407925\n",
      "Iteration 2701 => Loss: 29.404065\n",
      "Iteration 2702 => Loss: 29.400208\n",
      "Iteration 2703 => Loss: 29.400186\n",
      "Iteration 2704 => Loss: 29.396305\n",
      "Iteration 2705 => Loss: 29.392426\n",
      "Iteration 2706 => Loss: 29.388549\n",
      "Iteration 2707 => Loss: 29.384674\n",
      "Iteration 2708 => Loss: 29.380801\n",
      "Iteration 2709 => Loss: 29.376930\n",
      "Iteration 2710 => Loss: 29.373061\n",
      "Iteration 2711 => Loss: 29.369194\n",
      "Iteration 2712 => Loss: 29.365329\n",
      "Iteration 2713 => Loss: 29.361466\n",
      "Iteration 2714 => Loss: 29.357605\n",
      "Iteration 2715 => Loss: 29.353746\n",
      "Iteration 2716 => Loss: 29.349889\n",
      "Iteration 2717 => Loss: 29.346034\n",
      "Iteration 2718 => Loss: 29.342181\n",
      "Iteration 2719 => Loss: 29.338330\n",
      "Iteration 2720 => Loss: 29.334481\n",
      "Iteration 2721 => Loss: 29.334465\n",
      "Iteration 2722 => Loss: 29.330593\n",
      "Iteration 2723 => Loss: 29.326723\n",
      "Iteration 2724 => Loss: 29.322854\n",
      "Iteration 2725 => Loss: 29.318988\n",
      "Iteration 2726 => Loss: 29.315124\n",
      "Iteration 2727 => Loss: 29.311261\n",
      "Iteration 2728 => Loss: 29.307401\n",
      "Iteration 2729 => Loss: 29.303543\n",
      "Iteration 2730 => Loss: 29.299686\n",
      "Iteration 2731 => Loss: 29.295832\n",
      "Iteration 2732 => Loss: 29.291980\n",
      "Iteration 2733 => Loss: 29.288129\n",
      "Iteration 2734 => Loss: 29.284281\n",
      "Iteration 2735 => Loss: 29.280435\n",
      "Iteration 2736 => Loss: 29.276590\n",
      "Iteration 2737 => Loss: 29.272748\n",
      "Iteration 2738 => Loss: 29.268908\n",
      "Iteration 2739 => Loss: 29.268899\n",
      "Iteration 2740 => Loss: 29.265035\n",
      "Iteration 2741 => Loss: 29.261174\n",
      "Iteration 2742 => Loss: 29.257314\n",
      "Iteration 2743 => Loss: 29.253456\n",
      "Iteration 2744 => Loss: 29.249601\n",
      "Iteration 2745 => Loss: 29.245747\n",
      "Iteration 2746 => Loss: 29.241895\n",
      "Iteration 2747 => Loss: 29.238046\n",
      "Iteration 2748 => Loss: 29.234198\n",
      "Iteration 2749 => Loss: 29.230352\n",
      "Iteration 2750 => Loss: 29.226509\n",
      "Iteration 2751 => Loss: 29.222667\n",
      "Iteration 2752 => Loss: 29.218827\n",
      "Iteration 2753 => Loss: 29.214990\n",
      "Iteration 2754 => Loss: 29.211154\n",
      "Iteration 2755 => Loss: 29.207320\n",
      "Iteration 2756 => Loss: 29.203489\n",
      "Iteration 2757 => Loss: 29.203487\n",
      "Iteration 2758 => Loss: 29.199632\n",
      "Iteration 2759 => Loss: 29.195779\n",
      "Iteration 2760 => Loss: 29.191928\n",
      "Iteration 2761 => Loss: 29.188079\n",
      "Iteration 2762 => Loss: 29.184232\n",
      "Iteration 2763 => Loss: 29.180387\n",
      "Iteration 2764 => Loss: 29.176544\n",
      "Iteration 2765 => Loss: 29.172703\n",
      "Iteration 2766 => Loss: 29.168864\n",
      "Iteration 2767 => Loss: 29.165027\n",
      "Iteration 2768 => Loss: 29.161192\n",
      "Iteration 2769 => Loss: 29.157359\n",
      "Iteration 2770 => Loss: 29.153528\n",
      "Iteration 2771 => Loss: 29.149699\n",
      "Iteration 2772 => Loss: 29.145872\n",
      "Iteration 2773 => Loss: 29.142047\n",
      "Iteration 2774 => Loss: 29.138224\n",
      "Iteration 2775 => Loss: 29.134403\n",
      "Iteration 2776 => Loss: 29.134383\n",
      "Iteration 2777 => Loss: 29.130539\n",
      "Iteration 2778 => Loss: 29.126697\n",
      "Iteration 2779 => Loss: 29.122856\n",
      "Iteration 2780 => Loss: 29.119018\n",
      "Iteration 2781 => Loss: 29.115182\n",
      "Iteration 2782 => Loss: 29.111347\n",
      "Iteration 2783 => Loss: 29.107515\n",
      "Iteration 2784 => Loss: 29.103685\n",
      "Iteration 2785 => Loss: 29.099856\n",
      "Iteration 2786 => Loss: 29.096030\n",
      "Iteration 2787 => Loss: 29.092206\n",
      "Iteration 2788 => Loss: 29.088383\n",
      "Iteration 2789 => Loss: 29.084563\n",
      "Iteration 2790 => Loss: 29.080745\n",
      "Iteration 2791 => Loss: 29.076928\n",
      "Iteration 2792 => Loss: 29.073114\n",
      "Iteration 2793 => Loss: 29.069302\n",
      "Iteration 2794 => Loss: 29.069289\n",
      "Iteration 2795 => Loss: 29.065453\n",
      "Iteration 2796 => Loss: 29.061620\n",
      "Iteration 2797 => Loss: 29.057788\n",
      "Iteration 2798 => Loss: 29.053958\n",
      "Iteration 2799 => Loss: 29.050131\n",
      "Iteration 2800 => Loss: 29.046305\n",
      "Iteration 2801 => Loss: 29.042481\n",
      "Iteration 2802 => Loss: 29.038660\n",
      "Iteration 2803 => Loss: 29.034840\n",
      "Iteration 2804 => Loss: 29.031022\n",
      "Iteration 2805 => Loss: 29.027207\n",
      "Iteration 2806 => Loss: 29.023393\n",
      "Iteration 2807 => Loss: 29.019581\n",
      "Iteration 2808 => Loss: 29.015772\n",
      "Iteration 2809 => Loss: 29.011964\n",
      "Iteration 2810 => Loss: 29.008158\n",
      "Iteration 2811 => Loss: 29.004355\n",
      "Iteration 2812 => Loss: 29.004349\n",
      "Iteration 2813 => Loss: 29.000522\n",
      "Iteration 2814 => Loss: 28.996697\n",
      "Iteration 2815 => Loss: 28.992874\n",
      "Iteration 2816 => Loss: 28.989053\n",
      "Iteration 2817 => Loss: 28.985234\n",
      "Iteration 2818 => Loss: 28.981417\n",
      "Iteration 2819 => Loss: 28.977602\n",
      "Iteration 2820 => Loss: 28.973789\n",
      "Iteration 2821 => Loss: 28.969978\n",
      "Iteration 2822 => Loss: 28.966169\n",
      "Iteration 2823 => Loss: 28.962362\n",
      "Iteration 2824 => Loss: 28.958557\n",
      "Iteration 2825 => Loss: 28.954754\n",
      "Iteration 2826 => Loss: 28.950953\n",
      "Iteration 2827 => Loss: 28.947154\n",
      "Iteration 2828 => Loss: 28.943357\n",
      "Iteration 2829 => Loss: 28.939562\n",
      "Iteration 2830 => Loss: 28.935769\n",
      "Iteration 2831 => Loss: 28.935744\n",
      "Iteration 2832 => Loss: 28.931928\n",
      "Iteration 2833 => Loss: 28.928113\n",
      "Iteration 2834 => Loss: 28.924301\n",
      "Iteration 2835 => Loss: 28.920491\n",
      "Iteration 2836 => Loss: 28.916682\n",
      "Iteration 2837 => Loss: 28.912876\n",
      "Iteration 2838 => Loss: 28.909072\n",
      "Iteration 2839 => Loss: 28.905269\n",
      "Iteration 2840 => Loss: 28.901469\n",
      "Iteration 2841 => Loss: 28.897671\n",
      "Iteration 2842 => Loss: 28.893874\n",
      "Iteration 2843 => Loss: 28.890080\n",
      "Iteration 2844 => Loss: 28.886288\n",
      "Iteration 2845 => Loss: 28.882497\n",
      "Iteration 2846 => Loss: 28.878709\n",
      "Iteration 2847 => Loss: 28.874923\n",
      "Iteration 2848 => Loss: 28.871138\n",
      "Iteration 2849 => Loss: 28.871121\n",
      "Iteration 2850 => Loss: 28.867313\n",
      "Iteration 2851 => Loss: 28.863508\n",
      "Iteration 2852 => Loss: 28.859704\n",
      "Iteration 2853 => Loss: 28.855902\n",
      "Iteration 2854 => Loss: 28.852103\n",
      "Iteration 2855 => Loss: 28.848305\n",
      "Iteration 2856 => Loss: 28.844509\n",
      "Iteration 2857 => Loss: 28.840716\n",
      "Iteration 2858 => Loss: 28.836924\n",
      "Iteration 2859 => Loss: 28.833134\n",
      "Iteration 2860 => Loss: 28.829347\n",
      "Iteration 2861 => Loss: 28.825561\n",
      "Iteration 2862 => Loss: 28.821777\n",
      "Iteration 2863 => Loss: 28.817996\n",
      "Iteration 2864 => Loss: 28.814216\n",
      "Iteration 2865 => Loss: 28.810438\n",
      "Iteration 2866 => Loss: 28.806663\n",
      "Iteration 2867 => Loss: 28.806652\n",
      "Iteration 2868 => Loss: 28.802853\n",
      "Iteration 2869 => Loss: 28.799056\n",
      "Iteration 2870 => Loss: 28.795261\n",
      "Iteration 2871 => Loss: 28.791468\n",
      "Iteration 2872 => Loss: 28.787677\n",
      "Iteration 2873 => Loss: 28.783888\n",
      "Iteration 2874 => Loss: 28.780101\n",
      "Iteration 2875 => Loss: 28.776316\n",
      "Iteration 2876 => Loss: 28.772533\n",
      "Iteration 2877 => Loss: 28.768752\n",
      "Iteration 2878 => Loss: 28.764973\n",
      "Iteration 2879 => Loss: 28.761196\n",
      "Iteration 2880 => Loss: 28.757421\n",
      "Iteration 2881 => Loss: 28.753648\n",
      "Iteration 2882 => Loss: 28.749877\n",
      "Iteration 2883 => Loss: 28.746108\n",
      "Iteration 2884 => Loss: 28.742341\n",
      "Iteration 2885 => Loss: 28.742338\n",
      "Iteration 2886 => Loss: 28.738547\n",
      "Iteration 2887 => Loss: 28.734759\n",
      "Iteration 2888 => Loss: 28.730973\n",
      "Iteration 2889 => Loss: 28.727188\n",
      "Iteration 2890 => Loss: 28.723406\n",
      "Iteration 2891 => Loss: 28.719626\n",
      "Iteration 2892 => Loss: 28.715847\n",
      "Iteration 2893 => Loss: 28.712071\n",
      "Iteration 2894 => Loss: 28.708297\n",
      "Iteration 2895 => Loss: 28.704524\n",
      "Iteration 2896 => Loss: 28.700754\n",
      "Iteration 2897 => Loss: 28.696986\n",
      "Iteration 2898 => Loss: 28.693219\n",
      "Iteration 2899 => Loss: 28.689455\n",
      "Iteration 2900 => Loss: 28.685693\n",
      "Iteration 2901 => Loss: 28.681932\n",
      "Iteration 2902 => Loss: 28.678174\n",
      "Iteration 2903 => Loss: 28.674418\n",
      "Iteration 2904 => Loss: 28.674396\n",
      "Iteration 2905 => Loss: 28.670616\n",
      "Iteration 2906 => Loss: 28.666838\n",
      "Iteration 2907 => Loss: 28.663063\n",
      "Iteration 2908 => Loss: 28.659289\n",
      "Iteration 2909 => Loss: 28.655517\n",
      "Iteration 2910 => Loss: 28.651748\n",
      "Iteration 2911 => Loss: 28.647980\n",
      "Iteration 2912 => Loss: 28.644214\n",
      "Iteration 2913 => Loss: 28.640451\n",
      "Iteration 2914 => Loss: 28.636689\n",
      "Iteration 2915 => Loss: 28.632929\n",
      "Iteration 2916 => Loss: 28.629172\n",
      "Iteration 2917 => Loss: 28.625416\n",
      "Iteration 2918 => Loss: 28.621662\n",
      "Iteration 2919 => Loss: 28.617911\n",
      "Iteration 2920 => Loss: 28.614161\n",
      "Iteration 2921 => Loss: 28.610413\n",
      "Iteration 2922 => Loss: 28.610398\n",
      "Iteration 2923 => Loss: 28.606627\n",
      "Iteration 2924 => Loss: 28.602858\n",
      "Iteration 2925 => Loss: 28.599091\n",
      "Iteration 2926 => Loss: 28.595326\n",
      "Iteration 2927 => Loss: 28.591563\n",
      "Iteration 2928 => Loss: 28.587802\n",
      "Iteration 2929 => Loss: 28.584043\n",
      "Iteration 2930 => Loss: 28.580286\n",
      "Iteration 2931 => Loss: 28.576531\n",
      "Iteration 2932 => Loss: 28.572778\n",
      "Iteration 2933 => Loss: 28.569027\n",
      "Iteration 2934 => Loss: 28.565278\n",
      "Iteration 2935 => Loss: 28.561531\n",
      "Iteration 2936 => Loss: 28.557786\n",
      "Iteration 2937 => Loss: 28.554043\n",
      "Iteration 2938 => Loss: 28.550302\n",
      "Iteration 2939 => Loss: 28.546563\n",
      "Iteration 2940 => Loss: 28.546555\n",
      "Iteration 2941 => Loss: 28.542793\n",
      "Iteration 2942 => Loss: 28.539032\n",
      "Iteration 2943 => Loss: 28.535274\n",
      "Iteration 2944 => Loss: 28.531518\n",
      "Iteration 2945 => Loss: 28.527763\n",
      "Iteration 2946 => Loss: 28.524011\n",
      "Iteration 2947 => Loss: 28.520261\n",
      "Iteration 2948 => Loss: 28.516512\n",
      "Iteration 2949 => Loss: 28.512766\n",
      "Iteration 2950 => Loss: 28.509022\n",
      "Iteration 2951 => Loss: 28.505279\n",
      "Iteration 2952 => Loss: 28.501539\n",
      "Iteration 2953 => Loss: 28.497801\n",
      "Iteration 2954 => Loss: 28.494064\n",
      "Iteration 2955 => Loss: 28.490330\n",
      "Iteration 2956 => Loss: 28.486598\n",
      "Iteration 2957 => Loss: 28.482867\n",
      "Iteration 2958 => Loss: 28.482866\n",
      "Iteration 2959 => Loss: 28.479112\n",
      "Iteration 2960 => Loss: 28.475361\n",
      "Iteration 2961 => Loss: 28.471611\n",
      "Iteration 2962 => Loss: 28.467863\n",
      "Iteration 2963 => Loss: 28.464118\n",
      "Iteration 2964 => Loss: 28.460374\n",
      "Iteration 2965 => Loss: 28.456632\n",
      "Iteration 2966 => Loss: 28.452893\n",
      "Iteration 2967 => Loss: 28.449155\n",
      "Iteration 2968 => Loss: 28.445419\n",
      "Iteration 2969 => Loss: 28.441686\n",
      "Iteration 2970 => Loss: 28.437954\n",
      "Iteration 2971 => Loss: 28.434224\n",
      "Iteration 2972 => Loss: 28.430497\n",
      "Iteration 2973 => Loss: 28.426771\n",
      "Iteration 2974 => Loss: 28.423047\n",
      "Iteration 2975 => Loss: 28.419326\n",
      "Iteration 2976 => Loss: 28.415606\n",
      "Iteration 2977 => Loss: 28.415587\n",
      "Iteration 2978 => Loss: 28.411844\n",
      "Iteration 2979 => Loss: 28.408103\n",
      "Iteration 2980 => Loss: 28.404364\n",
      "Iteration 2981 => Loss: 28.400627\n",
      "Iteration 2982 => Loss: 28.396892\n",
      "Iteration 2983 => Loss: 28.393159\n",
      "Iteration 2984 => Loss: 28.389428\n",
      "Iteration 2985 => Loss: 28.385699\n",
      "Iteration 2986 => Loss: 28.381972\n",
      "Iteration 2987 => Loss: 28.378247\n",
      "Iteration 2988 => Loss: 28.374524\n",
      "Iteration 2989 => Loss: 28.370803\n",
      "Iteration 2990 => Loss: 28.367084\n",
      "Iteration 2991 => Loss: 28.363367\n",
      "Iteration 2992 => Loss: 28.359652\n",
      "Iteration 2993 => Loss: 28.355939\n",
      "Iteration 2994 => Loss: 28.352228\n",
      "Iteration 2995 => Loss: 28.352215\n",
      "Iteration 2996 => Loss: 28.348481\n",
      "Iteration 2997 => Loss: 28.344748\n",
      "Iteration 2998 => Loss: 28.341018\n",
      "Iteration 2999 => Loss: 28.337290\n",
      "Iteration 3000 => Loss: 28.333563\n",
      "Iteration 3001 => Loss: 28.329839\n",
      "Iteration 3002 => Loss: 28.326117\n",
      "Iteration 3003 => Loss: 28.322396\n",
      "Iteration 3004 => Loss: 28.318678\n",
      "Iteration 3005 => Loss: 28.314962\n",
      "Iteration 3006 => Loss: 28.311247\n",
      "Iteration 3007 => Loss: 28.307535\n",
      "Iteration 3008 => Loss: 28.303825\n",
      "Iteration 3009 => Loss: 28.300116\n",
      "Iteration 3010 => Loss: 28.296410\n",
      "Iteration 3011 => Loss: 28.292706\n",
      "Iteration 3012 => Loss: 28.289003\n",
      "Iteration 3013 => Loss: 28.288997\n",
      "Iteration 3014 => Loss: 28.285272\n",
      "Iteration 3015 => Loss: 28.281548\n",
      "Iteration 3016 => Loss: 28.277826\n",
      "Iteration 3017 => Loss: 28.274107\n",
      "Iteration 3018 => Loss: 28.270389\n",
      "Iteration 3019 => Loss: 28.266673\n",
      "Iteration 3020 => Loss: 28.262960\n",
      "Iteration 3021 => Loss: 28.259248\n",
      "Iteration 3022 => Loss: 28.255538\n",
      "Iteration 3023 => Loss: 28.251831\n",
      "Iteration 3024 => Loss: 28.248125\n",
      "Iteration 3025 => Loss: 28.244421\n",
      "Iteration 3026 => Loss: 28.240720\n",
      "Iteration 3027 => Loss: 28.237020\n",
      "Iteration 3028 => Loss: 28.233322\n",
      "Iteration 3029 => Loss: 28.229627\n",
      "Iteration 3030 => Loss: 28.225933\n",
      "Iteration 3031 => Loss: 28.222241\n",
      "Iteration 3032 => Loss: 28.222217\n",
      "Iteration 3033 => Loss: 28.218502\n",
      "Iteration 3034 => Loss: 28.214789\n",
      "Iteration 3035 => Loss: 28.211078\n",
      "Iteration 3036 => Loss: 28.207369\n",
      "Iteration 3037 => Loss: 28.203662\n",
      "Iteration 3038 => Loss: 28.199957\n",
      "Iteration 3039 => Loss: 28.196254\n",
      "Iteration 3040 => Loss: 28.192553\n",
      "Iteration 3041 => Loss: 28.188854\n",
      "Iteration 3042 => Loss: 28.185157\n",
      "Iteration 3043 => Loss: 28.181462\n",
      "Iteration 3044 => Loss: 28.177769\n",
      "Iteration 3045 => Loss: 28.174078\n",
      "Iteration 3046 => Loss: 28.170389\n",
      "Iteration 3047 => Loss: 28.166702\n",
      "Iteration 3048 => Loss: 28.163017\n",
      "Iteration 3049 => Loss: 28.159334\n",
      "Iteration 3050 => Loss: 28.159317\n",
      "Iteration 3051 => Loss: 28.155611\n",
      "Iteration 3052 => Loss: 28.151906\n",
      "Iteration 3053 => Loss: 28.148204\n",
      "Iteration 3054 => Loss: 28.144504\n",
      "Iteration 3055 => Loss: 28.140805\n",
      "Iteration 3056 => Loss: 28.137109\n",
      "Iteration 3057 => Loss: 28.133415\n",
      "Iteration 3058 => Loss: 28.129722\n",
      "Iteration 3059 => Loss: 28.126032\n",
      "Iteration 3060 => Loss: 28.122344\n",
      "Iteration 3061 => Loss: 28.118657\n",
      "Iteration 3062 => Loss: 28.114973\n",
      "Iteration 3063 => Loss: 28.111291\n",
      "Iteration 3064 => Loss: 28.107610\n",
      "Iteration 3065 => Loss: 28.103932\n",
      "Iteration 3066 => Loss: 28.100256\n",
      "Iteration 3067 => Loss: 28.096581\n",
      "Iteration 3068 => Loss: 28.096571\n",
      "Iteration 3069 => Loss: 28.092874\n",
      "Iteration 3070 => Loss: 28.089178\n",
      "Iteration 3071 => Loss: 28.085484\n",
      "Iteration 3072 => Loss: 28.081793\n",
      "Iteration 3073 => Loss: 28.078103\n",
      "Iteration 3074 => Loss: 28.074415\n",
      "Iteration 3075 => Loss: 28.070730\n",
      "Iteration 3076 => Loss: 28.067046\n",
      "Iteration 3077 => Loss: 28.063364\n",
      "Iteration 3078 => Loss: 28.059685\n",
      "Iteration 3079 => Loss: 28.056007\n",
      "Iteration 3080 => Loss: 28.052331\n",
      "Iteration 3081 => Loss: 28.048658\n",
      "Iteration 3082 => Loss: 28.044986\n",
      "Iteration 3083 => Loss: 28.041316\n",
      "Iteration 3084 => Loss: 28.037649\n",
      "Iteration 3085 => Loss: 28.033983\n",
      "Iteration 3086 => Loss: 28.033980\n",
      "Iteration 3087 => Loss: 28.030291\n",
      "Iteration 3088 => Loss: 28.026604\n",
      "Iteration 3089 => Loss: 28.022919\n",
      "Iteration 3090 => Loss: 28.019236\n",
      "Iteration 3091 => Loss: 28.015555\n",
      "Iteration 3092 => Loss: 28.011876\n",
      "Iteration 3093 => Loss: 28.008199\n",
      "Iteration 3094 => Loss: 28.004524\n",
      "Iteration 3095 => Loss: 28.000851\n",
      "Iteration 3096 => Loss: 27.997180\n",
      "Iteration 3097 => Loss: 27.993511\n",
      "Iteration 3098 => Loss: 27.989844\n",
      "Iteration 3099 => Loss: 27.986179\n",
      "Iteration 3100 => Loss: 27.982516\n",
      "Iteration 3101 => Loss: 27.978855\n",
      "Iteration 3102 => Loss: 27.975196\n",
      "Iteration 3103 => Loss: 27.971539\n",
      "Iteration 3104 => Loss: 27.967884\n",
      "Iteration 3105 => Loss: 27.967862\n",
      "Iteration 3106 => Loss: 27.964183\n",
      "Iteration 3107 => Loss: 27.960507\n",
      "Iteration 3108 => Loss: 27.956833\n",
      "Iteration 3109 => Loss: 27.953160\n",
      "Iteration 3110 => Loss: 27.949490\n",
      "Iteration 3111 => Loss: 27.945822\n",
      "Iteration 3112 => Loss: 27.942155\n",
      "Iteration 3113 => Loss: 27.938491\n",
      "Iteration 3114 => Loss: 27.934829\n",
      "Iteration 3115 => Loss: 27.931168\n",
      "Iteration 3116 => Loss: 27.927510\n",
      "Iteration 3117 => Loss: 27.923854\n",
      "Iteration 3118 => Loss: 27.920199\n",
      "Iteration 3119 => Loss: 27.916547\n",
      "Iteration 3120 => Loss: 27.912897\n",
      "Iteration 3121 => Loss: 27.909248\n",
      "Iteration 3122 => Loss: 27.905602\n",
      "Iteration 3123 => Loss: 27.905587\n",
      "Iteration 3124 => Loss: 27.901918\n",
      "Iteration 3125 => Loss: 27.898250\n",
      "Iteration 3126 => Loss: 27.894584\n",
      "Iteration 3127 => Loss: 27.890921\n",
      "Iteration 3128 => Loss: 27.887259\n",
      "Iteration 3129 => Loss: 27.883599\n",
      "Iteration 3130 => Loss: 27.879942\n",
      "Iteration 3131 => Loss: 27.876286\n",
      "Iteration 3132 => Loss: 27.872632\n",
      "Iteration 3133 => Loss: 27.868981\n",
      "Iteration 3134 => Loss: 27.865331\n",
      "Iteration 3135 => Loss: 27.861683\n",
      "Iteration 3136 => Loss: 27.858038\n",
      "Iteration 3137 => Loss: 27.854394\n",
      "Iteration 3138 => Loss: 27.850752\n",
      "Iteration 3139 => Loss: 27.847113\n",
      "Iteration 3140 => Loss: 27.843475\n",
      "Iteration 3141 => Loss: 27.843467\n",
      "Iteration 3142 => Loss: 27.839806\n",
      "Iteration 3143 => Loss: 27.836147\n",
      "Iteration 3144 => Loss: 27.832490\n",
      "Iteration 3145 => Loss: 27.828835\n",
      "Iteration 3146 => Loss: 27.825182\n",
      "Iteration 3147 => Loss: 27.821531\n",
      "Iteration 3148 => Loss: 27.817882\n",
      "Iteration 3149 => Loss: 27.814235\n",
      "Iteration 3150 => Loss: 27.810590\n",
      "Iteration 3151 => Loss: 27.806947\n",
      "Iteration 3152 => Loss: 27.803306\n",
      "Iteration 3153 => Loss: 27.799667\n",
      "Iteration 3154 => Loss: 27.796030\n",
      "Iteration 3155 => Loss: 27.792395\n",
      "Iteration 3156 => Loss: 27.788762\n",
      "Iteration 3157 => Loss: 27.785131\n",
      "Iteration 3158 => Loss: 27.781502\n",
      "Iteration 3159 => Loss: 27.781501\n",
      "Iteration 3160 => Loss: 27.777849\n",
      "Iteration 3161 => Loss: 27.774199\n",
      "Iteration 3162 => Loss: 27.770550\n",
      "Iteration 3163 => Loss: 27.766904\n",
      "Iteration 3164 => Loss: 27.763260\n",
      "Iteration 3165 => Loss: 27.759617\n",
      "Iteration 3166 => Loss: 27.755977\n",
      "Iteration 3167 => Loss: 27.752339\n",
      "Iteration 3168 => Loss: 27.748702\n",
      "Iteration 3169 => Loss: 27.745068\n",
      "Iteration 3170 => Loss: 27.741436\n",
      "Iteration 3171 => Loss: 27.737805\n",
      "Iteration 3172 => Loss: 27.734177\n",
      "Iteration 3173 => Loss: 27.730551\n",
      "Iteration 3174 => Loss: 27.726926\n",
      "Iteration 3175 => Loss: 27.723304\n",
      "Iteration 3176 => Loss: 27.719684\n",
      "Iteration 3177 => Loss: 27.716065\n",
      "Iteration 3178 => Loss: 27.716046\n",
      "Iteration 3179 => Loss: 27.712404\n",
      "Iteration 3180 => Loss: 27.708765\n",
      "Iteration 3181 => Loss: 27.705127\n",
      "Iteration 3182 => Loss: 27.701491\n",
      "Iteration 3183 => Loss: 27.697858\n",
      "Iteration 3184 => Loss: 27.694226\n",
      "Iteration 3185 => Loss: 27.690596\n",
      "Iteration 3186 => Loss: 27.686969\n",
      "Iteration 3187 => Loss: 27.683343\n",
      "Iteration 3188 => Loss: 27.679719\n",
      "Iteration 3189 => Loss: 27.676098\n",
      "Iteration 3190 => Loss: 27.672478\n",
      "Iteration 3191 => Loss: 27.668860\n",
      "Iteration 3192 => Loss: 27.665245\n",
      "Iteration 3193 => Loss: 27.661631\n",
      "Iteration 3194 => Loss: 27.658019\n",
      "Iteration 3195 => Loss: 27.654410\n",
      "Iteration 3196 => Loss: 27.654397\n",
      "Iteration 3197 => Loss: 27.650764\n",
      "Iteration 3198 => Loss: 27.647133\n",
      "Iteration 3199 => Loss: 27.643504\n",
      "Iteration 3200 => Loss: 27.639877\n",
      "Iteration 3201 => Loss: 27.636252\n",
      "Iteration 3202 => Loss: 27.632629\n",
      "Iteration 3203 => Loss: 27.629008\n",
      "Iteration 3204 => Loss: 27.625389\n",
      "Iteration 3205 => Loss: 27.621772\n",
      "Iteration 3206 => Loss: 27.618157\n",
      "Iteration 3207 => Loss: 27.614544\n",
      "Iteration 3208 => Loss: 27.610933\n",
      "Iteration 3209 => Loss: 27.607324\n",
      "Iteration 3210 => Loss: 27.603717\n",
      "Iteration 3211 => Loss: 27.600112\n",
      "Iteration 3212 => Loss: 27.596509\n",
      "Iteration 3213 => Loss: 27.592908\n",
      "Iteration 3214 => Loss: 27.592903\n",
      "Iteration 3215 => Loss: 27.589278\n",
      "Iteration 3216 => Loss: 27.585656\n",
      "Iteration 3217 => Loss: 27.582036\n",
      "Iteration 3218 => Loss: 27.578417\n",
      "Iteration 3219 => Loss: 27.574801\n",
      "Iteration 3220 => Loss: 27.571187\n",
      "Iteration 3221 => Loss: 27.567574\n",
      "Iteration 3222 => Loss: 27.563964\n",
      "Iteration 3223 => Loss: 27.560356\n",
      "Iteration 3224 => Loss: 27.556749\n",
      "Iteration 3225 => Loss: 27.553145\n",
      "Iteration 3226 => Loss: 27.549543\n",
      "Iteration 3227 => Loss: 27.545942\n",
      "Iteration 3228 => Loss: 27.542344\n",
      "Iteration 3229 => Loss: 27.538748\n",
      "Iteration 3230 => Loss: 27.535153\n",
      "Iteration 3231 => Loss: 27.531561\n",
      "Iteration 3232 => Loss: 27.527971\n",
      "Iteration 3233 => Loss: 27.527947\n",
      "Iteration 3234 => Loss: 27.524333\n",
      "Iteration 3235 => Loss: 27.520721\n",
      "Iteration 3236 => Loss: 27.517112\n",
      "Iteration 3237 => Loss: 27.513504\n",
      "Iteration 3238 => Loss: 27.509898\n",
      "Iteration 3239 => Loss: 27.506295\n",
      "Iteration 3240 => Loss: 27.502693\n",
      "Iteration 3241 => Loss: 27.499093\n",
      "Iteration 3242 => Loss: 27.495496\n",
      "Iteration 3243 => Loss: 27.491900\n",
      "Iteration 3244 => Loss: 27.488306\n",
      "Iteration 3245 => Loss: 27.484715\n",
      "Iteration 3246 => Loss: 27.481125\n",
      "Iteration 3247 => Loss: 27.477537\n",
      "Iteration 3248 => Loss: 27.473952\n",
      "Iteration 3249 => Loss: 27.470368\n",
      "Iteration 3250 => Loss: 27.466786\n",
      "Iteration 3251 => Loss: 27.466770\n",
      "Iteration 3252 => Loss: 27.463165\n",
      "Iteration 3253 => Loss: 27.459562\n",
      "Iteration 3254 => Loss: 27.455961\n",
      "Iteration 3255 => Loss: 27.452362\n",
      "Iteration 3256 => Loss: 27.448765\n",
      "Iteration 3257 => Loss: 27.445170\n",
      "Iteration 3258 => Loss: 27.441577\n",
      "Iteration 3259 => Loss: 27.437986\n",
      "Iteration 3260 => Loss: 27.434397\n",
      "Iteration 3261 => Loss: 27.430810\n",
      "Iteration 3262 => Loss: 27.427225\n",
      "Iteration 3263 => Loss: 27.423642\n",
      "Iteration 3264 => Loss: 27.420061\n",
      "Iteration 3265 => Loss: 27.416482\n",
      "Iteration 3266 => Loss: 27.412905\n",
      "Iteration 3267 => Loss: 27.409330\n",
      "Iteration 3268 => Loss: 27.405757\n",
      "Iteration 3269 => Loss: 27.405747\n",
      "Iteration 3270 => Loss: 27.402150\n",
      "Iteration 3271 => Loss: 27.398556\n",
      "Iteration 3272 => Loss: 27.394964\n",
      "Iteration 3273 => Loss: 27.391373\n",
      "Iteration 3274 => Loss: 27.387785\n",
      "Iteration 3275 => Loss: 27.384199\n",
      "Iteration 3276 => Loss: 27.380614\n",
      "Iteration 3277 => Loss: 27.377032\n",
      "Iteration 3278 => Loss: 27.373452\n",
      "Iteration 3279 => Loss: 27.369873\n",
      "Iteration 3280 => Loss: 27.366297\n",
      "Iteration 3281 => Loss: 27.362723\n",
      "Iteration 3282 => Loss: 27.359150\n",
      "Iteration 3283 => Loss: 27.355580\n",
      "Iteration 3284 => Loss: 27.352012\n",
      "Iteration 3285 => Loss: 27.348445\n",
      "Iteration 3286 => Loss: 27.344881\n",
      "Iteration 3287 => Loss: 27.344878\n",
      "Iteration 3288 => Loss: 27.341290\n",
      "Iteration 3289 => Loss: 27.337704\n",
      "Iteration 3290 => Loss: 27.334121\n",
      "Iteration 3291 => Loss: 27.330539\n",
      "Iteration 3292 => Loss: 27.326959\n",
      "Iteration 3293 => Loss: 27.323382\n",
      "Iteration 3294 => Loss: 27.319806\n",
      "Iteration 3295 => Loss: 27.316232\n",
      "Iteration 3296 => Loss: 27.312661\n",
      "Iteration 3297 => Loss: 27.309091\n",
      "Iteration 3298 => Loss: 27.305523\n",
      "Iteration 3299 => Loss: 27.301958\n",
      "Iteration 3300 => Loss: 27.298394\n",
      "Iteration 3301 => Loss: 27.294832\n",
      "Iteration 3302 => Loss: 27.291273\n",
      "Iteration 3303 => Loss: 27.287715\n",
      "Iteration 3304 => Loss: 27.284159\n",
      "Iteration 3305 => Loss: 27.280606\n",
      "Iteration 3306 => Loss: 27.280584\n",
      "Iteration 3307 => Loss: 27.277007\n",
      "Iteration 3308 => Loss: 27.273432\n",
      "Iteration 3309 => Loss: 27.269859\n",
      "Iteration 3310 => Loss: 27.266288\n",
      "Iteration 3311 => Loss: 27.262719\n",
      "Iteration 3312 => Loss: 27.259152\n",
      "Iteration 3313 => Loss: 27.255587\n",
      "Iteration 3314 => Loss: 27.252024\n",
      "Iteration 3315 => Loss: 27.248463\n",
      "Iteration 3316 => Loss: 27.244904\n",
      "Iteration 3317 => Loss: 27.241347\n",
      "Iteration 3318 => Loss: 27.237792\n",
      "Iteration 3319 => Loss: 27.234239\n",
      "Iteration 3320 => Loss: 27.230688\n",
      "Iteration 3321 => Loss: 27.227139\n",
      "Iteration 3322 => Loss: 27.223592\n",
      "Iteration 3323 => Loss: 27.220047\n",
      "Iteration 3324 => Loss: 27.220033\n",
      "Iteration 3325 => Loss: 27.216464\n",
      "Iteration 3326 => Loss: 27.212898\n",
      "Iteration 3327 => Loss: 27.209334\n",
      "Iteration 3328 => Loss: 27.205771\n",
      "Iteration 3329 => Loss: 27.202211\n",
      "Iteration 3330 => Loss: 27.198653\n",
      "Iteration 3331 => Loss: 27.195096\n",
      "Iteration 3332 => Loss: 27.191542\n",
      "Iteration 3333 => Loss: 27.187990\n",
      "Iteration 3334 => Loss: 27.184439\n",
      "Iteration 3335 => Loss: 27.180891\n",
      "Iteration 3336 => Loss: 27.177345\n",
      "Iteration 3337 => Loss: 27.173800\n",
      "Iteration 3338 => Loss: 27.170258\n",
      "Iteration 3339 => Loss: 27.166718\n",
      "Iteration 3340 => Loss: 27.163179\n",
      "Iteration 3341 => Loss: 27.159643\n",
      "Iteration 3342 => Loss: 27.159636\n",
      "Iteration 3343 => Loss: 27.156076\n",
      "Iteration 3344 => Loss: 27.152518\n",
      "Iteration 3345 => Loss: 27.148963\n",
      "Iteration 3346 => Loss: 27.145409\n",
      "Iteration 3347 => Loss: 27.141857\n",
      "Iteration 3348 => Loss: 27.138308\n",
      "Iteration 3349 => Loss: 27.134760\n",
      "Iteration 3350 => Loss: 27.131214\n",
      "Iteration 3351 => Loss: 27.127671\n",
      "Iteration 3352 => Loss: 27.124129\n",
      "Iteration 3353 => Loss: 27.120589\n",
      "Iteration 3354 => Loss: 27.117052\n",
      "Iteration 3355 => Loss: 27.113516\n",
      "Iteration 3356 => Loss: 27.109982\n",
      "Iteration 3357 => Loss: 27.106451\n",
      "Iteration 3358 => Loss: 27.102921\n",
      "Iteration 3359 => Loss: 27.099393\n",
      "Iteration 3360 => Loss: 27.099393\n",
      "Iteration 3361 => Loss: 27.095842\n",
      "Iteration 3362 => Loss: 27.092293\n",
      "Iteration 3363 => Loss: 27.088746\n",
      "Iteration 3364 => Loss: 27.085201\n",
      "Iteration 3365 => Loss: 27.081658\n",
      "Iteration 3366 => Loss: 27.078117\n",
      "Iteration 3367 => Loss: 27.074578\n",
      "Iteration 3368 => Loss: 27.071041\n",
      "Iteration 3369 => Loss: 27.067506\n",
      "Iteration 3370 => Loss: 27.063973\n",
      "Iteration 3371 => Loss: 27.060442\n",
      "Iteration 3372 => Loss: 27.056913\n",
      "Iteration 3373 => Loss: 27.053386\n",
      "Iteration 3374 => Loss: 27.049861\n",
      "Iteration 3375 => Loss: 27.046338\n",
      "Iteration 3376 => Loss: 27.042817\n",
      "Iteration 3377 => Loss: 27.039298\n",
      "Iteration 3378 => Loss: 27.035781\n",
      "Iteration 3379 => Loss: 27.035761\n",
      "Iteration 3380 => Loss: 27.032221\n",
      "Iteration 3381 => Loss: 27.028683\n",
      "Iteration 3382 => Loss: 27.025146\n",
      "Iteration 3383 => Loss: 27.021612\n",
      "Iteration 3384 => Loss: 27.018080\n",
      "Iteration 3385 => Loss: 27.014549\n",
      "Iteration 3386 => Loss: 27.011021\n",
      "Iteration 3387 => Loss: 27.007495\n",
      "Iteration 3388 => Loss: 27.003970\n",
      "Iteration 3389 => Loss: 27.000448\n",
      "Iteration 3390 => Loss: 26.996928\n",
      "Iteration 3391 => Loss: 26.993409\n",
      "Iteration 3392 => Loss: 26.989893\n",
      "Iteration 3393 => Loss: 26.986379\n",
      "Iteration 3394 => Loss: 26.982866\n",
      "Iteration 3395 => Loss: 26.979356\n",
      "Iteration 3396 => Loss: 26.975848\n",
      "Iteration 3397 => Loss: 26.975836\n",
      "Iteration 3398 => Loss: 26.972304\n",
      "Iteration 3399 => Loss: 26.968774\n",
      "Iteration 3400 => Loss: 26.965247\n",
      "Iteration 3401 => Loss: 26.961721\n",
      "Iteration 3402 => Loss: 26.958197\n",
      "Iteration 3403 => Loss: 26.954676\n",
      "Iteration 3404 => Loss: 26.951156\n",
      "Iteration 3405 => Loss: 26.947638\n",
      "Iteration 3406 => Loss: 26.944123\n",
      "Iteration 3407 => Loss: 26.940609\n",
      "Iteration 3408 => Loss: 26.937097\n",
      "Iteration 3409 => Loss: 26.933588\n",
      "Iteration 3410 => Loss: 26.930080\n",
      "Iteration 3411 => Loss: 26.926574\n",
      "Iteration 3412 => Loss: 26.923071\n",
      "Iteration 3413 => Loss: 26.919569\n",
      "Iteration 3414 => Loss: 26.916069\n",
      "Iteration 3415 => Loss: 26.916064\n",
      "Iteration 3416 => Loss: 26.912541\n",
      "Iteration 3417 => Loss: 26.909020\n",
      "Iteration 3418 => Loss: 26.905501\n",
      "Iteration 3419 => Loss: 26.901984\n",
      "Iteration 3420 => Loss: 26.898469\n",
      "Iteration 3421 => Loss: 26.894956\n",
      "Iteration 3422 => Loss: 26.891445\n",
      "Iteration 3423 => Loss: 26.887936\n",
      "Iteration 3424 => Loss: 26.884429\n",
      "Iteration 3425 => Loss: 26.880924\n",
      "Iteration 3426 => Loss: 26.877421\n",
      "Iteration 3427 => Loss: 26.873920\n",
      "Iteration 3428 => Loss: 26.870421\n",
      "Iteration 3429 => Loss: 26.866924\n",
      "Iteration 3430 => Loss: 26.863429\n",
      "Iteration 3431 => Loss: 26.859936\n",
      "Iteration 3432 => Loss: 26.856445\n",
      "Iteration 3433 => Loss: 26.852956\n",
      "Iteration 3434 => Loss: 26.852933\n",
      "Iteration 3435 => Loss: 26.849420\n",
      "Iteration 3436 => Loss: 26.845910\n",
      "Iteration 3437 => Loss: 26.842402\n",
      "Iteration 3438 => Loss: 26.838895\n",
      "Iteration 3439 => Loss: 26.835391\n",
      "Iteration 3440 => Loss: 26.831889\n",
      "Iteration 3441 => Loss: 26.828388\n",
      "Iteration 3442 => Loss: 26.824890\n",
      "Iteration 3443 => Loss: 26.821394\n",
      "Iteration 3444 => Loss: 26.817899\n",
      "Iteration 3445 => Loss: 26.814407\n",
      "Iteration 3446 => Loss: 26.810917\n",
      "Iteration 3447 => Loss: 26.807428\n",
      "Iteration 3448 => Loss: 26.803942\n",
      "Iteration 3449 => Loss: 26.800458\n",
      "Iteration 3450 => Loss: 26.796975\n",
      "Iteration 3451 => Loss: 26.793495\n",
      "Iteration 3452 => Loss: 26.793478\n",
      "Iteration 3453 => Loss: 26.789975\n",
      "Iteration 3454 => Loss: 26.786473\n",
      "Iteration 3455 => Loss: 26.782973\n",
      "Iteration 3456 => Loss: 26.779476\n",
      "Iteration 3457 => Loss: 26.775980\n",
      "Iteration 3458 => Loss: 26.772486\n",
      "Iteration 3459 => Loss: 26.768995\n",
      "Iteration 3460 => Loss: 26.765505\n",
      "Iteration 3461 => Loss: 26.762017\n",
      "Iteration 3462 => Loss: 26.758532\n",
      "Iteration 3463 => Loss: 26.755048\n",
      "Iteration 3464 => Loss: 26.751566\n",
      "Iteration 3465 => Loss: 26.748087\n",
      "Iteration 3466 => Loss: 26.744609\n",
      "Iteration 3467 => Loss: 26.741133\n",
      "Iteration 3468 => Loss: 26.737660\n",
      "Iteration 3469 => Loss: 26.734188\n",
      "Iteration 3470 => Loss: 26.734178\n",
      "Iteration 3471 => Loss: 26.730683\n",
      "Iteration 3472 => Loss: 26.727190\n",
      "Iteration 3473 => Loss: 26.723699\n",
      "Iteration 3474 => Loss: 26.720210\n",
      "Iteration 3475 => Loss: 26.716723\n",
      "Iteration 3476 => Loss: 26.713238\n",
      "Iteration 3477 => Loss: 26.709755\n",
      "Iteration 3478 => Loss: 26.706274\n",
      "Iteration 3479 => Loss: 26.702795\n",
      "Iteration 3480 => Loss: 26.699318\n",
      "Iteration 3481 => Loss: 26.695843\n",
      "Iteration 3482 => Loss: 26.692370\n",
      "Iteration 3483 => Loss: 26.688899\n",
      "Iteration 3484 => Loss: 26.685430\n",
      "Iteration 3485 => Loss: 26.681963\n",
      "Iteration 3486 => Loss: 26.678498\n",
      "Iteration 3487 => Loss: 26.675035\n",
      "Iteration 3488 => Loss: 26.675032\n",
      "Iteration 3489 => Loss: 26.671546\n",
      "Iteration 3490 => Loss: 26.668062\n",
      "Iteration 3491 => Loss: 26.664579\n",
      "Iteration 3492 => Loss: 26.661099\n",
      "Iteration 3493 => Loss: 26.657621\n",
      "Iteration 3494 => Loss: 26.654144\n",
      "Iteration 3495 => Loss: 26.650670\n",
      "Iteration 3496 => Loss: 26.647198\n",
      "Iteration 3497 => Loss: 26.643727\n",
      "Iteration 3498 => Loss: 26.640259\n",
      "Iteration 3499 => Loss: 26.636793\n",
      "Iteration 3500 => Loss: 26.633328\n",
      "Iteration 3501 => Loss: 26.629866\n",
      "Iteration 3502 => Loss: 26.626406\n",
      "Iteration 3503 => Loss: 26.622947\n",
      "Iteration 3504 => Loss: 26.619491\n",
      "Iteration 3505 => Loss: 26.616037\n",
      "Iteration 3506 => Loss: 26.612584\n",
      "Iteration 3507 => Loss: 26.612563\n",
      "Iteration 3508 => Loss: 26.609087\n",
      "Iteration 3509 => Loss: 26.605614\n",
      "Iteration 3510 => Loss: 26.602142\n",
      "Iteration 3511 => Loss: 26.598672\n",
      "Iteration 3512 => Loss: 26.595205\n",
      "Iteration 3513 => Loss: 26.591739\n",
      "Iteration 3514 => Loss: 26.588275\n",
      "Iteration 3515 => Loss: 26.584814\n",
      "Iteration 3516 => Loss: 26.581354\n",
      "Iteration 3517 => Loss: 26.577896\n",
      "Iteration 3518 => Loss: 26.574441\n",
      "Iteration 3519 => Loss: 26.570987\n",
      "Iteration 3520 => Loss: 26.567535\n",
      "Iteration 3521 => Loss: 26.564086\n",
      "Iteration 3522 => Loss: 26.560638\n",
      "Iteration 3523 => Loss: 26.557192\n",
      "Iteration 3524 => Loss: 26.553749\n",
      "Iteration 3525 => Loss: 26.553735\n",
      "Iteration 3526 => Loss: 26.550268\n",
      "Iteration 3527 => Loss: 26.546803\n",
      "Iteration 3528 => Loss: 26.543340\n",
      "Iteration 3529 => Loss: 26.539879\n",
      "Iteration 3530 => Loss: 26.536420\n",
      "Iteration 3531 => Loss: 26.532963\n",
      "Iteration 3532 => Loss: 26.529508\n",
      "Iteration 3533 => Loss: 26.526055\n",
      "Iteration 3534 => Loss: 26.522604\n",
      "Iteration 3535 => Loss: 26.519155\n",
      "Iteration 3536 => Loss: 26.515708\n",
      "Iteration 3537 => Loss: 26.512263\n",
      "Iteration 3538 => Loss: 26.508820\n",
      "Iteration 3539 => Loss: 26.505379\n",
      "Iteration 3540 => Loss: 26.501940\n",
      "Iteration 3541 => Loss: 26.498503\n",
      "Iteration 3542 => Loss: 26.495068\n",
      "Iteration 3543 => Loss: 26.495060\n",
      "Iteration 3544 => Loss: 26.491602\n",
      "Iteration 3545 => Loss: 26.488146\n",
      "Iteration 3546 => Loss: 26.484691\n",
      "Iteration 3547 => Loss: 26.481239\n",
      "Iteration 3548 => Loss: 26.477789\n",
      "Iteration 3549 => Loss: 26.474340\n",
      "Iteration 3550 => Loss: 26.470894\n",
      "Iteration 3551 => Loss: 26.467450\n",
      "Iteration 3552 => Loss: 26.464007\n",
      "Iteration 3553 => Loss: 26.460567\n",
      "Iteration 3554 => Loss: 26.457129\n",
      "Iteration 3555 => Loss: 26.453692\n",
      "Iteration 3556 => Loss: 26.450258\n",
      "Iteration 3557 => Loss: 26.446826\n",
      "Iteration 3558 => Loss: 26.443395\n",
      "Iteration 3559 => Loss: 26.439967\n",
      "Iteration 3560 => Loss: 26.436541\n",
      "Iteration 3561 => Loss: 26.436540\n",
      "Iteration 3562 => Loss: 26.433090\n",
      "Iteration 3563 => Loss: 26.429643\n",
      "Iteration 3564 => Loss: 26.426197\n",
      "Iteration 3565 => Loss: 26.422753\n",
      "Iteration 3566 => Loss: 26.419312\n",
      "Iteration 3567 => Loss: 26.415872\n",
      "Iteration 3568 => Loss: 26.412434\n",
      "Iteration 3569 => Loss: 26.408999\n",
      "Iteration 3570 => Loss: 26.405565\n",
      "Iteration 3571 => Loss: 26.402133\n",
      "Iteration 3572 => Loss: 26.398704\n",
      "Iteration 3573 => Loss: 26.395276\n",
      "Iteration 3574 => Loss: 26.391850\n",
      "Iteration 3575 => Loss: 26.388427\n",
      "Iteration 3576 => Loss: 26.385005\n",
      "Iteration 3577 => Loss: 26.381585\n",
      "Iteration 3578 => Loss: 26.378168\n",
      "Iteration 3579 => Loss: 26.374752\n",
      "Iteration 3580 => Loss: 26.374733\n",
      "Iteration 3581 => Loss: 26.371294\n",
      "Iteration 3582 => Loss: 26.367857\n",
      "Iteration 3583 => Loss: 26.364422\n",
      "Iteration 3584 => Loss: 26.360989\n",
      "Iteration 3585 => Loss: 26.357558\n",
      "Iteration 3586 => Loss: 26.354129\n",
      "Iteration 3587 => Loss: 26.350702\n",
      "Iteration 3588 => Loss: 26.347277\n",
      "Iteration 3589 => Loss: 26.343854\n",
      "Iteration 3590 => Loss: 26.340433\n",
      "Iteration 3591 => Loss: 26.337014\n",
      "Iteration 3592 => Loss: 26.333597\n",
      "Iteration 3593 => Loss: 26.330182\n",
      "Iteration 3594 => Loss: 26.326769\n",
      "Iteration 3595 => Loss: 26.323358\n",
      "Iteration 3596 => Loss: 26.319949\n",
      "Iteration 3597 => Loss: 26.316542\n",
      "Iteration 3598 => Loss: 26.316530\n",
      "Iteration 3599 => Loss: 26.313100\n",
      "Iteration 3600 => Loss: 26.309672\n",
      "Iteration 3601 => Loss: 26.306245\n",
      "Iteration 3602 => Loss: 26.302821\n",
      "Iteration 3603 => Loss: 26.299399\n",
      "Iteration 3604 => Loss: 26.295978\n",
      "Iteration 3605 => Loss: 26.292560\n",
      "Iteration 3606 => Loss: 26.289144\n",
      "Iteration 3607 => Loss: 26.285729\n",
      "Iteration 3608 => Loss: 26.282317\n",
      "Iteration 3609 => Loss: 26.278907\n",
      "Iteration 3610 => Loss: 26.275498\n",
      "Iteration 3611 => Loss: 26.272092\n",
      "Iteration 3612 => Loss: 26.268688\n",
      "Iteration 3613 => Loss: 26.265285\n",
      "Iteration 3614 => Loss: 26.261885\n",
      "Iteration 3615 => Loss: 26.258487\n",
      "Iteration 3616 => Loss: 26.258482\n",
      "Iteration 3617 => Loss: 26.255060\n",
      "Iteration 3618 => Loss: 26.251641\n",
      "Iteration 3619 => Loss: 26.248223\n",
      "Iteration 3620 => Loss: 26.244807\n",
      "Iteration 3621 => Loss: 26.241394\n",
      "Iteration 3622 => Loss: 26.237982\n",
      "Iteration 3623 => Loss: 26.234572\n",
      "Iteration 3624 => Loss: 26.231165\n",
      "Iteration 3625 => Loss: 26.227759\n",
      "Iteration 3626 => Loss: 26.224355\n",
      "Iteration 3627 => Loss: 26.220954\n",
      "Iteration 3628 => Loss: 26.217554\n",
      "Iteration 3629 => Loss: 26.214156\n",
      "Iteration 3630 => Loss: 26.210761\n",
      "Iteration 3631 => Loss: 26.207367\n",
      "Iteration 3632 => Loss: 26.203975\n",
      "Iteration 3633 => Loss: 26.200586\n",
      "Iteration 3634 => Loss: 26.197198\n",
      "Iteration 3635 => Loss: 26.197175\n",
      "Iteration 3636 => Loss: 26.193764\n",
      "Iteration 3637 => Loss: 26.190355\n",
      "Iteration 3638 => Loss: 26.186948\n",
      "Iteration 3639 => Loss: 26.183543\n",
      "Iteration 3640 => Loss: 26.180140\n",
      "Iteration 3641 => Loss: 26.176739\n",
      "Iteration 3642 => Loss: 26.173340\n",
      "Iteration 3643 => Loss: 26.169943\n",
      "Iteration 3644 => Loss: 26.166548\n",
      "Iteration 3645 => Loss: 26.163155\n",
      "Iteration 3646 => Loss: 26.159764\n",
      "Iteration 3647 => Loss: 26.156375\n",
      "Iteration 3648 => Loss: 26.152988\n",
      "Iteration 3649 => Loss: 26.149603\n",
      "Iteration 3650 => Loss: 26.146220\n",
      "Iteration 3651 => Loss: 26.142839\n",
      "Iteration 3652 => Loss: 26.139460\n",
      "Iteration 3653 => Loss: 26.139443\n",
      "Iteration 3654 => Loss: 26.136041\n",
      "Iteration 3655 => Loss: 26.132640\n",
      "Iteration 3656 => Loss: 26.129242\n",
      "Iteration 3657 => Loss: 26.125846\n",
      "Iteration 3658 => Loss: 26.122451\n",
      "Iteration 3659 => Loss: 26.119059\n",
      "Iteration 3660 => Loss: 26.115669\n",
      "Iteration 3661 => Loss: 26.112280\n",
      "Iteration 3662 => Loss: 26.108894\n",
      "Iteration 3663 => Loss: 26.105510\n",
      "Iteration 3664 => Loss: 26.102127\n",
      "Iteration 3665 => Loss: 26.098747\n",
      "Iteration 3666 => Loss: 26.095369\n",
      "Iteration 3667 => Loss: 26.091992\n",
      "Iteration 3668 => Loss: 26.088618\n",
      "Iteration 3669 => Loss: 26.085246\n",
      "Iteration 3670 => Loss: 26.081875\n",
      "Iteration 3671 => Loss: 26.081866\n",
      "Iteration 3672 => Loss: 26.078472\n",
      "Iteration 3673 => Loss: 26.075081\n",
      "Iteration 3674 => Loss: 26.071691\n",
      "Iteration 3675 => Loss: 26.068303\n",
      "Iteration 3676 => Loss: 26.064918\n",
      "Iteration 3677 => Loss: 26.061534\n",
      "Iteration 3678 => Loss: 26.058152\n",
      "Iteration 3679 => Loss: 26.054773\n",
      "Iteration 3680 => Loss: 26.051395\n",
      "Iteration 3681 => Loss: 26.048019\n",
      "Iteration 3682 => Loss: 26.044646\n",
      "Iteration 3683 => Loss: 26.041274\n",
      "Iteration 3684 => Loss: 26.037904\n",
      "Iteration 3685 => Loss: 26.034537\n",
      "Iteration 3686 => Loss: 26.031171\n",
      "Iteration 3687 => Loss: 26.027807\n",
      "Iteration 3688 => Loss: 26.024446\n",
      "Iteration 3689 => Loss: 26.024443\n",
      "Iteration 3690 => Loss: 26.021058\n",
      "Iteration 3691 => Loss: 26.017675\n",
      "Iteration 3692 => Loss: 26.014294\n",
      "Iteration 3693 => Loss: 26.010915\n",
      "Iteration 3694 => Loss: 26.007538\n",
      "Iteration 3695 => Loss: 26.004163\n",
      "Iteration 3696 => Loss: 26.000790\n",
      "Iteration 3697 => Loss: 25.997419\n",
      "Iteration 3698 => Loss: 25.994050\n",
      "Iteration 3699 => Loss: 25.990683\n",
      "Iteration 3700 => Loss: 25.987318\n",
      "Iteration 3701 => Loss: 25.983955\n",
      "Iteration 3702 => Loss: 25.980594\n",
      "Iteration 3703 => Loss: 25.977235\n",
      "Iteration 3704 => Loss: 25.973878\n",
      "Iteration 3705 => Loss: 25.970523\n",
      "Iteration 3706 => Loss: 25.967170\n",
      "Iteration 3707 => Loss: 25.963819\n",
      "Iteration 3708 => Loss: 25.963798\n",
      "Iteration 3709 => Loss: 25.960424\n",
      "Iteration 3710 => Loss: 25.957052\n",
      "Iteration 3711 => Loss: 25.953681\n",
      "Iteration 3712 => Loss: 25.950313\n",
      "Iteration 3713 => Loss: 25.946947\n",
      "Iteration 3714 => Loss: 25.943582\n",
      "Iteration 3715 => Loss: 25.940220\n",
      "Iteration 3716 => Loss: 25.936860\n",
      "Iteration 3717 => Loss: 25.933501\n",
      "Iteration 3718 => Loss: 25.930145\n",
      "Iteration 3719 => Loss: 25.926791\n",
      "Iteration 3720 => Loss: 25.923438\n",
      "Iteration 3721 => Loss: 25.920088\n",
      "Iteration 3722 => Loss: 25.916740\n",
      "Iteration 3723 => Loss: 25.913393\n",
      "Iteration 3724 => Loss: 25.910049\n",
      "Iteration 3725 => Loss: 25.906707\n",
      "Iteration 3726 => Loss: 25.906693\n",
      "Iteration 3727 => Loss: 25.903327\n",
      "Iteration 3728 => Loss: 25.899963\n",
      "Iteration 3729 => Loss: 25.896602\n",
      "Iteration 3730 => Loss: 25.893242\n",
      "Iteration 3731 => Loss: 25.889884\n",
      "Iteration 3732 => Loss: 25.886529\n",
      "Iteration 3733 => Loss: 25.883175\n",
      "Iteration 3734 => Loss: 25.879823\n",
      "Iteration 3735 => Loss: 25.876474\n",
      "Iteration 3736 => Loss: 25.873126\n",
      "Iteration 3737 => Loss: 25.869780\n",
      "Iteration 3738 => Loss: 25.866437\n",
      "Iteration 3739 => Loss: 25.863095\n",
      "Iteration 3740 => Loss: 25.859755\n",
      "Iteration 3741 => Loss: 25.856418\n",
      "Iteration 3742 => Loss: 25.853082\n",
      "Iteration 3743 => Loss: 25.849748\n",
      "Iteration 3744 => Loss: 25.849741\n",
      "Iteration 3745 => Loss: 25.846384\n",
      "Iteration 3746 => Loss: 25.843029\n",
      "Iteration 3747 => Loss: 25.839676\n",
      "Iteration 3748 => Loss: 25.836325\n",
      "Iteration 3749 => Loss: 25.832976\n",
      "Iteration 3750 => Loss: 25.829629\n",
      "Iteration 3751 => Loss: 25.826284\n",
      "Iteration 3752 => Loss: 25.822941\n",
      "Iteration 3753 => Loss: 25.819600\n",
      "Iteration 3754 => Loss: 25.816261\n",
      "Iteration 3755 => Loss: 25.812924\n",
      "Iteration 3756 => Loss: 25.809589\n",
      "Iteration 3757 => Loss: 25.806256\n",
      "Iteration 3758 => Loss: 25.802925\n",
      "Iteration 3759 => Loss: 25.799596\n",
      "Iteration 3760 => Loss: 25.796269\n",
      "Iteration 3761 => Loss: 25.792944\n",
      "Iteration 3762 => Loss: 25.792944\n",
      "Iteration 3763 => Loss: 25.789596\n",
      "Iteration 3764 => Loss: 25.786249\n",
      "Iteration 3765 => Loss: 25.782905\n",
      "Iteration 3766 => Loss: 25.779563\n",
      "Iteration 3767 => Loss: 25.776222\n",
      "Iteration 3768 => Loss: 25.772884\n",
      "Iteration 3769 => Loss: 25.769548\n",
      "Iteration 3770 => Loss: 25.766213\n",
      "Iteration 3771 => Loss: 25.762881\n",
      "Iteration 3772 => Loss: 25.759551\n",
      "Iteration 3773 => Loss: 25.756222\n",
      "Iteration 3774 => Loss: 25.752896\n",
      "Iteration 3775 => Loss: 25.749572\n",
      "Iteration 3776 => Loss: 25.746249\n",
      "Iteration 3777 => Loss: 25.742929\n",
      "Iteration 3778 => Loss: 25.739611\n",
      "Iteration 3779 => Loss: 25.736294\n",
      "Iteration 3780 => Loss: 25.732980\n",
      "Iteration 3781 => Loss: 25.732961\n",
      "Iteration 3782 => Loss: 25.729624\n",
      "Iteration 3783 => Loss: 25.726288\n",
      "Iteration 3784 => Loss: 25.722954\n",
      "Iteration 3785 => Loss: 25.719623\n",
      "Iteration 3786 => Loss: 25.716293\n",
      "Iteration 3787 => Loss: 25.712965\n",
      "Iteration 3788 => Loss: 25.709640\n",
      "Iteration 3789 => Loss: 25.706316\n",
      "Iteration 3790 => Loss: 25.702994\n",
      "Iteration 3791 => Loss: 25.699675\n",
      "Iteration 3792 => Loss: 25.696357\n",
      "Iteration 3793 => Loss: 25.693041\n",
      "Iteration 3794 => Loss: 25.689728\n",
      "Iteration 3795 => Loss: 25.686416\n",
      "Iteration 3796 => Loss: 25.683106\n",
      "Iteration 3797 => Loss: 25.679799\n",
      "Iteration 3798 => Loss: 25.676493\n",
      "Iteration 3799 => Loss: 25.676482\n",
      "Iteration 3800 => Loss: 25.673153\n",
      "Iteration 3801 => Loss: 25.669826\n",
      "Iteration 3802 => Loss: 25.666501\n",
      "Iteration 3803 => Loss: 25.663178\n",
      "Iteration 3804 => Loss: 25.659857\n",
      "Iteration 3805 => Loss: 25.656538\n",
      "Iteration 3806 => Loss: 25.653221\n",
      "Iteration 3807 => Loss: 25.649906\n",
      "Iteration 3808 => Loss: 25.646593\n",
      "Iteration 3809 => Loss: 25.643282\n",
      "Iteration 3810 => Loss: 25.639973\n",
      "Iteration 3811 => Loss: 25.636666\n",
      "Iteration 3812 => Loss: 25.633361\n",
      "Iteration 3813 => Loss: 25.630058\n",
      "Iteration 3814 => Loss: 25.626757\n",
      "Iteration 3815 => Loss: 25.623458\n",
      "Iteration 3816 => Loss: 25.620161\n",
      "Iteration 3817 => Loss: 25.620156\n",
      "Iteration 3818 => Loss: 25.616836\n",
      "Iteration 3819 => Loss: 25.613517\n",
      "Iteration 3820 => Loss: 25.610201\n",
      "Iteration 3821 => Loss: 25.606887\n",
      "Iteration 3822 => Loss: 25.603574\n",
      "Iteration 3823 => Loss: 25.600264\n",
      "Iteration 3824 => Loss: 25.596956\n",
      "Iteration 3825 => Loss: 25.593649\n",
      "Iteration 3826 => Loss: 25.590345\n",
      "Iteration 3827 => Loss: 25.587043\n",
      "Iteration 3828 => Loss: 25.583742\n",
      "Iteration 3829 => Loss: 25.580444\n",
      "Iteration 3830 => Loss: 25.577148\n",
      "Iteration 3831 => Loss: 25.573853\n",
      "Iteration 3832 => Loss: 25.570561\n",
      "Iteration 3833 => Loss: 25.567271\n",
      "Iteration 3834 => Loss: 25.563982\n",
      "Iteration 3835 => Loss: 25.560696\n",
      "Iteration 3836 => Loss: 25.560673\n",
      "Iteration 3837 => Loss: 25.557363\n",
      "Iteration 3838 => Loss: 25.554055\n",
      "Iteration 3839 => Loss: 25.550750\n",
      "Iteration 3840 => Loss: 25.547446\n",
      "Iteration 3841 => Loss: 25.544144\n",
      "Iteration 3842 => Loss: 25.540845\n",
      "Iteration 3843 => Loss: 25.537547\n",
      "Iteration 3844 => Loss: 25.534251\n",
      "Iteration 3845 => Loss: 25.530958\n",
      "Iteration 3846 => Loss: 25.527666\n",
      "Iteration 3847 => Loss: 25.524376\n",
      "Iteration 3848 => Loss: 25.521089\n",
      "Iteration 3849 => Loss: 25.517803\n",
      "Iteration 3850 => Loss: 25.514519\n",
      "Iteration 3851 => Loss: 25.511238\n",
      "Iteration 3852 => Loss: 25.507958\n",
      "Iteration 3853 => Loss: 25.504680\n",
      "Iteration 3854 => Loss: 25.504664\n",
      "Iteration 3855 => Loss: 25.501363\n",
      "Iteration 3856 => Loss: 25.498064\n",
      "Iteration 3857 => Loss: 25.494767\n",
      "Iteration 3858 => Loss: 25.491472\n",
      "Iteration 3859 => Loss: 25.488179\n",
      "Iteration 3860 => Loss: 25.484888\n",
      "Iteration 3861 => Loss: 25.481599\n",
      "Iteration 3862 => Loss: 25.478312\n",
      "Iteration 3863 => Loss: 25.475027\n",
      "Iteration 3864 => Loss: 25.471744\n",
      "Iteration 3865 => Loss: 25.468463\n",
      "Iteration 3866 => Loss: 25.465184\n",
      "Iteration 3867 => Loss: 25.461907\n",
      "Iteration 3868 => Loss: 25.458632\n",
      "Iteration 3869 => Loss: 25.455359\n",
      "Iteration 3870 => Loss: 25.452088\n",
      "Iteration 3871 => Loss: 25.448819\n",
      "Iteration 3872 => Loss: 25.448810\n",
      "Iteration 3873 => Loss: 25.445518\n",
      "Iteration 3874 => Loss: 25.442227\n",
      "Iteration 3875 => Loss: 25.438939\n",
      "Iteration 3876 => Loss: 25.435653\n",
      "Iteration 3877 => Loss: 25.432368\n",
      "Iteration 3878 => Loss: 25.429086\n",
      "Iteration 3879 => Loss: 25.425806\n",
      "Iteration 3880 => Loss: 25.422527\n",
      "Iteration 3881 => Loss: 25.419251\n",
      "Iteration 3882 => Loss: 25.415977\n",
      "Iteration 3883 => Loss: 25.412704\n",
      "Iteration 3884 => Loss: 25.409434\n",
      "Iteration 3885 => Loss: 25.406166\n",
      "Iteration 3886 => Loss: 25.402899\n",
      "Iteration 3887 => Loss: 25.399635\n",
      "Iteration 3888 => Loss: 25.396373\n",
      "Iteration 3889 => Loss: 25.393112\n",
      "Iteration 3890 => Loss: 25.393110\n",
      "Iteration 3891 => Loss: 25.389827\n",
      "Iteration 3892 => Loss: 25.386545\n",
      "Iteration 3893 => Loss: 25.383265\n",
      "Iteration 3894 => Loss: 25.379988\n",
      "Iteration 3895 => Loss: 25.376712\n",
      "Iteration 3896 => Loss: 25.373438\n",
      "Iteration 3897 => Loss: 25.370167\n",
      "Iteration 3898 => Loss: 25.366897\n",
      "Iteration 3899 => Loss: 25.363629\n",
      "Iteration 3900 => Loss: 25.360364\n",
      "Iteration 3901 => Loss: 25.357100\n",
      "Iteration 3902 => Loss: 25.353838\n",
      "Iteration 3903 => Loss: 25.350579\n",
      "Iteration 3904 => Loss: 25.347321\n",
      "Iteration 3905 => Loss: 25.344065\n",
      "Iteration 3906 => Loss: 25.340812\n",
      "Iteration 3907 => Loss: 25.337560\n",
      "Iteration 3908 => Loss: 25.334310\n",
      "Iteration 3909 => Loss: 25.334290\n",
      "Iteration 3910 => Loss: 25.331017\n",
      "Iteration 3911 => Loss: 25.327746\n",
      "Iteration 3912 => Loss: 25.324477\n",
      "Iteration 3913 => Loss: 25.321210\n",
      "Iteration 3914 => Loss: 25.317945\n",
      "Iteration 3915 => Loss: 25.314682\n",
      "Iteration 3916 => Loss: 25.311421\n",
      "Iteration 3917 => Loss: 25.308162\n",
      "Iteration 3918 => Loss: 25.304905\n",
      "Iteration 3919 => Loss: 25.301650\n",
      "Iteration 3920 => Loss: 25.298397\n",
      "Iteration 3921 => Loss: 25.295146\n",
      "Iteration 3922 => Loss: 25.291897\n",
      "Iteration 3923 => Loss: 25.288650\n",
      "Iteration 3924 => Loss: 25.285405\n",
      "Iteration 3925 => Loss: 25.282162\n",
      "Iteration 3926 => Loss: 25.278921\n",
      "Iteration 3927 => Loss: 25.278907\n",
      "Iteration 3928 => Loss: 25.275642\n",
      "Iteration 3929 => Loss: 25.272380\n",
      "Iteration 3930 => Loss: 25.269120\n",
      "Iteration 3931 => Loss: 25.265861\n",
      "Iteration 3932 => Loss: 25.262605\n",
      "Iteration 3933 => Loss: 25.259351\n",
      "Iteration 3934 => Loss: 25.256098\n",
      "Iteration 3935 => Loss: 25.252848\n",
      "Iteration 3936 => Loss: 25.249600\n",
      "Iteration 3937 => Loss: 25.246353\n",
      "Iteration 3938 => Loss: 25.243109\n",
      "Iteration 3939 => Loss: 25.239867\n",
      "Iteration 3940 => Loss: 25.236626\n",
      "Iteration 3941 => Loss: 25.233388\n",
      "Iteration 3942 => Loss: 25.230152\n",
      "Iteration 3943 => Loss: 25.226917\n",
      "Iteration 3944 => Loss: 25.223685\n",
      "Iteration 3945 => Loss: 25.223678\n",
      "Iteration 3946 => Loss: 25.220423\n",
      "Iteration 3947 => Loss: 25.217169\n",
      "Iteration 3948 => Loss: 25.213917\n",
      "Iteration 3949 => Loss: 25.210668\n",
      "Iteration 3950 => Loss: 25.207420\n",
      "Iteration 3951 => Loss: 25.204174\n",
      "Iteration 3952 => Loss: 25.200931\n",
      "Iteration 3953 => Loss: 25.197689\n",
      "Iteration 3954 => Loss: 25.194449\n",
      "Iteration 3955 => Loss: 25.191212\n",
      "Iteration 3956 => Loss: 25.187976\n",
      "Iteration 3957 => Loss: 25.184742\n",
      "Iteration 3958 => Loss: 25.181511\n",
      "Iteration 3959 => Loss: 25.178281\n",
      "Iteration 3960 => Loss: 25.175053\n",
      "Iteration 3961 => Loss: 25.171828\n",
      "Iteration 3962 => Loss: 25.168604\n",
      "Iteration 3963 => Loss: 25.165382\n",
      "Iteration 3964 => Loss: 25.165357\n",
      "Iteration 3965 => Loss: 25.162112\n",
      "Iteration 3966 => Loss: 25.158869\n",
      "Iteration 3967 => Loss: 25.155628\n",
      "Iteration 3968 => Loss: 25.152389\n",
      "Iteration 3969 => Loss: 25.149152\n",
      "Iteration 3970 => Loss: 25.145917\n",
      "Iteration 3971 => Loss: 25.142684\n",
      "Iteration 3972 => Loss: 25.139453\n",
      "Iteration 3973 => Loss: 25.136224\n",
      "Iteration 3974 => Loss: 25.132997\n",
      "Iteration 3975 => Loss: 25.129772\n",
      "Iteration 3976 => Loss: 25.126549\n",
      "Iteration 3977 => Loss: 25.123328\n",
      "Iteration 3978 => Loss: 25.120109\n",
      "Iteration 3979 => Loss: 25.116892\n",
      "Iteration 3980 => Loss: 25.113677\n",
      "Iteration 3981 => Loss: 25.110464\n",
      "Iteration 3982 => Loss: 25.110446\n",
      "Iteration 3983 => Loss: 25.107210\n",
      "Iteration 3984 => Loss: 25.103975\n",
      "Iteration 3985 => Loss: 25.100743\n",
      "Iteration 3986 => Loss: 25.097513\n",
      "Iteration 3987 => Loss: 25.094284\n",
      "Iteration 3988 => Loss: 25.091058\n",
      "Iteration 3989 => Loss: 25.087834\n",
      "Iteration 3990 => Loss: 25.084611\n",
      "Iteration 3991 => Loss: 25.081391\n",
      "Iteration 3992 => Loss: 25.078173\n",
      "Iteration 3993 => Loss: 25.074956\n",
      "Iteration 3994 => Loss: 25.071742\n",
      "Iteration 3995 => Loss: 25.068530\n",
      "Iteration 3996 => Loss: 25.065319\n",
      "Iteration 3997 => Loss: 25.062111\n",
      "Iteration 3998 => Loss: 25.058905\n",
      "Iteration 3999 => Loss: 25.055700\n",
      "Iteration 4000 => Loss: 25.055689\n",
      "Iteration 4001 => Loss: 25.052461\n",
      "Iteration 4002 => Loss: 25.049236\n",
      "Iteration 4003 => Loss: 25.046012\n",
      "Iteration 4004 => Loss: 25.042790\n",
      "Iteration 4005 => Loss: 25.039571\n",
      "Iteration 4006 => Loss: 25.036353\n",
      "Iteration 4007 => Loss: 25.033137\n",
      "Iteration 4008 => Loss: 25.029924\n",
      "Iteration 4009 => Loss: 25.026712\n",
      "Iteration 4010 => Loss: 25.023502\n",
      "Iteration 4011 => Loss: 25.020295\n",
      "Iteration 4012 => Loss: 25.017089\n",
      "Iteration 4013 => Loss: 25.013885\n",
      "Iteration 4014 => Loss: 25.010684\n",
      "Iteration 4015 => Loss: 25.007484\n",
      "Iteration 4016 => Loss: 25.004286\n",
      "Iteration 4017 => Loss: 25.001091\n",
      "Iteration 4018 => Loss: 25.001086\n",
      "Iteration 4019 => Loss: 24.997867\n",
      "Iteration 4020 => Loss: 24.994650\n",
      "Iteration 4021 => Loss: 24.991435\n",
      "Iteration 4022 => Loss: 24.988222\n",
      "Iteration 4023 => Loss: 24.985011\n",
      "Iteration 4024 => Loss: 24.981802\n",
      "Iteration 4025 => Loss: 24.978595\n",
      "Iteration 4026 => Loss: 24.975390\n",
      "Iteration 4027 => Loss: 24.972187\n",
      "Iteration 4028 => Loss: 24.968986\n",
      "Iteration 4029 => Loss: 24.965787\n",
      "Iteration 4030 => Loss: 24.962590\n",
      "Iteration 4031 => Loss: 24.959395\n",
      "Iteration 4032 => Loss: 24.956202\n",
      "Iteration 4033 => Loss: 24.953011\n",
      "Iteration 4034 => Loss: 24.949822\n",
      "Iteration 4035 => Loss: 24.946635\n",
      "Iteration 4036 => Loss: 24.943450\n",
      "Iteration 4037 => Loss: 24.943427\n",
      "Iteration 4038 => Loss: 24.940219\n",
      "Iteration 4039 => Loss: 24.937013\n",
      "Iteration 4040 => Loss: 24.933808\n",
      "Iteration 4041 => Loss: 24.930606\n",
      "Iteration 4042 => Loss: 24.927406\n",
      "Iteration 4043 => Loss: 24.924207\n",
      "Iteration 4044 => Loss: 24.921011\n",
      "Iteration 4045 => Loss: 24.917817\n",
      "Iteration 4046 => Loss: 24.914624\n",
      "Iteration 4047 => Loss: 24.911434\n",
      "Iteration 4048 => Loss: 24.908246\n",
      "Iteration 4049 => Loss: 24.905059\n",
      "Iteration 4050 => Loss: 24.901875\n",
      "Iteration 4051 => Loss: 24.898693\n",
      "Iteration 4052 => Loss: 24.895512\n",
      "Iteration 4053 => Loss: 24.892334\n",
      "Iteration 4054 => Loss: 24.889158\n",
      "Iteration 4055 => Loss: 24.889142\n",
      "Iteration 4056 => Loss: 24.885942\n",
      "Iteration 4057 => Loss: 24.882744\n",
      "Iteration 4058 => Loss: 24.879549\n",
      "Iteration 4059 => Loss: 24.876355\n",
      "Iteration 4060 => Loss: 24.873163\n",
      "Iteration 4061 => Loss: 24.869974\n",
      "Iteration 4062 => Loss: 24.866786\n",
      "Iteration 4063 => Loss: 24.863600\n",
      "Iteration 4064 => Loss: 24.860417\n",
      "Iteration 4065 => Loss: 24.857235\n",
      "Iteration 4066 => Loss: 24.854055\n",
      "Iteration 4067 => Loss: 24.850878\n",
      "Iteration 4068 => Loss: 24.847702\n",
      "Iteration 4069 => Loss: 24.844528\n",
      "Iteration 4070 => Loss: 24.841357\n",
      "Iteration 4071 => Loss: 24.838187\n",
      "Iteration 4072 => Loss: 24.835019\n",
      "Iteration 4073 => Loss: 24.835011\n",
      "Iteration 4074 => Loss: 24.831820\n",
      "Iteration 4075 => Loss: 24.828631\n",
      "Iteration 4076 => Loss: 24.825444\n",
      "Iteration 4077 => Loss: 24.822259\n",
      "Iteration 4078 => Loss: 24.819076\n",
      "Iteration 4079 => Loss: 24.815895\n",
      "Iteration 4080 => Loss: 24.812716\n",
      "Iteration 4081 => Loss: 24.809539\n",
      "Iteration 4082 => Loss: 24.806364\n",
      "Iteration 4083 => Loss: 24.803191\n",
      "Iteration 4084 => Loss: 24.800020\n",
      "Iteration 4085 => Loss: 24.796851\n",
      "Iteration 4086 => Loss: 24.793684\n",
      "Iteration 4087 => Loss: 24.790519\n",
      "Iteration 4088 => Loss: 24.787356\n",
      "Iteration 4089 => Loss: 24.784195\n",
      "Iteration 4090 => Loss: 24.781036\n",
      "Iteration 4091 => Loss: 24.781034\n",
      "Iteration 4092 => Loss: 24.777851\n",
      "Iteration 4093 => Loss: 24.774671\n",
      "Iteration 4094 => Loss: 24.771493\n",
      "Iteration 4095 => Loss: 24.768316\n",
      "Iteration 4096 => Loss: 24.765142\n",
      "Iteration 4097 => Loss: 24.761970\n",
      "Iteration 4098 => Loss: 24.758799\n",
      "Iteration 4099 => Loss: 24.755631\n",
      "Iteration 4100 => Loss: 24.752465\n",
      "Iteration 4101 => Loss: 24.749300\n",
      "Iteration 4102 => Loss: 24.746138\n",
      "Iteration 4103 => Loss: 24.742978\n",
      "Iteration 4104 => Loss: 24.739819\n",
      "Iteration 4105 => Loss: 24.736663\n",
      "Iteration 4106 => Loss: 24.733509\n",
      "Iteration 4107 => Loss: 24.730356\n",
      "Iteration 4108 => Loss: 24.727206\n",
      "Iteration 4109 => Loss: 24.724058\n",
      "Iteration 4110 => Loss: 24.724037\n",
      "Iteration 4111 => Loss: 24.720865\n",
      "Iteration 4112 => Loss: 24.717696\n",
      "Iteration 4113 => Loss: 24.714528\n",
      "Iteration 4114 => Loss: 24.711362\n",
      "Iteration 4115 => Loss: 24.708199\n",
      "Iteration 4116 => Loss: 24.705037\n",
      "Iteration 4117 => Loss: 24.701877\n",
      "Iteration 4118 => Loss: 24.698720\n",
      "Iteration 4119 => Loss: 24.695564\n",
      "Iteration 4120 => Loss: 24.692410\n",
      "Iteration 4121 => Loss: 24.689259\n",
      "Iteration 4122 => Loss: 24.686109\n",
      "Iteration 4123 => Loss: 24.682961\n",
      "Iteration 4124 => Loss: 24.679816\n",
      "Iteration 4125 => Loss: 24.676672\n",
      "Iteration 4126 => Loss: 24.673530\n",
      "Iteration 4127 => Loss: 24.670391\n",
      "Iteration 4128 => Loss: 24.670377\n",
      "Iteration 4129 => Loss: 24.667214\n",
      "Iteration 4130 => Loss: 24.664053\n",
      "Iteration 4131 => Loss: 24.660894\n",
      "Iteration 4132 => Loss: 24.657737\n",
      "Iteration 4133 => Loss: 24.654582\n",
      "Iteration 4134 => Loss: 24.651429\n",
      "Iteration 4135 => Loss: 24.648278\n",
      "Iteration 4136 => Loss: 24.645129\n",
      "Iteration 4137 => Loss: 24.641982\n",
      "Iteration 4138 => Loss: 24.638837\n",
      "Iteration 4139 => Loss: 24.635694\n",
      "Iteration 4140 => Loss: 24.632553\n",
      "Iteration 4141 => Loss: 24.629414\n",
      "Iteration 4142 => Loss: 24.626277\n",
      "Iteration 4143 => Loss: 24.623142\n",
      "Iteration 4144 => Loss: 24.620009\n",
      "Iteration 4145 => Loss: 24.616878\n",
      "Iteration 4146 => Loss: 24.616872\n",
      "Iteration 4147 => Loss: 24.613717\n",
      "Iteration 4148 => Loss: 24.610565\n",
      "Iteration 4149 => Loss: 24.607415\n",
      "Iteration 4150 => Loss: 24.604266\n",
      "Iteration 4151 => Loss: 24.601120\n",
      "Iteration 4152 => Loss: 24.597976\n",
      "Iteration 4153 => Loss: 24.594833\n",
      "Iteration 4154 => Loss: 24.591693\n",
      "Iteration 4155 => Loss: 24.588555\n",
      "Iteration 4156 => Loss: 24.585418\n",
      "Iteration 4157 => Loss: 24.582284\n",
      "Iteration 4158 => Loss: 24.579152\n",
      "Iteration 4159 => Loss: 24.576021\n",
      "Iteration 4160 => Loss: 24.572893\n",
      "Iteration 4161 => Loss: 24.569767\n",
      "Iteration 4162 => Loss: 24.566642\n",
      "Iteration 4163 => Loss: 24.563520\n",
      "Iteration 4164 => Loss: 24.560400\n",
      "Iteration 4165 => Loss: 24.560375\n",
      "Iteration 4166 => Loss: 24.557231\n",
      "Iteration 4167 => Loss: 24.554090\n",
      "Iteration 4168 => Loss: 24.550950\n",
      "Iteration 4169 => Loss: 24.547812\n",
      "Iteration 4170 => Loss: 24.544677\n",
      "Iteration 4171 => Loss: 24.541543\n",
      "Iteration 4172 => Loss: 24.538411\n",
      "Iteration 4173 => Loss: 24.535282\n",
      "Iteration 4174 => Loss: 24.532154\n",
      "Iteration 4175 => Loss: 24.529028\n",
      "Iteration 4176 => Loss: 24.525905\n",
      "Iteration 4177 => Loss: 24.522783\n",
      "Iteration 4178 => Loss: 24.519663\n",
      "Iteration 4179 => Loss: 24.516546\n",
      "Iteration 4180 => Loss: 24.513430\n",
      "Iteration 4181 => Loss: 24.510316\n",
      "Iteration 4182 => Loss: 24.507205\n",
      "Iteration 4183 => Loss: 24.507187\n",
      "Iteration 4184 => Loss: 24.504052\n",
      "Iteration 4185 => Loss: 24.500919\n",
      "Iteration 4186 => Loss: 24.497788\n",
      "Iteration 4187 => Loss: 24.494659\n",
      "Iteration 4188 => Loss: 24.491532\n",
      "Iteration 4189 => Loss: 24.488407\n",
      "Iteration 4190 => Loss: 24.485284\n",
      "Iteration 4191 => Loss: 24.482163\n",
      "Iteration 4192 => Loss: 24.479044\n",
      "Iteration 4193 => Loss: 24.475927\n",
      "Iteration 4194 => Loss: 24.472812\n",
      "Iteration 4195 => Loss: 24.469699\n",
      "Iteration 4196 => Loss: 24.466588\n",
      "Iteration 4197 => Loss: 24.463479\n",
      "Iteration 4198 => Loss: 24.460372\n",
      "Iteration 4199 => Loss: 24.457267\n",
      "Iteration 4200 => Loss: 24.454164\n",
      "Iteration 4201 => Loss: 24.454152\n",
      "Iteration 4202 => Loss: 24.451026\n",
      "Iteration 4203 => Loss: 24.447902\n",
      "Iteration 4204 => Loss: 24.444779\n",
      "Iteration 4205 => Loss: 24.441659\n",
      "Iteration 4206 => Loss: 24.438541\n",
      "Iteration 4207 => Loss: 24.435424\n",
      "Iteration 4208 => Loss: 24.432310\n",
      "Iteration 4209 => Loss: 24.429198\n",
      "Iteration 4210 => Loss: 24.426087\n",
      "Iteration 4211 => Loss: 24.422979\n",
      "Iteration 4212 => Loss: 24.419873\n",
      "Iteration 4213 => Loss: 24.416768\n",
      "Iteration 4214 => Loss: 24.413666\n",
      "Iteration 4215 => Loss: 24.410566\n",
      "Iteration 4216 => Loss: 24.407467\n",
      "Iteration 4217 => Loss: 24.404371\n",
      "Iteration 4218 => Loss: 24.401277\n",
      "Iteration 4219 => Loss: 24.401273\n",
      "Iteration 4220 => Loss: 24.398155\n",
      "Iteration 4221 => Loss: 24.395039\n",
      "Iteration 4222 => Loss: 24.391926\n",
      "Iteration 4223 => Loss: 24.388814\n",
      "Iteration 4224 => Loss: 24.385704\n",
      "Iteration 4225 => Loss: 24.382597\n",
      "Iteration 4226 => Loss: 24.379491\n",
      "Iteration 4227 => Loss: 24.376387\n",
      "Iteration 4228 => Loss: 24.373286\n",
      "Iteration 4229 => Loss: 24.370186\n",
      "Iteration 4230 => Loss: 24.367088\n",
      "Iteration 4231 => Loss: 24.363993\n",
      "Iteration 4232 => Loss: 24.360899\n",
      "Iteration 4233 => Loss: 24.357807\n",
      "Iteration 4234 => Loss: 24.354718\n",
      "Iteration 4235 => Loss: 24.351630\n",
      "Iteration 4236 => Loss: 24.348544\n",
      "Iteration 4237 => Loss: 24.345461\n",
      "Iteration 4238 => Loss: 24.345438\n",
      "Iteration 4239 => Loss: 24.342331\n",
      "Iteration 4240 => Loss: 24.339226\n",
      "Iteration 4241 => Loss: 24.336123\n",
      "Iteration 4242 => Loss: 24.333022\n",
      "Iteration 4243 => Loss: 24.329923\n",
      "Iteration 4244 => Loss: 24.326826\n",
      "Iteration 4245 => Loss: 24.323731\n",
      "Iteration 4246 => Loss: 24.320638\n",
      "Iteration 4247 => Loss: 24.317547\n",
      "Iteration 4248 => Loss: 24.314458\n",
      "Iteration 4249 => Loss: 24.311371\n",
      "Iteration 4250 => Loss: 24.308286\n",
      "Iteration 4251 => Loss: 24.305203\n",
      "Iteration 4252 => Loss: 24.302122\n",
      "Iteration 4253 => Loss: 24.299043\n",
      "Iteration 4254 => Loss: 24.295966\n",
      "Iteration 4255 => Loss: 24.292891\n",
      "Iteration 4256 => Loss: 24.292876\n",
      "Iteration 4257 => Loss: 24.289777\n",
      "Iteration 4258 => Loss: 24.286681\n",
      "Iteration 4259 => Loss: 24.283587\n",
      "Iteration 4260 => Loss: 24.280494\n",
      "Iteration 4261 => Loss: 24.277404\n",
      "Iteration 4262 => Loss: 24.274316\n",
      "Iteration 4263 => Loss: 24.271229\n",
      "Iteration 4264 => Loss: 24.268145\n",
      "Iteration 4265 => Loss: 24.265063\n",
      "Iteration 4266 => Loss: 24.261982\n",
      "Iteration 4267 => Loss: 24.258904\n",
      "Iteration 4268 => Loss: 24.255828\n",
      "Iteration 4269 => Loss: 24.252753\n",
      "Iteration 4270 => Loss: 24.249681\n",
      "Iteration 4271 => Loss: 24.246611\n",
      "Iteration 4272 => Loss: 24.243542\n",
      "Iteration 4273 => Loss: 24.240476\n",
      "Iteration 4274 => Loss: 24.240467\n",
      "Iteration 4275 => Loss: 24.237378\n",
      "Iteration 4276 => Loss: 24.234290\n",
      "Iteration 4277 => Loss: 24.231204\n",
      "Iteration 4278 => Loss: 24.228121\n",
      "Iteration 4279 => Loss: 24.225039\n",
      "Iteration 4280 => Loss: 24.221959\n",
      "Iteration 4281 => Loss: 24.218882\n",
      "Iteration 4282 => Loss: 24.215806\n",
      "Iteration 4283 => Loss: 24.212732\n",
      "Iteration 4284 => Loss: 24.209661\n",
      "Iteration 4285 => Loss: 24.206591\n",
      "Iteration 4286 => Loss: 24.203523\n",
      "Iteration 4287 => Loss: 24.200458\n",
      "Iteration 4288 => Loss: 24.197394\n",
      "Iteration 4289 => Loss: 24.194332\n",
      "Iteration 4290 => Loss: 24.191273\n",
      "Iteration 4291 => Loss: 24.188215\n",
      "Iteration 4292 => Loss: 24.188213\n",
      "Iteration 4293 => Loss: 24.185132\n",
      "Iteration 4294 => Loss: 24.182053\n",
      "Iteration 4295 => Loss: 24.178976\n",
      "Iteration 4296 => Loss: 24.175901\n",
      "Iteration 4297 => Loss: 24.172828\n",
      "Iteration 4298 => Loss: 24.169757\n",
      "Iteration 4299 => Loss: 24.166688\n",
      "Iteration 4300 => Loss: 24.163621\n",
      "Iteration 4301 => Loss: 24.160556\n",
      "Iteration 4302 => Loss: 24.157493\n",
      "Iteration 4303 => Loss: 24.154432\n",
      "Iteration 4304 => Loss: 24.151373\n",
      "Iteration 4305 => Loss: 24.148316\n",
      "Iteration 4306 => Loss: 24.145261\n",
      "Iteration 4307 => Loss: 24.142208\n",
      "Iteration 4308 => Loss: 24.139157\n",
      "Iteration 4309 => Loss: 24.136108\n",
      "Iteration 4310 => Loss: 24.133061\n",
      "Iteration 4311 => Loss: 24.133041\n",
      "Iteration 4312 => Loss: 24.129971\n",
      "Iteration 4313 => Loss: 24.126902\n",
      "Iteration 4314 => Loss: 24.123836\n",
      "Iteration 4315 => Loss: 24.120772\n",
      "Iteration 4316 => Loss: 24.117709\n",
      "Iteration 4317 => Loss: 24.114649\n",
      "Iteration 4318 => Loss: 24.111591\n",
      "Iteration 4319 => Loss: 24.108534\n",
      "Iteration 4320 => Loss: 24.105480\n",
      "Iteration 4321 => Loss: 24.102428\n",
      "Iteration 4322 => Loss: 24.099377\n",
      "Iteration 4323 => Loss: 24.096329\n",
      "Iteration 4324 => Loss: 24.093283\n",
      "Iteration 4325 => Loss: 24.090238\n",
      "Iteration 4326 => Loss: 24.087196\n",
      "Iteration 4327 => Loss: 24.084156\n",
      "Iteration 4328 => Loss: 24.081117\n",
      "Iteration 4329 => Loss: 24.081104\n",
      "Iteration 4330 => Loss: 24.078042\n",
      "Iteration 4331 => Loss: 24.074983\n",
      "Iteration 4332 => Loss: 24.071925\n",
      "Iteration 4333 => Loss: 24.068869\n",
      "Iteration 4334 => Loss: 24.065816\n",
      "Iteration 4335 => Loss: 24.062764\n",
      "Iteration 4336 => Loss: 24.059714\n",
      "Iteration 4337 => Loss: 24.056667\n",
      "Iteration 4338 => Loss: 24.053621\n",
      "Iteration 4339 => Loss: 24.050577\n",
      "Iteration 4340 => Loss: 24.047536\n",
      "Iteration 4341 => Loss: 24.044496\n",
      "Iteration 4342 => Loss: 24.041458\n",
      "Iteration 4343 => Loss: 24.038423\n",
      "Iteration 4344 => Loss: 24.035389\n",
      "Iteration 4345 => Loss: 24.032357\n",
      "Iteration 4346 => Loss: 24.029328\n",
      "Iteration 4347 => Loss: 24.029322\n",
      "Iteration 4348 => Loss: 24.026269\n",
      "Iteration 4349 => Loss: 24.023218\n",
      "Iteration 4350 => Loss: 24.020169\n",
      "Iteration 4351 => Loss: 24.017122\n",
      "Iteration 4352 => Loss: 24.014077\n",
      "Iteration 4353 => Loss: 24.011034\n",
      "Iteration 4354 => Loss: 24.007993\n",
      "Iteration 4355 => Loss: 24.004954\n",
      "Iteration 4356 => Loss: 24.001917\n",
      "Iteration 4357 => Loss: 23.998882\n",
      "Iteration 4358 => Loss: 23.995849\n",
      "Iteration 4359 => Loss: 23.992818\n",
      "Iteration 4360 => Loss: 23.989789\n",
      "Iteration 4361 => Loss: 23.986762\n",
      "Iteration 4362 => Loss: 23.983737\n",
      "Iteration 4363 => Loss: 23.980714\n",
      "Iteration 4364 => Loss: 23.977693\n",
      "Iteration 4365 => Loss: 23.974674\n",
      "Iteration 4366 => Loss: 23.974649\n",
      "Iteration 4367 => Loss: 23.971607\n",
      "Iteration 4368 => Loss: 23.968566\n",
      "Iteration 4369 => Loss: 23.965528\n",
      "Iteration 4370 => Loss: 23.962492\n",
      "Iteration 4371 => Loss: 23.959457\n",
      "Iteration 4372 => Loss: 23.956425\n",
      "Iteration 4373 => Loss: 23.953395\n",
      "Iteration 4374 => Loss: 23.950366\n",
      "Iteration 4375 => Loss: 23.947340\n",
      "Iteration 4376 => Loss: 23.944316\n",
      "Iteration 4377 => Loss: 23.941293\n",
      "Iteration 4378 => Loss: 23.938273\n",
      "Iteration 4379 => Loss: 23.935255\n",
      "Iteration 4380 => Loss: 23.932238\n",
      "Iteration 4381 => Loss: 23.929224\n",
      "Iteration 4382 => Loss: 23.926212\n",
      "Iteration 4383 => Loss: 23.923201\n",
      "Iteration 4384 => Loss: 23.923183\n",
      "Iteration 4385 => Loss: 23.920150\n",
      "Iteration 4386 => Loss: 23.917118\n",
      "Iteration 4387 => Loss: 23.914088\n",
      "Iteration 4388 => Loss: 23.911061\n",
      "Iteration 4389 => Loss: 23.908035\n",
      "Iteration 4390 => Loss: 23.905011\n",
      "Iteration 4391 => Loss: 23.901990\n",
      "Iteration 4392 => Loss: 23.898970\n",
      "Iteration 4393 => Loss: 23.895952\n",
      "Iteration 4394 => Loss: 23.892937\n",
      "Iteration 4395 => Loss: 23.889923\n",
      "Iteration 4396 => Loss: 23.886911\n",
      "Iteration 4397 => Loss: 23.883902\n",
      "Iteration 4398 => Loss: 23.880894\n",
      "Iteration 4399 => Loss: 23.877888\n",
      "Iteration 4400 => Loss: 23.874885\n",
      "Iteration 4401 => Loss: 23.871883\n",
      "Iteration 4402 => Loss: 23.871872\n",
      "Iteration 4403 => Loss: 23.868847\n",
      "Iteration 4404 => Loss: 23.865824\n",
      "Iteration 4405 => Loss: 23.862803\n",
      "Iteration 4406 => Loss: 23.859784\n",
      "Iteration 4407 => Loss: 23.856767\n",
      "Iteration 4408 => Loss: 23.853752\n",
      "Iteration 4409 => Loss: 23.850739\n",
      "Iteration 4410 => Loss: 23.847728\n",
      "Iteration 4411 => Loss: 23.844719\n",
      "Iteration 4412 => Loss: 23.841712\n",
      "Iteration 4413 => Loss: 23.838707\n",
      "Iteration 4414 => Loss: 23.835704\n",
      "Iteration 4415 => Loss: 23.832703\n",
      "Iteration 4416 => Loss: 23.829704\n",
      "Iteration 4417 => Loss: 23.826707\n",
      "Iteration 4418 => Loss: 23.823712\n",
      "Iteration 4419 => Loss: 23.820719\n",
      "Iteration 4420 => Loss: 23.820715\n",
      "Iteration 4421 => Loss: 23.817699\n",
      "Iteration 4422 => Loss: 23.814685\n",
      "Iteration 4423 => Loss: 23.811672\n",
      "Iteration 4424 => Loss: 23.808662\n",
      "Iteration 4425 => Loss: 23.805654\n",
      "Iteration 4426 => Loss: 23.802647\n",
      "Iteration 4427 => Loss: 23.799643\n",
      "Iteration 4428 => Loss: 23.796641\n",
      "Iteration 4429 => Loss: 23.793640\n",
      "Iteration 4430 => Loss: 23.790642\n",
      "Iteration 4431 => Loss: 23.787646\n",
      "Iteration 4432 => Loss: 23.784651\n",
      "Iteration 4433 => Loss: 23.781659\n",
      "Iteration 4434 => Loss: 23.778669\n",
      "Iteration 4435 => Loss: 23.775680\n",
      "Iteration 4436 => Loss: 23.772694\n",
      "Iteration 4437 => Loss: 23.769710\n",
      "Iteration 4438 => Loss: 23.766727\n",
      "Iteration 4439 => Loss: 23.766705\n",
      "Iteration 4440 => Loss: 23.763700\n",
      "Iteration 4441 => Loss: 23.760696\n",
      "Iteration 4442 => Loss: 23.757694\n",
      "Iteration 4443 => Loss: 23.754695\n",
      "Iteration 4444 => Loss: 23.751697\n",
      "Iteration 4445 => Loss: 23.748701\n",
      "Iteration 4446 => Loss: 23.745708\n",
      "Iteration 4447 => Loss: 23.742716\n",
      "Iteration 4448 => Loss: 23.739726\n",
      "Iteration 4449 => Loss: 23.736739\n",
      "Iteration 4450 => Loss: 23.733753\n",
      "Iteration 4451 => Loss: 23.730769\n",
      "Iteration 4452 => Loss: 23.727788\n",
      "Iteration 4453 => Loss: 23.724808\n",
      "Iteration 4454 => Loss: 23.721830\n",
      "Iteration 4455 => Loss: 23.718855\n",
      "Iteration 4456 => Loss: 23.715881\n",
      "Iteration 4457 => Loss: 23.715866\n",
      "Iteration 4458 => Loss: 23.712869\n",
      "Iteration 4459 => Loss: 23.709874\n",
      "Iteration 4460 => Loss: 23.706881\n",
      "Iteration 4461 => Loss: 23.703890\n",
      "Iteration 4462 => Loss: 23.700901\n",
      "Iteration 4463 => Loss: 23.697914\n",
      "Iteration 4464 => Loss: 23.694929\n",
      "Iteration 4465 => Loss: 23.691946\n",
      "Iteration 4466 => Loss: 23.688965\n",
      "Iteration 4467 => Loss: 23.685986\n",
      "Iteration 4468 => Loss: 23.683009\n",
      "Iteration 4469 => Loss: 23.680034\n",
      "Iteration 4470 => Loss: 23.677061\n",
      "Iteration 4471 => Loss: 23.674090\n",
      "Iteration 4472 => Loss: 23.671121\n",
      "Iteration 4473 => Loss: 23.668154\n",
      "Iteration 4474 => Loss: 23.665189\n",
      "Iteration 4475 => Loss: 23.665180\n",
      "Iteration 4476 => Loss: 23.662192\n",
      "Iteration 4477 => Loss: 23.659205\n",
      "Iteration 4478 => Loss: 23.656221\n",
      "Iteration 4479 => Loss: 23.653239\n",
      "Iteration 4480 => Loss: 23.650258\n",
      "Iteration 4481 => Loss: 23.647280\n",
      "Iteration 4482 => Loss: 23.644304\n",
      "Iteration 4483 => Loss: 23.641329\n",
      "Iteration 4484 => Loss: 23.638357\n",
      "Iteration 4485 => Loss: 23.635387\n",
      "Iteration 4486 => Loss: 23.632418\n",
      "Iteration 4487 => Loss: 23.629452\n",
      "Iteration 4488 => Loss: 23.626488\n",
      "Iteration 4489 => Loss: 23.623525\n",
      "Iteration 4490 => Loss: 23.620565\n",
      "Iteration 4491 => Loss: 23.617607\n",
      "Iteration 4492 => Loss: 23.614650\n",
      "Iteration 4493 => Loss: 23.614649\n",
      "Iteration 4494 => Loss: 23.611669\n",
      "Iteration 4495 => Loss: 23.608692\n",
      "Iteration 4496 => Loss: 23.605716\n",
      "Iteration 4497 => Loss: 23.602742\n",
      "Iteration 4498 => Loss: 23.599771\n",
      "Iteration 4499 => Loss: 23.596801\n",
      "Iteration 4500 => Loss: 23.593833\n",
      "Iteration 4501 => Loss: 23.590868\n",
      "Iteration 4502 => Loss: 23.587904\n",
      "Iteration 4503 => Loss: 23.584942\n",
      "Iteration 4504 => Loss: 23.581983\n",
      "Iteration 4505 => Loss: 23.579025\n",
      "Iteration 4506 => Loss: 23.576069\n",
      "Iteration 4507 => Loss: 23.573116\n",
      "Iteration 4508 => Loss: 23.570164\n",
      "Iteration 4509 => Loss: 23.567214\n",
      "Iteration 4510 => Loss: 23.564267\n",
      "Iteration 4511 => Loss: 23.561321\n",
      "Iteration 4512 => Loss: 23.561301\n",
      "Iteration 4513 => Loss: 23.558332\n",
      "Iteration 4514 => Loss: 23.555365\n",
      "Iteration 4515 => Loss: 23.552400\n",
      "Iteration 4516 => Loss: 23.549437\n",
      "Iteration 4517 => Loss: 23.546476\n",
      "Iteration 4518 => Loss: 23.543517\n",
      "Iteration 4519 => Loss: 23.540560\n",
      "Iteration 4520 => Loss: 23.537605\n",
      "Iteration 4521 => Loss: 23.534652\n",
      "Iteration 4522 => Loss: 23.531701\n",
      "Iteration 4523 => Loss: 23.528752\n",
      "Iteration 4524 => Loss: 23.525805\n",
      "Iteration 4525 => Loss: 23.522860\n",
      "Iteration 4526 => Loss: 23.519917\n",
      "Iteration 4527 => Loss: 23.516976\n",
      "Iteration 4528 => Loss: 23.514037\n",
      "Iteration 4529 => Loss: 23.511100\n",
      "Iteration 4530 => Loss: 23.511087\n",
      "Iteration 4531 => Loss: 23.508127\n",
      "Iteration 4532 => Loss: 23.505169\n",
      "Iteration 4533 => Loss: 23.502212\n",
      "Iteration 4534 => Loss: 23.499258\n",
      "Iteration 4535 => Loss: 23.496306\n",
      "Iteration 4536 => Loss: 23.493355\n",
      "Iteration 4537 => Loss: 23.490407\n",
      "Iteration 4538 => Loss: 23.487461\n",
      "Iteration 4539 => Loss: 23.484516\n",
      "Iteration 4540 => Loss: 23.481574\n",
      "Iteration 4541 => Loss: 23.478634\n",
      "Iteration 4542 => Loss: 23.475695\n",
      "Iteration 4543 => Loss: 23.472759\n",
      "Iteration 4544 => Loss: 23.469825\n",
      "Iteration 4545 => Loss: 23.466892\n",
      "Iteration 4546 => Loss: 23.463962\n",
      "Iteration 4547 => Loss: 23.461034\n",
      "Iteration 4548 => Loss: 23.461028\n",
      "Iteration 4549 => Loss: 23.458076\n",
      "Iteration 4550 => Loss: 23.455126\n",
      "Iteration 4551 => Loss: 23.452179\n",
      "Iteration 4552 => Loss: 23.449233\n",
      "Iteration 4553 => Loss: 23.446289\n",
      "Iteration 4554 => Loss: 23.443348\n",
      "Iteration 4555 => Loss: 23.440408\n",
      "Iteration 4556 => Loss: 23.437470\n",
      "Iteration 4557 => Loss: 23.434535\n",
      "Iteration 4558 => Loss: 23.431601\n",
      "Iteration 4559 => Loss: 23.428669\n",
      "Iteration 4560 => Loss: 23.425740\n",
      "Iteration 4561 => Loss: 23.422812\n",
      "Iteration 4562 => Loss: 23.419886\n",
      "Iteration 4563 => Loss: 23.416963\n",
      "Iteration 4564 => Loss: 23.414041\n",
      "Iteration 4565 => Loss: 23.411121\n",
      "Iteration 4566 => Loss: 23.408204\n",
      "Iteration 4567 => Loss: 23.408179\n",
      "Iteration 4568 => Loss: 23.405238\n",
      "Iteration 4569 => Loss: 23.402299\n",
      "Iteration 4570 => Loss: 23.399362\n",
      "Iteration 4571 => Loss: 23.396427\n",
      "Iteration 4572 => Loss: 23.393494\n",
      "Iteration 4573 => Loss: 23.390563\n",
      "Iteration 4574 => Loss: 23.387634\n",
      "Iteration 4575 => Loss: 23.384707\n",
      "Iteration 4576 => Loss: 23.381782\n",
      "Iteration 4577 => Loss: 23.378859\n",
      "Iteration 4578 => Loss: 23.375938\n",
      "Iteration 4579 => Loss: 23.373019\n",
      "Iteration 4580 => Loss: 23.370102\n",
      "Iteration 4581 => Loss: 23.367187\n",
      "Iteration 4582 => Loss: 23.364274\n",
      "Iteration 4583 => Loss: 23.361363\n",
      "Iteration 4584 => Loss: 23.358454\n",
      "Iteration 4585 => Loss: 23.358437\n",
      "Iteration 4586 => Loss: 23.355504\n",
      "Iteration 4587 => Loss: 23.352574\n",
      "Iteration 4588 => Loss: 23.349646\n",
      "Iteration 4589 => Loss: 23.346719\n",
      "Iteration 4590 => Loss: 23.343795\n",
      "Iteration 4591 => Loss: 23.340873\n",
      "Iteration 4592 => Loss: 23.337952\n",
      "Iteration 4593 => Loss: 23.335034\n",
      "Iteration 4594 => Loss: 23.332118\n",
      "Iteration 4595 => Loss: 23.329203\n",
      "Iteration 4596 => Loss: 23.326291\n",
      "Iteration 4597 => Loss: 23.323381\n",
      "Iteration 4598 => Loss: 23.320472\n",
      "Iteration 4599 => Loss: 23.317566\n",
      "Iteration 4600 => Loss: 23.314662\n",
      "Iteration 4601 => Loss: 23.311759\n",
      "Iteration 4602 => Loss: 23.308859\n",
      "Iteration 4603 => Loss: 23.308848\n",
      "Iteration 4604 => Loss: 23.305925\n",
      "Iteration 4605 => Loss: 23.303003\n",
      "Iteration 4606 => Loss: 23.300083\n",
      "Iteration 4607 => Loss: 23.297166\n",
      "Iteration 4608 => Loss: 23.294250\n",
      "Iteration 4609 => Loss: 23.291336\n",
      "Iteration 4610 => Loss: 23.288425\n",
      "Iteration 4611 => Loss: 23.285515\n",
      "Iteration 4612 => Loss: 23.282607\n",
      "Iteration 4613 => Loss: 23.279702\n",
      "Iteration 4614 => Loss: 23.276798\n",
      "Iteration 4615 => Loss: 23.273896\n",
      "Iteration 4616 => Loss: 23.270997\n",
      "Iteration 4617 => Loss: 23.268099\n",
      "Iteration 4618 => Loss: 23.265203\n",
      "Iteration 4619 => Loss: 23.262310\n",
      "Iteration 4620 => Loss: 23.259418\n",
      "Iteration 4621 => Loss: 23.259415\n",
      "Iteration 4622 => Loss: 23.256500\n",
      "Iteration 4623 => Loss: 23.253587\n",
      "Iteration 4624 => Loss: 23.250676\n",
      "Iteration 4625 => Loss: 23.247767\n",
      "Iteration 4626 => Loss: 23.244860\n",
      "Iteration 4627 => Loss: 23.241955\n",
      "Iteration 4628 => Loss: 23.239052\n",
      "Iteration 4629 => Loss: 23.236151\n",
      "Iteration 4630 => Loss: 23.233252\n",
      "Iteration 4631 => Loss: 23.230355\n",
      "Iteration 4632 => Loss: 23.227460\n",
      "Iteration 4633 => Loss: 23.224567\n",
      "Iteration 4634 => Loss: 23.221676\n",
      "Iteration 4635 => Loss: 23.218787\n",
      "Iteration 4636 => Loss: 23.215900\n",
      "Iteration 4637 => Loss: 23.213015\n",
      "Iteration 4638 => Loss: 23.210132\n",
      "Iteration 4639 => Loss: 23.207251\n",
      "Iteration 4640 => Loss: 23.207229\n",
      "Iteration 4641 => Loss: 23.204324\n",
      "Iteration 4642 => Loss: 23.201422\n",
      "Iteration 4643 => Loss: 23.198522\n",
      "Iteration 4644 => Loss: 23.195623\n",
      "Iteration 4645 => Loss: 23.192727\n",
      "Iteration 4646 => Loss: 23.189833\n",
      "Iteration 4647 => Loss: 23.186940\n",
      "Iteration 4648 => Loss: 23.184050\n",
      "Iteration 4649 => Loss: 23.181162\n",
      "Iteration 4650 => Loss: 23.178275\n",
      "Iteration 4651 => Loss: 23.175391\n",
      "Iteration 4652 => Loss: 23.172509\n",
      "Iteration 4653 => Loss: 23.169628\n",
      "Iteration 4654 => Loss: 23.166750\n",
      "Iteration 4655 => Loss: 23.163874\n",
      "Iteration 4656 => Loss: 23.160999\n",
      "Iteration 4657 => Loss: 23.158127\n",
      "Iteration 4658 => Loss: 23.158112\n",
      "Iteration 4659 => Loss: 23.155216\n",
      "Iteration 4660 => Loss: 23.152322\n",
      "Iteration 4661 => Loss: 23.149431\n",
      "Iteration 4662 => Loss: 23.146541\n",
      "Iteration 4663 => Loss: 23.143653\n",
      "Iteration 4664 => Loss: 23.140768\n",
      "Iteration 4665 => Loss: 23.137884\n",
      "Iteration 4666 => Loss: 23.135002\n",
      "Iteration 4667 => Loss: 23.132123\n",
      "Iteration 4668 => Loss: 23.129245\n",
      "Iteration 4669 => Loss: 23.126369\n",
      "Iteration 4670 => Loss: 23.123496\n",
      "Iteration 4671 => Loss: 23.120624\n",
      "Iteration 4672 => Loss: 23.117754\n",
      "Iteration 4673 => Loss: 23.114887\n",
      "Iteration 4674 => Loss: 23.112021\n",
      "Iteration 4675 => Loss: 23.109157\n",
      "Iteration 4676 => Loss: 23.109149\n",
      "Iteration 4677 => Loss: 23.106262\n",
      "Iteration 4678 => Loss: 23.103377\n",
      "Iteration 4679 => Loss: 23.100494\n",
      "Iteration 4680 => Loss: 23.097613\n",
      "Iteration 4681 => Loss: 23.094734\n",
      "Iteration 4682 => Loss: 23.091857\n",
      "Iteration 4683 => Loss: 23.088982\n",
      "Iteration 4684 => Loss: 23.086109\n",
      "Iteration 4685 => Loss: 23.083238\n",
      "Iteration 4686 => Loss: 23.080369\n",
      "Iteration 4687 => Loss: 23.077502\n",
      "Iteration 4688 => Loss: 23.074637\n",
      "Iteration 4689 => Loss: 23.071774\n",
      "Iteration 4690 => Loss: 23.068913\n",
      "Iteration 4691 => Loss: 23.066054\n",
      "Iteration 4692 => Loss: 23.063197\n",
      "Iteration 4693 => Loss: 23.060342\n",
      "Iteration 4694 => Loss: 23.060341\n",
      "Iteration 4695 => Loss: 23.057463\n",
      "Iteration 4696 => Loss: 23.054586\n",
      "Iteration 4697 => Loss: 23.051712\n",
      "Iteration 4698 => Loss: 23.048840\n",
      "Iteration 4699 => Loss: 23.045969\n",
      "Iteration 4700 => Loss: 23.043101\n",
      "Iteration 4701 => Loss: 23.040235\n",
      "Iteration 4702 => Loss: 23.037370\n",
      "Iteration 4703 => Loss: 23.034508\n",
      "Iteration 4704 => Loss: 23.031648\n",
      "Iteration 4705 => Loss: 23.028789\n",
      "Iteration 4706 => Loss: 23.025933\n",
      "Iteration 4707 => Loss: 23.023079\n",
      "Iteration 4708 => Loss: 23.020226\n",
      "Iteration 4709 => Loss: 23.017376\n",
      "Iteration 4710 => Loss: 23.014528\n",
      "Iteration 4711 => Loss: 23.011681\n",
      "Iteration 4712 => Loss: 23.008837\n",
      "Iteration 4713 => Loss: 23.008818\n",
      "Iteration 4714 => Loss: 23.005950\n",
      "Iteration 4715 => Loss: 23.003084\n",
      "Iteration 4716 => Loss: 23.000221\n",
      "Iteration 4717 => Loss: 22.997359\n",
      "Iteration 4718 => Loss: 22.994499\n",
      "Iteration 4719 => Loss: 22.991642\n",
      "Iteration 4720 => Loss: 22.988786\n",
      "Iteration 4721 => Loss: 22.985932\n",
      "Iteration 4722 => Loss: 22.983081\n",
      "Iteration 4723 => Loss: 22.980231\n",
      "Iteration 4724 => Loss: 22.977383\n",
      "Iteration 4725 => Loss: 22.974538\n",
      "Iteration 4726 => Loss: 22.971694\n",
      "Iteration 4727 => Loss: 22.968852\n",
      "Iteration 4728 => Loss: 22.966013\n",
      "Iteration 4729 => Loss: 22.963175\n",
      "Iteration 4730 => Loss: 22.960339\n",
      "Iteration 4731 => Loss: 22.960327\n",
      "Iteration 4732 => Loss: 22.957468\n",
      "Iteration 4733 => Loss: 22.954611\n",
      "Iteration 4734 => Loss: 22.951756\n",
      "Iteration 4735 => Loss: 22.948903\n",
      "Iteration 4736 => Loss: 22.946052\n",
      "Iteration 4737 => Loss: 22.943203\n",
      "Iteration 4738 => Loss: 22.940356\n",
      "Iteration 4739 => Loss: 22.937511\n",
      "Iteration 4740 => Loss: 22.934668\n",
      "Iteration 4741 => Loss: 22.931827\n",
      "Iteration 4742 => Loss: 22.928988\n",
      "Iteration 4743 => Loss: 22.926151\n",
      "Iteration 4744 => Loss: 22.923316\n",
      "Iteration 4745 => Loss: 22.920483\n",
      "Iteration 4746 => Loss: 22.917652\n",
      "Iteration 4747 => Loss: 22.914823\n",
      "Iteration 4748 => Loss: 22.911996\n",
      "Iteration 4749 => Loss: 22.911990\n",
      "Iteration 4750 => Loss: 22.909139\n",
      "Iteration 4751 => Loss: 22.906291\n",
      "Iteration 4752 => Loss: 22.903445\n",
      "Iteration 4753 => Loss: 22.900600\n",
      "Iteration 4754 => Loss: 22.897758\n",
      "Iteration 4755 => Loss: 22.894918\n",
      "Iteration 4756 => Loss: 22.892079\n",
      "Iteration 4757 => Loss: 22.889243\n",
      "Iteration 4758 => Loss: 22.886409\n",
      "Iteration 4759 => Loss: 22.883576\n",
      "Iteration 4760 => Loss: 22.880746\n",
      "Iteration 4761 => Loss: 22.877918\n",
      "Iteration 4762 => Loss: 22.875091\n",
      "Iteration 4763 => Loss: 22.872267\n",
      "Iteration 4764 => Loss: 22.869445\n",
      "Iteration 4765 => Loss: 22.866624\n",
      "Iteration 4766 => Loss: 22.863806\n",
      "Iteration 4767 => Loss: 22.860990\n",
      "Iteration 4768 => Loss: 22.860966\n",
      "Iteration 4769 => Loss: 22.858126\n",
      "Iteration 4770 => Loss: 22.855288\n",
      "Iteration 4771 => Loss: 22.852453\n",
      "Iteration 4772 => Loss: 22.849619\n",
      "Iteration 4773 => Loss: 22.846787\n",
      "Iteration 4774 => Loss: 22.843958\n",
      "Iteration 4775 => Loss: 22.841130\n",
      "Iteration 4776 => Loss: 22.838304\n",
      "Iteration 4777 => Loss: 22.835481\n",
      "Iteration 4778 => Loss: 22.832659\n",
      "Iteration 4779 => Loss: 22.829839\n",
      "Iteration 4780 => Loss: 22.827022\n",
      "Iteration 4781 => Loss: 22.824206\n",
      "Iteration 4782 => Loss: 22.821392\n",
      "Iteration 4783 => Loss: 22.818581\n",
      "Iteration 4784 => Loss: 22.815771\n",
      "Iteration 4785 => Loss: 22.812963\n",
      "Iteration 4786 => Loss: 22.812946\n",
      "Iteration 4787 => Loss: 22.810115\n",
      "Iteration 4788 => Loss: 22.807286\n",
      "Iteration 4789 => Loss: 22.804459\n",
      "Iteration 4790 => Loss: 22.801634\n",
      "Iteration 4791 => Loss: 22.798811\n",
      "Iteration 4792 => Loss: 22.795990\n",
      "Iteration 4793 => Loss: 22.793171\n",
      "Iteration 4794 => Loss: 22.790354\n",
      "Iteration 4795 => Loss: 22.787539\n",
      "Iteration 4796 => Loss: 22.784726\n",
      "Iteration 4797 => Loss: 22.781915\n",
      "Iteration 4798 => Loss: 22.779106\n",
      "Iteration 4799 => Loss: 22.776299\n",
      "Iteration 4800 => Loss: 22.773494\n",
      "Iteration 4801 => Loss: 22.770691\n",
      "Iteration 4802 => Loss: 22.767890\n",
      "Iteration 4803 => Loss: 22.765091\n",
      "Iteration 4804 => Loss: 22.765081\n",
      "Iteration 4805 => Loss: 22.762259\n",
      "Iteration 4806 => Loss: 22.759438\n",
      "Iteration 4807 => Loss: 22.756620\n",
      "Iteration 4808 => Loss: 22.753804\n",
      "Iteration 4809 => Loss: 22.750989\n",
      "Iteration 4810 => Loss: 22.748177\n",
      "Iteration 4811 => Loss: 22.745367\n",
      "Iteration 4812 => Loss: 22.742558\n",
      "Iteration 4813 => Loss: 22.739752\n",
      "Iteration 4814 => Loss: 22.736948\n",
      "Iteration 4815 => Loss: 22.734145\n",
      "Iteration 4816 => Loss: 22.731345\n",
      "Iteration 4817 => Loss: 22.728547\n",
      "Iteration 4818 => Loss: 22.725750\n",
      "Iteration 4819 => Loss: 22.722956\n",
      "Iteration 4820 => Loss: 22.720164\n",
      "Iteration 4821 => Loss: 22.717373\n",
      "Iteration 4822 => Loss: 22.717370\n",
      "Iteration 4823 => Loss: 22.714556\n",
      "Iteration 4824 => Loss: 22.711745\n",
      "Iteration 4825 => Loss: 22.708935\n",
      "Iteration 4826 => Loss: 22.706127\n",
      "Iteration 4827 => Loss: 22.703322\n",
      "Iteration 4828 => Loss: 22.700518\n",
      "Iteration 4829 => Loss: 22.697716\n",
      "Iteration 4830 => Loss: 22.694917\n",
      "Iteration 4831 => Loss: 22.692119\n",
      "Iteration 4832 => Loss: 22.689323\n",
      "Iteration 4833 => Loss: 22.686530\n",
      "Iteration 4834 => Loss: 22.683738\n",
      "Iteration 4835 => Loss: 22.680948\n",
      "Iteration 4836 => Loss: 22.678161\n",
      "Iteration 4837 => Loss: 22.675375\n",
      "Iteration 4838 => Loss: 22.672591\n",
      "Iteration 4839 => Loss: 22.669810\n",
      "Iteration 4840 => Loss: 22.667030\n",
      "Iteration 4841 => Loss: 22.667008\n",
      "Iteration 4842 => Loss: 22.664205\n",
      "Iteration 4843 => Loss: 22.661404\n",
      "Iteration 4844 => Loss: 22.658605\n",
      "Iteration 4845 => Loss: 22.655808\n",
      "Iteration 4846 => Loss: 22.653013\n",
      "Iteration 4847 => Loss: 22.650220\n",
      "Iteration 4848 => Loss: 22.647429\n",
      "Iteration 4849 => Loss: 22.644640\n",
      "Iteration 4850 => Loss: 22.641853\n",
      "Iteration 4851 => Loss: 22.639068\n",
      "Iteration 4852 => Loss: 22.636285\n",
      "Iteration 4853 => Loss: 22.633504\n",
      "Iteration 4854 => Loss: 22.630725\n",
      "Iteration 4855 => Loss: 22.627948\n",
      "Iteration 4856 => Loss: 22.625173\n",
      "Iteration 4857 => Loss: 22.622400\n",
      "Iteration 4858 => Loss: 22.619629\n",
      "Iteration 4859 => Loss: 22.619614\n",
      "Iteration 4860 => Loss: 22.616820\n",
      "Iteration 4861 => Loss: 22.614028\n",
      "Iteration 4862 => Loss: 22.611237\n",
      "Iteration 4863 => Loss: 22.608449\n",
      "Iteration 4864 => Loss: 22.605663\n",
      "Iteration 4865 => Loss: 22.602878\n",
      "Iteration 4866 => Loss: 22.600096\n",
      "Iteration 4867 => Loss: 22.597316\n",
      "Iteration 4868 => Loss: 22.594537\n",
      "Iteration 4869 => Loss: 22.591761\n",
      "Iteration 4870 => Loss: 22.588987\n",
      "Iteration 4871 => Loss: 22.586214\n",
      "Iteration 4872 => Loss: 22.583444\n",
      "Iteration 4873 => Loss: 22.580676\n",
      "Iteration 4874 => Loss: 22.577909\n",
      "Iteration 4875 => Loss: 22.575145\n",
      "Iteration 4876 => Loss: 22.572383\n",
      "Iteration 4877 => Loss: 22.572375\n",
      "Iteration 4878 => Loss: 22.569589\n",
      "Iteration 4879 => Loss: 22.566805\n",
      "Iteration 4880 => Loss: 22.564024\n",
      "Iteration 4881 => Loss: 22.561244\n",
      "Iteration 4882 => Loss: 22.558466\n",
      "Iteration 4883 => Loss: 22.555691\n",
      "Iteration 4884 => Loss: 22.552917\n",
      "Iteration 4885 => Loss: 22.550145\n",
      "Iteration 4886 => Loss: 22.547376\n",
      "Iteration 4887 => Loss: 22.544608\n",
      "Iteration 4888 => Loss: 22.541842\n",
      "Iteration 4889 => Loss: 22.539079\n",
      "Iteration 4890 => Loss: 22.536317\n",
      "Iteration 4891 => Loss: 22.533557\n",
      "Iteration 4892 => Loss: 22.530800\n",
      "Iteration 4893 => Loss: 22.528044\n",
      "Iteration 4894 => Loss: 22.525290\n",
      "Iteration 4895 => Loss: 22.525290\n",
      "Iteration 4896 => Loss: 22.522513\n",
      "Iteration 4897 => Loss: 22.519738\n",
      "Iteration 4898 => Loss: 22.516965\n",
      "Iteration 4899 => Loss: 22.514194\n",
      "Iteration 4900 => Loss: 22.511425\n",
      "Iteration 4901 => Loss: 22.508658\n",
      "Iteration 4902 => Loss: 22.505893\n",
      "Iteration 4903 => Loss: 22.503130\n",
      "Iteration 4904 => Loss: 22.500369\n",
      "Iteration 4905 => Loss: 22.497610\n",
      "Iteration 4906 => Loss: 22.494853\n",
      "Iteration 4907 => Loss: 22.492098\n",
      "Iteration 4908 => Loss: 22.489345\n",
      "Iteration 4909 => Loss: 22.486594\n",
      "Iteration 4910 => Loss: 22.483845\n",
      "Iteration 4911 => Loss: 22.481098\n",
      "Iteration 4912 => Loss: 22.478353\n",
      "Iteration 4913 => Loss: 22.475610\n",
      "Iteration 4914 => Loss: 22.475590\n",
      "Iteration 4915 => Loss: 22.472824\n",
      "Iteration 4916 => Loss: 22.470060\n",
      "Iteration 4917 => Loss: 22.467297\n",
      "Iteration 4918 => Loss: 22.464537\n",
      "Iteration 4919 => Loss: 22.461779\n",
      "Iteration 4920 => Loss: 22.459022\n",
      "Iteration 4921 => Loss: 22.456268\n",
      "Iteration 4922 => Loss: 22.453516\n",
      "Iteration 4923 => Loss: 22.450765\n",
      "Iteration 4924 => Loss: 22.448017\n",
      "Iteration 4925 => Loss: 22.445271\n",
      "Iteration 4926 => Loss: 22.442526\n",
      "Iteration 4927 => Loss: 22.439784\n",
      "Iteration 4928 => Loss: 22.437044\n",
      "Iteration 4929 => Loss: 22.434305\n",
      "Iteration 4930 => Loss: 22.431569\n",
      "Iteration 4931 => Loss: 22.428835\n",
      "Iteration 4932 => Loss: 22.428822\n",
      "Iteration 4933 => Loss: 22.426064\n",
      "Iteration 4934 => Loss: 22.423309\n",
      "Iteration 4935 => Loss: 22.420555\n",
      "Iteration 4936 => Loss: 22.417803\n",
      "Iteration 4937 => Loss: 22.415054\n",
      "Iteration 4938 => Loss: 22.412306\n",
      "Iteration 4939 => Loss: 22.409560\n",
      "Iteration 4940 => Loss: 22.406817\n",
      "Iteration 4941 => Loss: 22.404075\n",
      "Iteration 4942 => Loss: 22.401335\n",
      "Iteration 4943 => Loss: 22.398598\n",
      "Iteration 4944 => Loss: 22.395862\n",
      "Iteration 4945 => Loss: 22.393128\n",
      "Iteration 4946 => Loss: 22.390397\n",
      "Iteration 4947 => Loss: 22.387667\n",
      "Iteration 4948 => Loss: 22.384939\n",
      "Iteration 4949 => Loss: 22.382214\n",
      "Iteration 4950 => Loss: 22.382208\n",
      "Iteration 4951 => Loss: 22.379459\n",
      "Iteration 4952 => Loss: 22.376712\n",
      "Iteration 4953 => Loss: 22.373967\n",
      "Iteration 4954 => Loss: 22.371224\n",
      "Iteration 4955 => Loss: 22.368483\n",
      "Iteration 4956 => Loss: 22.365744\n",
      "Iteration 4957 => Loss: 22.363007\n",
      "Iteration 4958 => Loss: 22.360272\n",
      "Iteration 4959 => Loss: 22.357539\n",
      "Iteration 4960 => Loss: 22.354808\n",
      "Iteration 4961 => Loss: 22.352079\n",
      "Iteration 4962 => Loss: 22.349352\n",
      "Iteration 4963 => Loss: 22.346627\n",
      "Iteration 4964 => Loss: 22.343904\n",
      "Iteration 4965 => Loss: 22.341183\n",
      "Iteration 4966 => Loss: 22.338464\n",
      "Iteration 4967 => Loss: 22.335747\n",
      "Iteration 4968 => Loss: 22.333032\n",
      "Iteration 4969 => Loss: 22.333008\n",
      "Iteration 4970 => Loss: 22.330270\n",
      "Iteration 4971 => Loss: 22.327534\n",
      "Iteration 4972 => Loss: 22.324799\n",
      "Iteration 4973 => Loss: 22.322067\n",
      "Iteration 4974 => Loss: 22.319337\n",
      "Iteration 4975 => Loss: 22.316608\n",
      "Iteration 4976 => Loss: 22.313882\n",
      "Iteration 4977 => Loss: 22.311158\n",
      "Iteration 4978 => Loss: 22.308435\n",
      "Iteration 4979 => Loss: 22.305715\n",
      "Iteration 4980 => Loss: 22.302997\n",
      "Iteration 4981 => Loss: 22.300280\n",
      "Iteration 4982 => Loss: 22.297566\n",
      "Iteration 4983 => Loss: 22.294854\n",
      "Iteration 4984 => Loss: 22.292143\n",
      "Iteration 4985 => Loss: 22.289435\n",
      "Iteration 4986 => Loss: 22.286729\n",
      "Iteration 4987 => Loss: 22.286712\n",
      "Iteration 4988 => Loss: 22.283982\n",
      "Iteration 4989 => Loss: 22.281255\n",
      "Iteration 4990 => Loss: 22.278529\n",
      "Iteration 4991 => Loss: 22.275805\n",
      "Iteration 4992 => Loss: 22.273084\n",
      "Iteration 4993 => Loss: 22.270364\n",
      "Iteration 4994 => Loss: 22.267646\n",
      "Iteration 4995 => Loss: 22.264931\n",
      "Iteration 4996 => Loss: 22.262217\n",
      "Iteration 4997 => Loss: 22.259505\n",
      "Iteration 4998 => Loss: 22.256796\n",
      "Iteration 4999 => Loss: 22.254088\n",
      "Iteration 5000 => Loss: 22.251382\n",
      "Iteration 5001 => Loss: 22.248679\n",
      "Iteration 5002 => Loss: 22.245977\n",
      "Iteration 5003 => Loss: 22.243277\n",
      "Iteration 5004 => Loss: 22.240580\n",
      "Iteration 5005 => Loss: 22.240570\n",
      "Iteration 5006 => Loss: 22.237849\n",
      "Iteration 5007 => Loss: 22.235130\n",
      "Iteration 5008 => Loss: 22.232413\n",
      "Iteration 5009 => Loss: 22.229698\n",
      "Iteration 5010 => Loss: 22.226985\n",
      "Iteration 5011 => Loss: 22.224274\n",
      "Iteration 5012 => Loss: 22.221565\n",
      "Iteration 5013 => Loss: 22.218858\n",
      "Iteration 5014 => Loss: 22.216153\n",
      "Iteration 5015 => Loss: 22.213450\n",
      "Iteration 5016 => Loss: 22.210749\n",
      "Iteration 5017 => Loss: 22.208050\n",
      "Iteration 5018 => Loss: 22.205353\n",
      "Iteration 5019 => Loss: 22.202658\n",
      "Iteration 5020 => Loss: 22.199965\n",
      "Iteration 5021 => Loss: 22.197274\n",
      "Iteration 5022 => Loss: 22.194585\n",
      "Iteration 5023 => Loss: 22.194581\n",
      "Iteration 5024 => Loss: 22.191869\n",
      "Iteration 5025 => Loss: 22.189159\n",
      "Iteration 5026 => Loss: 22.186450\n",
      "Iteration 5027 => Loss: 22.183744\n",
      "Iteration 5028 => Loss: 22.181040\n",
      "Iteration 5029 => Loss: 22.178337\n",
      "Iteration 5030 => Loss: 22.175637\n",
      "Iteration 5031 => Loss: 22.172939\n",
      "Iteration 5032 => Loss: 22.170242\n",
      "Iteration 5033 => Loss: 22.167548\n",
      "Iteration 5034 => Loss: 22.164856\n",
      "Iteration 5035 => Loss: 22.162165\n",
      "Iteration 5036 => Loss: 22.159477\n",
      "Iteration 5037 => Loss: 22.156791\n",
      "Iteration 5038 => Loss: 22.154106\n",
      "Iteration 5039 => Loss: 22.151424\n",
      "Iteration 5040 => Loss: 22.148744\n",
      "Iteration 5041 => Loss: 22.146065\n",
      "Iteration 5042 => Loss: 22.146044\n",
      "Iteration 5043 => Loss: 22.143342\n",
      "Iteration 5044 => Loss: 22.140643\n",
      "Iteration 5045 => Loss: 22.137945\n",
      "Iteration 5046 => Loss: 22.135249\n",
      "Iteration 5047 => Loss: 22.132556\n",
      "Iteration 5048 => Loss: 22.129864\n",
      "Iteration 5049 => Loss: 22.127174\n",
      "Iteration 5050 => Loss: 22.124487\n",
      "Iteration 5051 => Loss: 22.121801\n",
      "Iteration 5052 => Loss: 22.119117\n",
      "Iteration 5053 => Loss: 22.116436\n",
      "Iteration 5054 => Loss: 22.113756\n",
      "Iteration 5055 => Loss: 22.111078\n",
      "Iteration 5056 => Loss: 22.108403\n",
      "Iteration 5057 => Loss: 22.105729\n",
      "Iteration 5058 => Loss: 22.103057\n",
      "Iteration 5059 => Loss: 22.100388\n",
      "Iteration 5060 => Loss: 22.100373\n",
      "Iteration 5061 => Loss: 22.097680\n",
      "Iteration 5062 => Loss: 22.094989\n",
      "Iteration 5063 => Loss: 22.092300\n",
      "Iteration 5064 => Loss: 22.089613\n",
      "Iteration 5065 => Loss: 22.086928\n",
      "Iteration 5066 => Loss: 22.084245\n",
      "Iteration 5067 => Loss: 22.081564\n",
      "Iteration 5068 => Loss: 22.078885\n",
      "Iteration 5069 => Loss: 22.076208\n",
      "Iteration 5070 => Loss: 22.073533\n",
      "Iteration 5071 => Loss: 22.070860\n",
      "Iteration 5072 => Loss: 22.068189\n",
      "Iteration 5073 => Loss: 22.065520\n",
      "Iteration 5074 => Loss: 22.062853\n",
      "Iteration 5075 => Loss: 22.060188\n",
      "Iteration 5076 => Loss: 22.057525\n",
      "Iteration 5077 => Loss: 22.054864\n",
      "Iteration 5078 => Loss: 22.054857\n",
      "Iteration 5079 => Loss: 22.052172\n",
      "Iteration 5080 => Loss: 22.049490\n",
      "Iteration 5081 => Loss: 22.046810\n",
      "Iteration 5082 => Loss: 22.044131\n",
      "Iteration 5083 => Loss: 22.041455\n",
      "Iteration 5084 => Loss: 22.038781\n",
      "Iteration 5085 => Loss: 22.036108\n",
      "Iteration 5086 => Loss: 22.033438\n",
      "Iteration 5087 => Loss: 22.030770\n",
      "Iteration 5088 => Loss: 22.028103\n",
      "Iteration 5089 => Loss: 22.025439\n",
      "Iteration 5090 => Loss: 22.022777\n",
      "Iteration 5091 => Loss: 22.020116\n",
      "Iteration 5092 => Loss: 22.017458\n",
      "Iteration 5093 => Loss: 22.014802\n",
      "Iteration 5094 => Loss: 22.012147\n",
      "Iteration 5095 => Loss: 22.009495\n",
      "Iteration 5096 => Loss: 22.009494\n",
      "Iteration 5097 => Loss: 22.006819\n",
      "Iteration 5098 => Loss: 22.004145\n",
      "Iteration 5099 => Loss: 22.001473\n",
      "Iteration 5100 => Loss: 21.998804\n",
      "Iteration 5101 => Loss: 21.996136\n",
      "Iteration 5102 => Loss: 21.993470\n",
      "Iteration 5103 => Loss: 21.990807\n",
      "Iteration 5104 => Loss: 21.988145\n",
      "Iteration 5105 => Loss: 21.985485\n",
      "Iteration 5106 => Loss: 21.982828\n",
      "Iteration 5107 => Loss: 21.980172\n",
      "Iteration 5108 => Loss: 21.977518\n",
      "Iteration 5109 => Loss: 21.974867\n",
      "Iteration 5110 => Loss: 21.972217\n",
      "Iteration 5111 => Loss: 21.969569\n",
      "Iteration 5112 => Loss: 21.966924\n",
      "Iteration 5113 => Loss: 21.964280\n",
      "Iteration 5114 => Loss: 21.961638\n",
      "Iteration 5115 => Loss: 21.961619\n",
      "Iteration 5116 => Loss: 21.958954\n",
      "Iteration 5117 => Loss: 21.956291\n",
      "Iteration 5118 => Loss: 21.953630\n",
      "Iteration 5119 => Loss: 21.950971\n",
      "Iteration 5120 => Loss: 21.948314\n",
      "Iteration 5121 => Loss: 21.945659\n",
      "Iteration 5122 => Loss: 21.943006\n",
      "Iteration 5123 => Loss: 21.940355\n",
      "Iteration 5124 => Loss: 21.937706\n",
      "Iteration 5125 => Loss: 21.935059\n",
      "Iteration 5126 => Loss: 21.932414\n",
      "Iteration 5127 => Loss: 21.929771\n",
      "Iteration 5128 => Loss: 21.927130\n",
      "Iteration 5129 => Loss: 21.924491\n",
      "Iteration 5130 => Loss: 21.921854\n",
      "Iteration 5131 => Loss: 21.919219\n",
      "Iteration 5132 => Loss: 21.916586\n",
      "Iteration 5133 => Loss: 21.916574\n",
      "Iteration 5134 => Loss: 21.913918\n",
      "Iteration 5135 => Loss: 21.911263\n",
      "Iteration 5136 => Loss: 21.908611\n",
      "Iteration 5137 => Loss: 21.905961\n",
      "Iteration 5138 => Loss: 21.903312\n",
      "Iteration 5139 => Loss: 21.900666\n",
      "Iteration 5140 => Loss: 21.898022\n",
      "Iteration 5141 => Loss: 21.895379\n",
      "Iteration 5142 => Loss: 21.892739\n",
      "Iteration 5143 => Loss: 21.890101\n",
      "Iteration 5144 => Loss: 21.887464\n",
      "Iteration 5145 => Loss: 21.884830\n",
      "Iteration 5146 => Loss: 21.882198\n",
      "Iteration 5147 => Loss: 21.879567\n",
      "Iteration 5148 => Loss: 21.876939\n",
      "Iteration 5149 => Loss: 21.874313\n",
      "Iteration 5150 => Loss: 21.871688\n",
      "Iteration 5151 => Loss: 21.871683\n",
      "Iteration 5152 => Loss: 21.869035\n",
      "Iteration 5153 => Loss: 21.866390\n",
      "Iteration 5154 => Loss: 21.863746\n",
      "Iteration 5155 => Loss: 21.861104\n",
      "Iteration 5156 => Loss: 21.858465\n",
      "Iteration 5157 => Loss: 21.855827\n",
      "Iteration 5158 => Loss: 21.853191\n",
      "Iteration 5159 => Loss: 21.850558\n",
      "Iteration 5160 => Loss: 21.847926\n",
      "Iteration 5161 => Loss: 21.845296\n",
      "Iteration 5162 => Loss: 21.842669\n",
      "Iteration 5163 => Loss: 21.840043\n",
      "Iteration 5164 => Loss: 21.837419\n",
      "Iteration 5165 => Loss: 21.834798\n",
      "Iteration 5166 => Loss: 21.832178\n",
      "Iteration 5167 => Loss: 21.829560\n",
      "Iteration 5168 => Loss: 21.826945\n",
      "Iteration 5169 => Loss: 21.824331\n",
      "Iteration 5170 => Loss: 21.824308\n",
      "Iteration 5171 => Loss: 21.821671\n",
      "Iteration 5172 => Loss: 21.819036\n",
      "Iteration 5173 => Loss: 21.816403\n",
      "Iteration 5174 => Loss: 21.813772\n",
      "Iteration 5175 => Loss: 21.811143\n",
      "Iteration 5176 => Loss: 21.808516\n",
      "Iteration 5177 => Loss: 21.805891\n",
      "Iteration 5178 => Loss: 21.803268\n",
      "Iteration 5179 => Loss: 21.800647\n",
      "Iteration 5180 => Loss: 21.798028\n",
      "Iteration 5181 => Loss: 21.795411\n",
      "Iteration 5182 => Loss: 21.792796\n",
      "Iteration 5183 => Loss: 21.790183\n",
      "Iteration 5184 => Loss: 21.787572\n",
      "Iteration 5185 => Loss: 21.784963\n",
      "Iteration 5186 => Loss: 21.782356\n",
      "Iteration 5187 => Loss: 21.779751\n",
      "Iteration 5188 => Loss: 21.779734\n",
      "Iteration 5189 => Loss: 21.777106\n",
      "Iteration 5190 => Loss: 21.774479\n",
      "Iteration 5191 => Loss: 21.771855\n",
      "Iteration 5192 => Loss: 21.769233\n",
      "Iteration 5193 => Loss: 21.766612\n",
      "Iteration 5194 => Loss: 21.763994\n",
      "Iteration 5195 => Loss: 21.761378\n",
      "Iteration 5196 => Loss: 21.758763\n",
      "Iteration 5197 => Loss: 21.756151\n",
      "Iteration 5198 => Loss: 21.753541\n",
      "Iteration 5199 => Loss: 21.750932\n",
      "Iteration 5200 => Loss: 21.748326\n",
      "Iteration 5201 => Loss: 21.745722\n",
      "Iteration 5202 => Loss: 21.743119\n",
      "Iteration 5203 => Loss: 21.740519\n",
      "Iteration 5204 => Loss: 21.737921\n",
      "Iteration 5205 => Loss: 21.735324\n",
      "Iteration 5206 => Loss: 21.735314\n",
      "Iteration 5207 => Loss: 21.732695\n",
      "Iteration 5208 => Loss: 21.730077\n",
      "Iteration 5209 => Loss: 21.727461\n",
      "Iteration 5210 => Loss: 21.724848\n",
      "Iteration 5211 => Loss: 21.722236\n",
      "Iteration 5212 => Loss: 21.719626\n",
      "Iteration 5213 => Loss: 21.717019\n",
      "Iteration 5214 => Loss: 21.714413\n",
      "Iteration 5215 => Loss: 21.711809\n",
      "Iteration 5216 => Loss: 21.709208\n",
      "Iteration 5217 => Loss: 21.706608\n",
      "Iteration 5218 => Loss: 21.704010\n",
      "Iteration 5219 => Loss: 21.701415\n",
      "Iteration 5220 => Loss: 21.698821\n",
      "Iteration 5221 => Loss: 21.696229\n",
      "Iteration 5222 => Loss: 21.693640\n",
      "Iteration 5223 => Loss: 21.691052\n",
      "Iteration 5224 => Loss: 21.691049\n",
      "Iteration 5225 => Loss: 21.688438\n",
      "Iteration 5226 => Loss: 21.685829\n",
      "Iteration 5227 => Loss: 21.683222\n",
      "Iteration 5228 => Loss: 21.680617\n",
      "Iteration 5229 => Loss: 21.678014\n",
      "Iteration 5230 => Loss: 21.675413\n",
      "Iteration 5231 => Loss: 21.672814\n",
      "Iteration 5232 => Loss: 21.670217\n",
      "Iteration 5233 => Loss: 21.667622\n",
      "Iteration 5234 => Loss: 21.665029\n",
      "Iteration 5235 => Loss: 21.662438\n",
      "Iteration 5236 => Loss: 21.659849\n",
      "Iteration 5237 => Loss: 21.657262\n",
      "Iteration 5238 => Loss: 21.654677\n",
      "Iteration 5239 => Loss: 21.652094\n",
      "Iteration 5240 => Loss: 21.649513\n",
      "Iteration 5241 => Loss: 21.646934\n",
      "Iteration 5242 => Loss: 21.644357\n",
      "Iteration 5243 => Loss: 21.644336\n",
      "Iteration 5244 => Loss: 21.641736\n",
      "Iteration 5245 => Loss: 21.639137\n",
      "Iteration 5246 => Loss: 21.636541\n",
      "Iteration 5247 => Loss: 21.633947\n",
      "Iteration 5248 => Loss: 21.631354\n",
      "Iteration 5249 => Loss: 21.628764\n",
      "Iteration 5250 => Loss: 21.626176\n",
      "Iteration 5251 => Loss: 21.623589\n",
      "Iteration 5252 => Loss: 21.621005\n",
      "Iteration 5253 => Loss: 21.618423\n",
      "Iteration 5254 => Loss: 21.615842\n",
      "Iteration 5255 => Loss: 21.613264\n",
      "Iteration 5256 => Loss: 21.610688\n",
      "Iteration 5257 => Loss: 21.608113\n",
      "Iteration 5258 => Loss: 21.605541\n",
      "Iteration 5259 => Loss: 21.602971\n",
      "Iteration 5260 => Loss: 21.600402\n",
      "Iteration 5261 => Loss: 21.600388\n",
      "Iteration 5262 => Loss: 21.597797\n",
      "Iteration 5263 => Loss: 21.595207\n",
      "Iteration 5264 => Loss: 21.592619\n",
      "Iteration 5265 => Loss: 21.590034\n",
      "Iteration 5266 => Loss: 21.587450\n",
      "Iteration 5267 => Loss: 21.584868\n",
      "Iteration 5268 => Loss: 21.582289\n",
      "Iteration 5269 => Loss: 21.579711\n",
      "Iteration 5270 => Loss: 21.577135\n",
      "Iteration 5271 => Loss: 21.574562\n",
      "Iteration 5272 => Loss: 21.571990\n",
      "Iteration 5273 => Loss: 21.569420\n",
      "Iteration 5274 => Loss: 21.566853\n",
      "Iteration 5275 => Loss: 21.564287\n",
      "Iteration 5276 => Loss: 21.561723\n",
      "Iteration 5277 => Loss: 21.559162\n",
      "Iteration 5278 => Loss: 21.556602\n",
      "Iteration 5279 => Loss: 21.556595\n",
      "Iteration 5280 => Loss: 21.554012\n",
      "Iteration 5281 => Loss: 21.551431\n",
      "Iteration 5282 => Loss: 21.548852\n",
      "Iteration 5283 => Loss: 21.546275\n",
      "Iteration 5284 => Loss: 21.543700\n",
      "Iteration 5285 => Loss: 21.541127\n",
      "Iteration 5286 => Loss: 21.538556\n",
      "Iteration 5287 => Loss: 21.535987\n",
      "Iteration 5288 => Loss: 21.533420\n",
      "Iteration 5289 => Loss: 21.530855\n",
      "Iteration 5290 => Loss: 21.528292\n",
      "Iteration 5291 => Loss: 21.525731\n",
      "Iteration 5292 => Loss: 21.523172\n",
      "Iteration 5293 => Loss: 21.520615\n",
      "Iteration 5294 => Loss: 21.518060\n",
      "Iteration 5295 => Loss: 21.515507\n",
      "Iteration 5296 => Loss: 21.512956\n",
      "Iteration 5297 => Loss: 21.512955\n",
      "Iteration 5298 => Loss: 21.510381\n",
      "Iteration 5299 => Loss: 21.507808\n",
      "Iteration 5300 => Loss: 21.505238\n",
      "Iteration 5301 => Loss: 21.502670\n",
      "Iteration 5302 => Loss: 21.500103\n",
      "Iteration 5303 => Loss: 21.497539\n",
      "Iteration 5304 => Loss: 21.494977\n",
      "Iteration 5305 => Loss: 21.492416\n",
      "Iteration 5306 => Loss: 21.489858\n",
      "Iteration 5307 => Loss: 21.487302\n",
      "Iteration 5308 => Loss: 21.484747\n",
      "Iteration 5309 => Loss: 21.482195\n",
      "Iteration 5310 => Loss: 21.479645\n",
      "Iteration 5311 => Loss: 21.477096\n",
      "Iteration 5312 => Loss: 21.474550\n",
      "Iteration 5313 => Loss: 21.472006\n",
      "Iteration 5314 => Loss: 21.469463\n",
      "Iteration 5315 => Loss: 21.466923\n",
      "Iteration 5316 => Loss: 21.466904\n",
      "Iteration 5317 => Loss: 21.464341\n",
      "Iteration 5318 => Loss: 21.461779\n",
      "Iteration 5319 => Loss: 21.459219\n",
      "Iteration 5320 => Loss: 21.456662\n",
      "Iteration 5321 => Loss: 21.454106\n",
      "Iteration 5322 => Loss: 21.451552\n",
      "Iteration 5323 => Loss: 21.449001\n",
      "Iteration 5324 => Loss: 21.446451\n",
      "Iteration 5325 => Loss: 21.443903\n",
      "Iteration 5326 => Loss: 21.441358\n",
      "Iteration 5327 => Loss: 21.438814\n",
      "Iteration 5328 => Loss: 21.436272\n",
      "Iteration 5329 => Loss: 21.433733\n",
      "Iteration 5330 => Loss: 21.431195\n",
      "Iteration 5331 => Loss: 21.428659\n",
      "Iteration 5332 => Loss: 21.426126\n",
      "Iteration 5333 => Loss: 21.423594\n",
      "Iteration 5334 => Loss: 21.423582\n",
      "Iteration 5335 => Loss: 21.421027\n",
      "Iteration 5336 => Loss: 21.418474\n",
      "Iteration 5337 => Loss: 21.415923\n",
      "Iteration 5338 => Loss: 21.413374\n",
      "Iteration 5339 => Loss: 21.410827\n",
      "Iteration 5340 => Loss: 21.408282\n",
      "Iteration 5341 => Loss: 21.405739\n",
      "Iteration 5342 => Loss: 21.403198\n",
      "Iteration 5343 => Loss: 21.400659\n",
      "Iteration 5344 => Loss: 21.398122\n",
      "Iteration 5345 => Loss: 21.395587\n",
      "Iteration 5346 => Loss: 21.393054\n",
      "Iteration 5347 => Loss: 21.390523\n",
      "Iteration 5348 => Loss: 21.387994\n",
      "Iteration 5349 => Loss: 21.385467\n",
      "Iteration 5350 => Loss: 21.382942\n",
      "Iteration 5351 => Loss: 21.380419\n",
      "Iteration 5352 => Loss: 21.380414\n",
      "Iteration 5353 => Loss: 21.377868\n",
      "Iteration 5354 => Loss: 21.375324\n",
      "Iteration 5355 => Loss: 21.372781\n",
      "Iteration 5356 => Loss: 21.370241\n",
      "Iteration 5357 => Loss: 21.367703\n",
      "Iteration 5358 => Loss: 21.365166\n",
      "Iteration 5359 => Loss: 21.362632\n",
      "Iteration 5360 => Loss: 21.360100\n",
      "Iteration 5361 => Loss: 21.357569\n",
      "Iteration 5362 => Loss: 21.355041\n",
      "Iteration 5363 => Loss: 21.352515\n",
      "Iteration 5364 => Loss: 21.349990\n",
      "Iteration 5365 => Loss: 21.347468\n",
      "Iteration 5366 => Loss: 21.344948\n",
      "Iteration 5367 => Loss: 21.342429\n",
      "Iteration 5368 => Loss: 21.339913\n",
      "Iteration 5369 => Loss: 21.337399\n",
      "Iteration 5370 => Loss: 21.334886\n",
      "Iteration 5371 => Loss: 21.334863\n",
      "Iteration 5372 => Loss: 21.332327\n",
      "Iteration 5373 => Loss: 21.329794\n",
      "Iteration 5374 => Loss: 21.327262\n",
      "Iteration 5375 => Loss: 21.324732\n",
      "Iteration 5376 => Loss: 21.322205\n",
      "Iteration 5377 => Loss: 21.319679\n",
      "Iteration 5378 => Loss: 21.317155\n",
      "Iteration 5379 => Loss: 21.314634\n",
      "Iteration 5380 => Loss: 21.312114\n",
      "Iteration 5381 => Loss: 21.309596\n",
      "Iteration 5382 => Loss: 21.307081\n",
      "Iteration 5383 => Loss: 21.304567\n",
      "Iteration 5384 => Loss: 21.302055\n",
      "Iteration 5385 => Loss: 21.299546\n",
      "Iteration 5386 => Loss: 21.297038\n",
      "Iteration 5387 => Loss: 21.294532\n",
      "Iteration 5388 => Loss: 21.292029\n",
      "Iteration 5389 => Loss: 21.292012\n",
      "Iteration 5390 => Loss: 21.289485\n",
      "Iteration 5391 => Loss: 21.286960\n",
      "Iteration 5392 => Loss: 21.284437\n",
      "Iteration 5393 => Loss: 21.281916\n",
      "Iteration 5394 => Loss: 21.279397\n",
      "Iteration 5395 => Loss: 21.276880\n",
      "Iteration 5396 => Loss: 21.274365\n",
      "Iteration 5397 => Loss: 21.271852\n",
      "Iteration 5398 => Loss: 21.269341\n",
      "Iteration 5399 => Loss: 21.266832\n",
      "Iteration 5400 => Loss: 21.264325\n",
      "Iteration 5401 => Loss: 21.261820\n",
      "Iteration 5402 => Loss: 21.259317\n",
      "Iteration 5403 => Loss: 21.256816\n",
      "Iteration 5404 => Loss: 21.254317\n",
      "Iteration 5405 => Loss: 21.251820\n",
      "Iteration 5406 => Loss: 21.249325\n",
      "Iteration 5407 => Loss: 21.249316\n",
      "Iteration 5408 => Loss: 21.246797\n",
      "Iteration 5409 => Loss: 21.244281\n",
      "Iteration 5410 => Loss: 21.241767\n",
      "Iteration 5411 => Loss: 21.239254\n",
      "Iteration 5412 => Loss: 21.236744\n",
      "Iteration 5413 => Loss: 21.234236\n",
      "Iteration 5414 => Loss: 21.231729\n",
      "Iteration 5415 => Loss: 21.229225\n",
      "Iteration 5416 => Loss: 21.226723\n",
      "Iteration 5417 => Loss: 21.224222\n",
      "Iteration 5418 => Loss: 21.221724\n",
      "Iteration 5419 => Loss: 21.219228\n",
      "Iteration 5420 => Loss: 21.216733\n",
      "Iteration 5421 => Loss: 21.214241\n",
      "Iteration 5422 => Loss: 21.211751\n",
      "Iteration 5423 => Loss: 21.209262\n",
      "Iteration 5424 => Loss: 21.206776\n",
      "Iteration 5425 => Loss: 21.206773\n",
      "Iteration 5426 => Loss: 21.204264\n",
      "Iteration 5427 => Loss: 21.201756\n",
      "Iteration 5428 => Loss: 21.199250\n",
      "Iteration 5429 => Loss: 21.196747\n",
      "Iteration 5430 => Loss: 21.194245\n",
      "Iteration 5431 => Loss: 21.191745\n",
      "Iteration 5432 => Loss: 21.189248\n",
      "Iteration 5433 => Loss: 21.186752\n",
      "Iteration 5434 => Loss: 21.184258\n",
      "Iteration 5435 => Loss: 21.181767\n",
      "Iteration 5436 => Loss: 21.179277\n",
      "Iteration 5437 => Loss: 21.176789\n",
      "Iteration 5438 => Loss: 21.174304\n",
      "Iteration 5439 => Loss: 21.171820\n",
      "Iteration 5440 => Loss: 21.169338\n",
      "Iteration 5441 => Loss: 21.166859\n",
      "Iteration 5442 => Loss: 21.164381\n",
      "Iteration 5443 => Loss: 21.161905\n",
      "Iteration 5444 => Loss: 21.161885\n",
      "Iteration 5445 => Loss: 21.159386\n",
      "Iteration 5446 => Loss: 21.156889\n",
      "Iteration 5447 => Loss: 21.154394\n",
      "Iteration 5448 => Loss: 21.151901\n",
      "Iteration 5449 => Loss: 21.149410\n",
      "Iteration 5450 => Loss: 21.146921\n",
      "Iteration 5451 => Loss: 21.144434\n",
      "Iteration 5452 => Loss: 21.141949\n",
      "Iteration 5453 => Loss: 21.139466\n",
      "Iteration 5454 => Loss: 21.136985\n",
      "Iteration 5455 => Loss: 21.134506\n",
      "Iteration 5456 => Loss: 21.132029\n",
      "Iteration 5457 => Loss: 21.129554\n",
      "Iteration 5458 => Loss: 21.127081\n",
      "Iteration 5459 => Loss: 21.124610\n",
      "Iteration 5460 => Loss: 21.122141\n",
      "Iteration 5461 => Loss: 21.119674\n",
      "Iteration 5462 => Loss: 21.119660\n",
      "Iteration 5463 => Loss: 21.117169\n",
      "Iteration 5464 => Loss: 21.114681\n",
      "Iteration 5465 => Loss: 21.112195\n",
      "Iteration 5466 => Loss: 21.109710\n",
      "Iteration 5467 => Loss: 21.107228\n",
      "Iteration 5468 => Loss: 21.104748\n",
      "Iteration 5469 => Loss: 21.102269\n",
      "Iteration 5470 => Loss: 21.099793\n",
      "Iteration 5471 => Loss: 21.097319\n",
      "Iteration 5472 => Loss: 21.094846\n",
      "Iteration 5473 => Loss: 21.092376\n",
      "Iteration 5474 => Loss: 21.089908\n",
      "Iteration 5475 => Loss: 21.087441\n",
      "Iteration 5476 => Loss: 21.084977\n",
      "Iteration 5477 => Loss: 21.082515\n",
      "Iteration 5478 => Loss: 21.080054\n",
      "Iteration 5479 => Loss: 21.077596\n",
      "Iteration 5480 => Loss: 21.077589\n",
      "Iteration 5481 => Loss: 21.075107\n",
      "Iteration 5482 => Loss: 21.072627\n",
      "Iteration 5483 => Loss: 21.070150\n",
      "Iteration 5484 => Loss: 21.067674\n",
      "Iteration 5485 => Loss: 21.065200\n",
      "Iteration 5486 => Loss: 21.062729\n",
      "Iteration 5487 => Loss: 21.060259\n",
      "Iteration 5488 => Loss: 21.057791\n",
      "Iteration 5489 => Loss: 21.055326\n",
      "Iteration 5490 => Loss: 21.052862\n",
      "Iteration 5491 => Loss: 21.050400\n",
      "Iteration 5492 => Loss: 21.047941\n",
      "Iteration 5493 => Loss: 21.045483\n",
      "Iteration 5494 => Loss: 21.043027\n",
      "Iteration 5495 => Loss: 21.040574\n",
      "Iteration 5496 => Loss: 21.038122\n",
      "Iteration 5497 => Loss: 21.035672\n",
      "Iteration 5498 => Loss: 21.035672\n",
      "Iteration 5499 => Loss: 21.033199\n",
      "Iteration 5500 => Loss: 21.030728\n",
      "Iteration 5501 => Loss: 21.028259\n",
      "Iteration 5502 => Loss: 21.025792\n",
      "Iteration 5503 => Loss: 21.023327\n",
      "Iteration 5504 => Loss: 21.020864\n",
      "Iteration 5505 => Loss: 21.018403\n",
      "Iteration 5506 => Loss: 21.015944\n",
      "Iteration 5507 => Loss: 21.013487\n",
      "Iteration 5508 => Loss: 21.011032\n",
      "Iteration 5509 => Loss: 21.008579\n",
      "Iteration 5510 => Loss: 21.006128\n",
      "Iteration 5511 => Loss: 21.003679\n",
      "Iteration 5512 => Loss: 21.001232\n",
      "Iteration 5513 => Loss: 20.998787\n",
      "Iteration 5514 => Loss: 20.996344\n",
      "Iteration 5515 => Loss: 20.993903\n",
      "Iteration 5516 => Loss: 20.991464\n",
      "Iteration 5517 => Loss: 20.991446\n",
      "Iteration 5518 => Loss: 20.988983\n",
      "Iteration 5519 => Loss: 20.986523\n",
      "Iteration 5520 => Loss: 20.984065\n",
      "Iteration 5521 => Loss: 20.981608\n",
      "Iteration 5522 => Loss: 20.979154\n",
      "Iteration 5523 => Loss: 20.976702\n",
      "Iteration 5524 => Loss: 20.974251\n",
      "Iteration 5525 => Loss: 20.971803\n",
      "Iteration 5526 => Loss: 20.969357\n",
      "Iteration 5527 => Loss: 20.966912\n",
      "Iteration 5528 => Loss: 20.964470\n",
      "Iteration 5529 => Loss: 20.962030\n",
      "Iteration 5530 => Loss: 20.959591\n",
      "Iteration 5531 => Loss: 20.957155\n",
      "Iteration 5532 => Loss: 20.954721\n",
      "Iteration 5533 => Loss: 20.952288\n",
      "Iteration 5534 => Loss: 20.949858\n",
      "Iteration 5535 => Loss: 20.949847\n",
      "Iteration 5536 => Loss: 20.947393\n",
      "Iteration 5537 => Loss: 20.944941\n",
      "Iteration 5538 => Loss: 20.942492\n",
      "Iteration 5539 => Loss: 20.940044\n",
      "Iteration 5540 => Loss: 20.937598\n",
      "Iteration 5541 => Loss: 20.935155\n",
      "Iteration 5542 => Loss: 20.932713\n",
      "Iteration 5543 => Loss: 20.930273\n",
      "Iteration 5544 => Loss: 20.927836\n",
      "Iteration 5545 => Loss: 20.925400\n",
      "Iteration 5546 => Loss: 20.922966\n",
      "Iteration 5547 => Loss: 20.920535\n",
      "Iteration 5548 => Loss: 20.918105\n",
      "Iteration 5549 => Loss: 20.915677\n",
      "Iteration 5550 => Loss: 20.913252\n",
      "Iteration 5551 => Loss: 20.910828\n",
      "Iteration 5552 => Loss: 20.908406\n",
      "Iteration 5553 => Loss: 20.908402\n",
      "Iteration 5554 => Loss: 20.905957\n",
      "Iteration 5555 => Loss: 20.903514\n",
      "Iteration 5556 => Loss: 20.901073\n",
      "Iteration 5557 => Loss: 20.898634\n",
      "Iteration 5558 => Loss: 20.896197\n",
      "Iteration 5559 => Loss: 20.893762\n",
      "Iteration 5560 => Loss: 20.891329\n",
      "Iteration 5561 => Loss: 20.888898\n",
      "Iteration 5562 => Loss: 20.886469\n",
      "Iteration 5563 => Loss: 20.884042\n",
      "Iteration 5564 => Loss: 20.881617\n",
      "Iteration 5565 => Loss: 20.879194\n",
      "Iteration 5566 => Loss: 20.876773\n",
      "Iteration 5567 => Loss: 20.874354\n",
      "Iteration 5568 => Loss: 20.871937\n",
      "Iteration 5569 => Loss: 20.869522\n",
      "Iteration 5570 => Loss: 20.867109\n",
      "Iteration 5571 => Loss: 20.864698\n",
      "Iteration 5572 => Loss: 20.864674\n",
      "Iteration 5573 => Loss: 20.862240\n",
      "Iteration 5574 => Loss: 20.859808\n",
      "Iteration 5575 => Loss: 20.857377\n",
      "Iteration 5576 => Loss: 20.854949\n",
      "Iteration 5577 => Loss: 20.852523\n",
      "Iteration 5578 => Loss: 20.850098\n",
      "Iteration 5579 => Loss: 20.847676\n",
      "Iteration 5580 => Loss: 20.845256\n",
      "Iteration 5581 => Loss: 20.842837\n",
      "Iteration 5582 => Loss: 20.840421\n",
      "Iteration 5583 => Loss: 20.838007\n",
      "Iteration 5584 => Loss: 20.835594\n",
      "Iteration 5585 => Loss: 20.833184\n",
      "Iteration 5586 => Loss: 20.830776\n",
      "Iteration 5587 => Loss: 20.828369\n",
      "Iteration 5588 => Loss: 20.825965\n",
      "Iteration 5589 => Loss: 20.823563\n",
      "Iteration 5590 => Loss: 20.823547\n",
      "Iteration 5591 => Loss: 20.821121\n",
      "Iteration 5592 => Loss: 20.818697\n",
      "Iteration 5593 => Loss: 20.816276\n",
      "Iteration 5594 => Loss: 20.813856\n",
      "Iteration 5595 => Loss: 20.811438\n",
      "Iteration 5596 => Loss: 20.809023\n",
      "Iteration 5597 => Loss: 20.806609\n",
      "Iteration 5598 => Loss: 20.804197\n",
      "Iteration 5599 => Loss: 20.801788\n",
      "Iteration 5600 => Loss: 20.799380\n",
      "Iteration 5601 => Loss: 20.796974\n",
      "Iteration 5602 => Loss: 20.794571\n",
      "Iteration 5603 => Loss: 20.792169\n",
      "Iteration 5604 => Loss: 20.789769\n",
      "Iteration 5605 => Loss: 20.787372\n",
      "Iteration 5606 => Loss: 20.784976\n",
      "Iteration 5607 => Loss: 20.782582\n",
      "Iteration 5608 => Loss: 20.782573\n",
      "Iteration 5609 => Loss: 20.780156\n",
      "Iteration 5610 => Loss: 20.777741\n",
      "Iteration 5611 => Loss: 20.775328\n",
      "Iteration 5612 => Loss: 20.772917\n",
      "Iteration 5613 => Loss: 20.770508\n",
      "Iteration 5614 => Loss: 20.768101\n",
      "Iteration 5615 => Loss: 20.765696\n",
      "Iteration 5616 => Loss: 20.763293\n",
      "Iteration 5617 => Loss: 20.760892\n",
      "Iteration 5618 => Loss: 20.758493\n",
      "Iteration 5619 => Loss: 20.756096\n",
      "Iteration 5620 => Loss: 20.753701\n",
      "Iteration 5621 => Loss: 20.751308\n",
      "Iteration 5622 => Loss: 20.748917\n",
      "Iteration 5623 => Loss: 20.746528\n",
      "Iteration 5624 => Loss: 20.744141\n",
      "Iteration 5625 => Loss: 20.741756\n",
      "Iteration 5626 => Loss: 20.741754\n",
      "Iteration 5627 => Loss: 20.739346\n",
      "Iteration 5628 => Loss: 20.736939\n",
      "Iteration 5629 => Loss: 20.734535\n",
      "Iteration 5630 => Loss: 20.732133\n",
      "Iteration 5631 => Loss: 20.729732\n",
      "Iteration 5632 => Loss: 20.727334\n",
      "Iteration 5633 => Loss: 20.724938\n",
      "Iteration 5634 => Loss: 20.722543\n",
      "Iteration 5635 => Loss: 20.720151\n",
      "Iteration 5636 => Loss: 20.717761\n",
      "Iteration 5637 => Loss: 20.715372\n",
      "Iteration 5638 => Loss: 20.712986\n",
      "Iteration 5639 => Loss: 20.710602\n",
      "Iteration 5640 => Loss: 20.708219\n",
      "Iteration 5641 => Loss: 20.705839\n",
      "Iteration 5642 => Loss: 20.703461\n",
      "Iteration 5643 => Loss: 20.701084\n",
      "Iteration 5644 => Loss: 20.698710\n",
      "Iteration 5645 => Loss: 20.698689\n",
      "Iteration 5646 => Loss: 20.696292\n",
      "Iteration 5647 => Loss: 20.693896\n",
      "Iteration 5648 => Loss: 20.691502\n",
      "Iteration 5649 => Loss: 20.689111\n",
      "Iteration 5650 => Loss: 20.686721\n",
      "Iteration 5651 => Loss: 20.684333\n",
      "Iteration 5652 => Loss: 20.681948\n",
      "Iteration 5653 => Loss: 20.679564\n",
      "Iteration 5654 => Loss: 20.677182\n",
      "Iteration 5655 => Loss: 20.674803\n",
      "Iteration 5656 => Loss: 20.672425\n",
      "Iteration 5657 => Loss: 20.670049\n",
      "Iteration 5658 => Loss: 20.667676\n",
      "Iteration 5659 => Loss: 20.665304\n",
      "Iteration 5660 => Loss: 20.662934\n",
      "Iteration 5661 => Loss: 20.660567\n",
      "Iteration 5662 => Loss: 20.658201\n",
      "Iteration 5663 => Loss: 20.658187\n",
      "Iteration 5664 => Loss: 20.655798\n",
      "Iteration 5665 => Loss: 20.653411\n",
      "Iteration 5666 => Loss: 20.651026\n",
      "Iteration 5667 => Loss: 20.648643\n",
      "Iteration 5668 => Loss: 20.646262\n",
      "Iteration 5669 => Loss: 20.643883\n",
      "Iteration 5670 => Loss: 20.641506\n",
      "Iteration 5671 => Loss: 20.639131\n",
      "Iteration 5672 => Loss: 20.636758\n",
      "Iteration 5673 => Loss: 20.634387\n",
      "Iteration 5674 => Loss: 20.632018\n",
      "Iteration 5675 => Loss: 20.629651\n",
      "Iteration 5676 => Loss: 20.627286\n",
      "Iteration 5677 => Loss: 20.624923\n",
      "Iteration 5678 => Loss: 20.622562\n",
      "Iteration 5679 => Loss: 20.620203\n",
      "Iteration 5680 => Loss: 20.617846\n",
      "Iteration 5681 => Loss: 20.617839\n",
      "Iteration 5682 => Loss: 20.615459\n",
      "Iteration 5683 => Loss: 20.613081\n",
      "Iteration 5684 => Loss: 20.610704\n",
      "Iteration 5685 => Loss: 20.608330\n",
      "Iteration 5686 => Loss: 20.605958\n",
      "Iteration 5687 => Loss: 20.603587\n",
      "Iteration 5688 => Loss: 20.601219\n",
      "Iteration 5689 => Loss: 20.598853\n",
      "Iteration 5690 => Loss: 20.596488\n",
      "Iteration 5691 => Loss: 20.594126\n",
      "Iteration 5692 => Loss: 20.591766\n",
      "Iteration 5693 => Loss: 20.589407\n",
      "Iteration 5694 => Loss: 20.587051\n",
      "Iteration 5695 => Loss: 20.584697\n",
      "Iteration 5696 => Loss: 20.582344\n",
      "Iteration 5697 => Loss: 20.579994\n",
      "Iteration 5698 => Loss: 20.577646\n",
      "Iteration 5699 => Loss: 20.575299\n",
      "Iteration 5700 => Loss: 20.575274\n",
      "Iteration 5701 => Loss: 20.572904\n",
      "Iteration 5702 => Loss: 20.570537\n",
      "Iteration 5703 => Loss: 20.568171\n",
      "Iteration 5704 => Loss: 20.565807\n",
      "Iteration 5705 => Loss: 20.563446\n",
      "Iteration 5706 => Loss: 20.561086\n",
      "Iteration 5707 => Loss: 20.558728\n",
      "Iteration 5708 => Loss: 20.556373\n",
      "Iteration 5709 => Loss: 20.554019\n",
      "Iteration 5710 => Loss: 20.551667\n",
      "Iteration 5711 => Loss: 20.549318\n",
      "Iteration 5712 => Loss: 20.546970\n",
      "Iteration 5713 => Loss: 20.544624\n",
      "Iteration 5714 => Loss: 20.542281\n",
      "Iteration 5715 => Loss: 20.539939\n",
      "Iteration 5716 => Loss: 20.537599\n",
      "Iteration 5717 => Loss: 20.535262\n",
      "Iteration 5718 => Loss: 20.535244\n",
      "Iteration 5719 => Loss: 20.532883\n",
      "Iteration 5720 => Loss: 20.530524\n",
      "Iteration 5721 => Loss: 20.528167\n",
      "Iteration 5722 => Loss: 20.525812\n",
      "Iteration 5723 => Loss: 20.523459\n",
      "Iteration 5724 => Loss: 20.521108\n",
      "Iteration 5725 => Loss: 20.518759\n",
      "Iteration 5726 => Loss: 20.516412\n",
      "Iteration 5727 => Loss: 20.514067\n",
      "Iteration 5728 => Loss: 20.511724\n",
      "Iteration 5729 => Loss: 20.509383\n",
      "Iteration 5730 => Loss: 20.507044\n",
      "Iteration 5731 => Loss: 20.504707\n",
      "Iteration 5732 => Loss: 20.502372\n",
      "Iteration 5733 => Loss: 20.500039\n",
      "Iteration 5734 => Loss: 20.497708\n",
      "Iteration 5735 => Loss: 20.495379\n",
      "Iteration 5736 => Loss: 20.495367\n",
      "Iteration 5737 => Loss: 20.493015\n",
      "Iteration 5738 => Loss: 20.490665\n",
      "Iteration 5739 => Loss: 20.488316\n",
      "Iteration 5740 => Loss: 20.485970\n",
      "Iteration 5741 => Loss: 20.483626\n",
      "Iteration 5742 => Loss: 20.481283\n",
      "Iteration 5743 => Loss: 20.478943\n",
      "Iteration 5744 => Loss: 20.476605\n",
      "Iteration 5745 => Loss: 20.474268\n",
      "Iteration 5746 => Loss: 20.471934\n",
      "Iteration 5747 => Loss: 20.469602\n",
      "Iteration 5748 => Loss: 20.467271\n",
      "Iteration 5749 => Loss: 20.464943\n",
      "Iteration 5750 => Loss: 20.462617\n",
      "Iteration 5751 => Loss: 20.460292\n",
      "Iteration 5752 => Loss: 20.457970\n",
      "Iteration 5753 => Loss: 20.455650\n",
      "Iteration 5754 => Loss: 20.455645\n",
      "Iteration 5755 => Loss: 20.453301\n",
      "Iteration 5756 => Loss: 20.450960\n",
      "Iteration 5757 => Loss: 20.448620\n",
      "Iteration 5758 => Loss: 20.446282\n",
      "Iteration 5759 => Loss: 20.443947\n",
      "Iteration 5760 => Loss: 20.441613\n",
      "Iteration 5761 => Loss: 20.439281\n",
      "Iteration 5762 => Loss: 20.436952\n",
      "Iteration 5763 => Loss: 20.434624\n",
      "Iteration 5764 => Loss: 20.432298\n",
      "Iteration 5765 => Loss: 20.429975\n",
      "Iteration 5766 => Loss: 20.427653\n",
      "Iteration 5767 => Loss: 20.425333\n",
      "Iteration 5768 => Loss: 20.423016\n",
      "Iteration 5769 => Loss: 20.420700\n",
      "Iteration 5770 => Loss: 20.418386\n",
      "Iteration 5771 => Loss: 20.416075\n",
      "Iteration 5772 => Loss: 20.413765\n",
      "Iteration 5773 => Loss: 20.413742\n",
      "Iteration 5774 => Loss: 20.411409\n",
      "Iteration 5775 => Loss: 20.409078\n",
      "Iteration 5776 => Loss: 20.406749\n",
      "Iteration 5777 => Loss: 20.404422\n",
      "Iteration 5778 => Loss: 20.402097\n",
      "Iteration 5779 => Loss: 20.399774\n",
      "Iteration 5780 => Loss: 20.397453\n",
      "Iteration 5781 => Loss: 20.395134\n",
      "Iteration 5782 => Loss: 20.392817\n",
      "Iteration 5783 => Loss: 20.390502\n",
      "Iteration 5784 => Loss: 20.388189\n",
      "Iteration 5785 => Loss: 20.385878\n",
      "Iteration 5786 => Loss: 20.383569\n",
      "Iteration 5787 => Loss: 20.381262\n",
      "Iteration 5788 => Loss: 20.378957\n",
      "Iteration 5789 => Loss: 20.376654\n",
      "Iteration 5790 => Loss: 20.374353\n",
      "Iteration 5791 => Loss: 20.374337\n",
      "Iteration 5792 => Loss: 20.372013\n",
      "Iteration 5793 => Loss: 20.369691\n",
      "Iteration 5794 => Loss: 20.367370\n",
      "Iteration 5795 => Loss: 20.365052\n",
      "Iteration 5796 => Loss: 20.362736\n",
      "Iteration 5797 => Loss: 20.360421\n",
      "Iteration 5798 => Loss: 20.358109\n",
      "Iteration 5799 => Loss: 20.355799\n",
      "Iteration 5800 => Loss: 20.353490\n",
      "Iteration 5801 => Loss: 20.351184\n",
      "Iteration 5802 => Loss: 20.348880\n",
      "Iteration 5803 => Loss: 20.346577\n",
      "Iteration 5804 => Loss: 20.344277\n",
      "Iteration 5805 => Loss: 20.341979\n",
      "Iteration 5806 => Loss: 20.339682\n",
      "Iteration 5807 => Loss: 20.337388\n",
      "Iteration 5808 => Loss: 20.335096\n",
      "Iteration 5809 => Loss: 20.335087\n",
      "Iteration 5810 => Loss: 20.332771\n",
      "Iteration 5811 => Loss: 20.330458\n",
      "Iteration 5812 => Loss: 20.328146\n",
      "Iteration 5813 => Loss: 20.325836\n",
      "Iteration 5814 => Loss: 20.323529\n",
      "Iteration 5815 => Loss: 20.321223\n",
      "Iteration 5816 => Loss: 20.318919\n",
      "Iteration 5817 => Loss: 20.316618\n",
      "Iteration 5818 => Loss: 20.314318\n",
      "Iteration 5819 => Loss: 20.312020\n",
      "Iteration 5820 => Loss: 20.309725\n",
      "Iteration 5821 => Loss: 20.307431\n",
      "Iteration 5822 => Loss: 20.305139\n",
      "Iteration 5823 => Loss: 20.302850\n",
      "Iteration 5824 => Loss: 20.300562\n",
      "Iteration 5825 => Loss: 20.298276\n",
      "Iteration 5826 => Loss: 20.295993\n",
      "Iteration 5827 => Loss: 20.295991\n",
      "Iteration 5828 => Loss: 20.293684\n",
      "Iteration 5829 => Loss: 20.291379\n",
      "Iteration 5830 => Loss: 20.289076\n",
      "Iteration 5831 => Loss: 20.286775\n",
      "Iteration 5832 => Loss: 20.284476\n",
      "Iteration 5833 => Loss: 20.282179\n",
      "Iteration 5834 => Loss: 20.279884\n",
      "Iteration 5835 => Loss: 20.277591\n",
      "Iteration 5836 => Loss: 20.275300\n",
      "Iteration 5837 => Loss: 20.273011\n",
      "Iteration 5838 => Loss: 20.270724\n",
      "Iteration 5839 => Loss: 20.268439\n",
      "Iteration 5840 => Loss: 20.266156\n",
      "Iteration 5841 => Loss: 20.263875\n",
      "Iteration 5842 => Loss: 20.261596\n",
      "Iteration 5843 => Loss: 20.259319\n",
      "Iteration 5844 => Loss: 20.257044\n",
      "Iteration 5845 => Loss: 20.254771\n",
      "Iteration 5846 => Loss: 20.254750\n",
      "Iteration 5847 => Loss: 20.252454\n",
      "Iteration 5848 => Loss: 20.250159\n",
      "Iteration 5849 => Loss: 20.247867\n",
      "Iteration 5850 => Loss: 20.245577\n",
      "Iteration 5851 => Loss: 20.243288\n",
      "Iteration 5852 => Loss: 20.241002\n",
      "Iteration 5853 => Loss: 20.238718\n",
      "Iteration 5854 => Loss: 20.236435\n",
      "Iteration 5855 => Loss: 20.234155\n",
      "Iteration 5856 => Loss: 20.231877\n",
      "Iteration 5857 => Loss: 20.229600\n",
      "Iteration 5858 => Loss: 20.227326\n",
      "Iteration 5859 => Loss: 20.225054\n",
      "Iteration 5860 => Loss: 20.222783\n",
      "Iteration 5861 => Loss: 20.220515\n",
      "Iteration 5862 => Loss: 20.218249\n",
      "Iteration 5863 => Loss: 20.215984\n",
      "Iteration 5864 => Loss: 20.215971\n",
      "Iteration 5865 => Loss: 20.213683\n",
      "Iteration 5866 => Loss: 20.211398\n",
      "Iteration 5867 => Loss: 20.209114\n",
      "Iteration 5868 => Loss: 20.206832\n",
      "Iteration 5869 => Loss: 20.204553\n",
      "Iteration 5870 => Loss: 20.202275\n",
      "Iteration 5871 => Loss: 20.199999\n",
      "Iteration 5872 => Loss: 20.197726\n",
      "Iteration 5873 => Loss: 20.195454\n",
      "Iteration 5874 => Loss: 20.193184\n",
      "Iteration 5875 => Loss: 20.190917\n",
      "Iteration 5876 => Loss: 20.188651\n",
      "Iteration 5877 => Loss: 20.186387\n",
      "Iteration 5878 => Loss: 20.184126\n",
      "Iteration 5879 => Loss: 20.181866\n",
      "Iteration 5880 => Loss: 20.179608\n",
      "Iteration 5881 => Loss: 20.177353\n",
      "Iteration 5882 => Loss: 20.177346\n",
      "Iteration 5883 => Loss: 20.175067\n",
      "Iteration 5884 => Loss: 20.172790\n",
      "Iteration 5885 => Loss: 20.170515\n",
      "Iteration 5886 => Loss: 20.168242\n",
      "Iteration 5887 => Loss: 20.165971\n",
      "Iteration 5888 => Loss: 20.163702\n",
      "Iteration 5889 => Loss: 20.161435\n",
      "Iteration 5890 => Loss: 20.159170\n",
      "Iteration 5891 => Loss: 20.156907\n",
      "Iteration 5892 => Loss: 20.154646\n",
      "Iteration 5893 => Loss: 20.152387\n",
      "Iteration 5894 => Loss: 20.150130\n",
      "Iteration 5895 => Loss: 20.147875\n",
      "Iteration 5896 => Loss: 20.145622\n",
      "Iteration 5897 => Loss: 20.143371\n",
      "Iteration 5898 => Loss: 20.141122\n",
      "Iteration 5899 => Loss: 20.138875\n",
      "Iteration 5900 => Loss: 20.136630\n",
      "Iteration 5901 => Loss: 20.136605\n",
      "Iteration 5902 => Loss: 20.134337\n",
      "Iteration 5903 => Loss: 20.132071\n",
      "Iteration 5904 => Loss: 20.129806\n",
      "Iteration 5905 => Loss: 20.127544\n",
      "Iteration 5906 => Loss: 20.125284\n",
      "Iteration 5907 => Loss: 20.123025\n",
      "Iteration 5908 => Loss: 20.120769\n",
      "Iteration 5909 => Loss: 20.118515\n",
      "Iteration 5910 => Loss: 20.116262\n",
      "Iteration 5911 => Loss: 20.114012\n",
      "Iteration 5912 => Loss: 20.111764\n",
      "Iteration 5913 => Loss: 20.109517\n",
      "Iteration 5914 => Loss: 20.107273\n",
      "Iteration 5915 => Loss: 20.105031\n",
      "Iteration 5916 => Loss: 20.102790\n",
      "Iteration 5917 => Loss: 20.100552\n",
      "Iteration 5918 => Loss: 20.098316\n",
      "Iteration 5919 => Loss: 20.098298\n",
      "Iteration 5920 => Loss: 20.096038\n",
      "Iteration 5921 => Loss: 20.093780\n",
      "Iteration 5922 => Loss: 20.091525\n",
      "Iteration 5923 => Loss: 20.089271\n",
      "Iteration 5924 => Loss: 20.087019\n",
      "Iteration 5925 => Loss: 20.084770\n",
      "Iteration 5926 => Loss: 20.082522\n",
      "Iteration 5927 => Loss: 20.080276\n",
      "Iteration 5928 => Loss: 20.078033\n",
      "Iteration 5929 => Loss: 20.075791\n",
      "Iteration 5930 => Loss: 20.073551\n",
      "Iteration 5931 => Loss: 20.071314\n",
      "Iteration 5932 => Loss: 20.069078\n",
      "Iteration 5933 => Loss: 20.066844\n",
      "Iteration 5934 => Loss: 20.064613\n",
      "Iteration 5935 => Loss: 20.062383\n",
      "Iteration 5936 => Loss: 20.060155\n",
      "Iteration 5937 => Loss: 20.060144\n",
      "Iteration 5938 => Loss: 20.057893\n",
      "Iteration 5939 => Loss: 20.055644\n",
      "Iteration 5940 => Loss: 20.053397\n",
      "Iteration 5941 => Loss: 20.051152\n",
      "Iteration 5942 => Loss: 20.048909\n",
      "Iteration 5943 => Loss: 20.046668\n",
      "Iteration 5944 => Loss: 20.044429\n",
      "Iteration 5945 => Loss: 20.042192\n",
      "Iteration 5946 => Loss: 20.039957\n",
      "Iteration 5947 => Loss: 20.037724\n",
      "Iteration 5948 => Loss: 20.035493\n",
      "Iteration 5949 => Loss: 20.033264\n",
      "Iteration 5950 => Loss: 20.031037\n",
      "Iteration 5951 => Loss: 20.028812\n",
      "Iteration 5952 => Loss: 20.026589\n",
      "Iteration 5953 => Loss: 20.024368\n",
      "Iteration 5954 => Loss: 20.022149\n",
      "Iteration 5955 => Loss: 20.022145\n",
      "Iteration 5956 => Loss: 20.019903\n",
      "Iteration 5957 => Loss: 20.017662\n",
      "Iteration 5958 => Loss: 20.015424\n",
      "Iteration 5959 => Loss: 20.013188\n",
      "Iteration 5960 => Loss: 20.010953\n",
      "Iteration 5961 => Loss: 20.008721\n",
      "Iteration 5962 => Loss: 20.006491\n",
      "Iteration 5963 => Loss: 20.004262\n",
      "Iteration 5964 => Loss: 20.002036\n",
      "Iteration 5965 => Loss: 19.999812\n",
      "Iteration 5966 => Loss: 19.997589\n",
      "Iteration 5967 => Loss: 19.995369\n",
      "Iteration 5968 => Loss: 19.993151\n",
      "Iteration 5969 => Loss: 19.990934\n",
      "Iteration 5970 => Loss: 19.988720\n",
      "Iteration 5971 => Loss: 19.986508\n",
      "Iteration 5972 => Loss: 19.984297\n",
      "Iteration 5973 => Loss: 19.982089\n",
      "Iteration 5974 => Loss: 19.982066\n",
      "Iteration 5975 => Loss: 19.979835\n",
      "Iteration 5976 => Loss: 19.977605\n",
      "Iteration 5977 => Loss: 19.975377\n",
      "Iteration 5978 => Loss: 19.973152\n",
      "Iteration 5979 => Loss: 19.970928\n",
      "Iteration 5980 => Loss: 19.968706\n",
      "Iteration 5981 => Loss: 19.966487\n",
      "Iteration 5982 => Loss: 19.964269\n",
      "Iteration 5983 => Loss: 19.962053\n",
      "Iteration 5984 => Loss: 19.959840\n",
      "Iteration 5985 => Loss: 19.957628\n",
      "Iteration 5986 => Loss: 19.955418\n",
      "Iteration 5987 => Loss: 19.953211\n",
      "Iteration 5988 => Loss: 19.951005\n",
      "Iteration 5989 => Loss: 19.948801\n",
      "Iteration 5990 => Loss: 19.946600\n",
      "Iteration 5991 => Loss: 19.944400\n",
      "Iteration 5992 => Loss: 19.944385\n",
      "Iteration 5993 => Loss: 19.942162\n",
      "Iteration 5994 => Loss: 19.939941\n",
      "Iteration 5995 => Loss: 19.937722\n",
      "Iteration 5996 => Loss: 19.935505\n",
      "Iteration 5997 => Loss: 19.933290\n",
      "Iteration 5998 => Loss: 19.931077\n",
      "Iteration 5999 => Loss: 19.928866\n",
      "Iteration 6000 => Loss: 19.926657\n",
      "Iteration 6001 => Loss: 19.924450\n",
      "Iteration 6002 => Loss: 19.922245\n",
      "Iteration 6003 => Loss: 19.920042\n",
      "Iteration 6004 => Loss: 19.917841\n",
      "Iteration 6005 => Loss: 19.915642\n",
      "Iteration 6006 => Loss: 19.913445\n",
      "Iteration 6007 => Loss: 19.911250\n",
      "Iteration 6008 => Loss: 19.909057\n",
      "Iteration 6009 => Loss: 19.906866\n",
      "Iteration 6010 => Loss: 19.906857\n",
      "Iteration 6011 => Loss: 19.904643\n",
      "Iteration 6012 => Loss: 19.902430\n",
      "Iteration 6013 => Loss: 19.900220\n",
      "Iteration 6014 => Loss: 19.898012\n",
      "Iteration 6015 => Loss: 19.895805\n",
      "Iteration 6016 => Loss: 19.893601\n",
      "Iteration 6017 => Loss: 19.891399\n",
      "Iteration 6018 => Loss: 19.889198\n",
      "Iteration 6019 => Loss: 19.887000\n",
      "Iteration 6020 => Loss: 19.884804\n",
      "Iteration 6021 => Loss: 19.882609\n",
      "Iteration 6022 => Loss: 19.880417\n",
      "Iteration 6023 => Loss: 19.878227\n",
      "Iteration 6024 => Loss: 19.876038\n",
      "Iteration 6025 => Loss: 19.873852\n",
      "Iteration 6026 => Loss: 19.871668\n",
      "Iteration 6027 => Loss: 19.869485\n",
      "Iteration 6028 => Loss: 19.869483\n",
      "Iteration 6029 => Loss: 19.867278\n",
      "Iteration 6030 => Loss: 19.865074\n",
      "Iteration 6031 => Loss: 19.862872\n",
      "Iteration 6032 => Loss: 19.860673\n",
      "Iteration 6033 => Loss: 19.858475\n",
      "Iteration 6034 => Loss: 19.856279\n",
      "Iteration 6035 => Loss: 19.854086\n",
      "Iteration 6036 => Loss: 19.851894\n",
      "Iteration 6037 => Loss: 19.849704\n",
      "Iteration 6038 => Loss: 19.847517\n",
      "Iteration 6039 => Loss: 19.845331\n",
      "Iteration 6040 => Loss: 19.843147\n",
      "Iteration 6041 => Loss: 19.840966\n",
      "Iteration 6042 => Loss: 19.838786\n",
      "Iteration 6043 => Loss: 19.836608\n",
      "Iteration 6044 => Loss: 19.834433\n",
      "Iteration 6045 => Loss: 19.832259\n",
      "Iteration 6046 => Loss: 19.830087\n",
      "Iteration 6047 => Loss: 19.830067\n",
      "Iteration 6048 => Loss: 19.827872\n",
      "Iteration 6049 => Loss: 19.825679\n",
      "Iteration 6050 => Loss: 19.823488\n",
      "Iteration 6051 => Loss: 19.821299\n",
      "Iteration 6052 => Loss: 19.819112\n",
      "Iteration 6053 => Loss: 19.816927\n",
      "Iteration 6054 => Loss: 19.814744\n",
      "Iteration 6055 => Loss: 19.812563\n",
      "Iteration 6056 => Loss: 19.810384\n",
      "Iteration 6057 => Loss: 19.808207\n",
      "Iteration 6058 => Loss: 19.806032\n",
      "Iteration 6059 => Loss: 19.803859\n",
      "Iteration 6060 => Loss: 19.801688\n",
      "Iteration 6061 => Loss: 19.799519\n",
      "Iteration 6062 => Loss: 19.797352\n",
      "Iteration 6063 => Loss: 19.795187\n",
      "Iteration 6064 => Loss: 19.793024\n",
      "Iteration 6065 => Loss: 19.793011\n",
      "Iteration 6066 => Loss: 19.790825\n",
      "Iteration 6067 => Loss: 19.788640\n",
      "Iteration 6068 => Loss: 19.786458\n",
      "Iteration 6069 => Loss: 19.784278\n",
      "Iteration 6070 => Loss: 19.782099\n",
      "Iteration 6071 => Loss: 19.779923\n",
      "Iteration 6072 => Loss: 19.777749\n",
      "Iteration 6073 => Loss: 19.775576\n",
      "Iteration 6074 => Loss: 19.773406\n",
      "Iteration 6075 => Loss: 19.771238\n",
      "Iteration 6076 => Loss: 19.769071\n",
      "Iteration 6077 => Loss: 19.766907\n",
      "Iteration 6078 => Loss: 19.764745\n",
      "Iteration 6079 => Loss: 19.762584\n",
      "Iteration 6080 => Loss: 19.760426\n",
      "Iteration 6081 => Loss: 19.758270\n",
      "Iteration 6082 => Loss: 19.756115\n",
      "Iteration 6083 => Loss: 19.756109\n",
      "Iteration 6084 => Loss: 19.753932\n",
      "Iteration 6085 => Loss: 19.751756\n",
      "Iteration 6086 => Loss: 19.749582\n",
      "Iteration 6087 => Loss: 19.747411\n",
      "Iteration 6088 => Loss: 19.745241\n",
      "Iteration 6089 => Loss: 19.743073\n",
      "Iteration 6090 => Loss: 19.740908\n",
      "Iteration 6091 => Loss: 19.738744\n",
      "Iteration 6092 => Loss: 19.736582\n",
      "Iteration 6093 => Loss: 19.734423\n",
      "Iteration 6094 => Loss: 19.732265\n",
      "Iteration 6095 => Loss: 19.730109\n",
      "Iteration 6096 => Loss: 19.727956\n",
      "Iteration 6097 => Loss: 19.725804\n",
      "Iteration 6098 => Loss: 19.723654\n",
      "Iteration 6099 => Loss: 19.721507\n",
      "Iteration 6100 => Loss: 19.719361\n",
      "Iteration 6101 => Loss: 19.717217\n",
      "Iteration 6102 => Loss: 19.717193\n",
      "Iteration 6103 => Loss: 19.715026\n",
      "Iteration 6104 => Loss: 19.712861\n",
      "Iteration 6105 => Loss: 19.710698\n",
      "Iteration 6106 => Loss: 19.708537\n",
      "Iteration 6107 => Loss: 19.706378\n",
      "Iteration 6108 => Loss: 19.704221\n",
      "Iteration 6109 => Loss: 19.702066\n",
      "Iteration 6110 => Loss: 19.699913\n",
      "Iteration 6111 => Loss: 19.697762\n",
      "Iteration 6112 => Loss: 19.695613\n",
      "Iteration 6113 => Loss: 19.693466\n",
      "Iteration 6114 => Loss: 19.691321\n",
      "Iteration 6115 => Loss: 19.689178\n",
      "Iteration 6116 => Loss: 19.687037\n",
      "Iteration 6117 => Loss: 19.684898\n",
      "Iteration 6118 => Loss: 19.682761\n",
      "Iteration 6119 => Loss: 19.680626\n",
      "Iteration 6120 => Loss: 19.680608\n",
      "Iteration 6121 => Loss: 19.678449\n",
      "Iteration 6122 => Loss: 19.676293\n",
      "Iteration 6123 => Loss: 19.674139\n",
      "Iteration 6124 => Loss: 19.671986\n",
      "Iteration 6125 => Loss: 19.669836\n",
      "Iteration 6126 => Loss: 19.667688\n",
      "Iteration 6127 => Loss: 19.665541\n",
      "Iteration 6128 => Loss: 19.663397\n",
      "Iteration 6129 => Loss: 19.661255\n",
      "Iteration 6130 => Loss: 19.659114\n",
      "Iteration 6131 => Loss: 19.656976\n",
      "Iteration 6132 => Loss: 19.654840\n",
      "Iteration 6133 => Loss: 19.652705\n",
      "Iteration 6134 => Loss: 19.650573\n",
      "Iteration 6135 => Loss: 19.648443\n",
      "Iteration 6136 => Loss: 19.646314\n",
      "Iteration 6137 => Loss: 19.644188\n",
      "Iteration 6138 => Loss: 19.644177\n",
      "Iteration 6139 => Loss: 19.642028\n",
      "Iteration 6140 => Loss: 19.639880\n",
      "Iteration 6141 => Loss: 19.637734\n",
      "Iteration 6142 => Loss: 19.635591\n",
      "Iteration 6143 => Loss: 19.633449\n",
      "Iteration 6144 => Loss: 19.631309\n",
      "Iteration 6145 => Loss: 19.629172\n",
      "Iteration 6146 => Loss: 19.627036\n",
      "Iteration 6147 => Loss: 19.624902\n",
      "Iteration 6148 => Loss: 19.622771\n",
      "Iteration 6149 => Loss: 19.620641\n",
      "Iteration 6150 => Loss: 19.618513\n",
      "Iteration 6151 => Loss: 19.616388\n",
      "Iteration 6152 => Loss: 19.614264\n",
      "Iteration 6153 => Loss: 19.612142\n",
      "Iteration 6154 => Loss: 19.610023\n",
      "Iteration 6155 => Loss: 19.607905\n",
      "Iteration 6156 => Loss: 19.607901\n",
      "Iteration 6157 => Loss: 19.605760\n",
      "Iteration 6158 => Loss: 19.603621\n",
      "Iteration 6159 => Loss: 19.601484\n",
      "Iteration 6160 => Loss: 19.599349\n",
      "Iteration 6161 => Loss: 19.597216\n",
      "Iteration 6162 => Loss: 19.595085\n",
      "Iteration 6163 => Loss: 19.592956\n",
      "Iteration 6164 => Loss: 19.590829\n",
      "Iteration 6165 => Loss: 19.588704\n",
      "Iteration 6166 => Loss: 19.586581\n",
      "Iteration 6167 => Loss: 19.584460\n",
      "Iteration 6168 => Loss: 19.582341\n",
      "Iteration 6169 => Loss: 19.580224\n",
      "Iteration 6170 => Loss: 19.578109\n",
      "Iteration 6171 => Loss: 19.575996\n",
      "Iteration 6172 => Loss: 19.573885\n",
      "Iteration 6173 => Loss: 19.571776\n",
      "Iteration 6174 => Loss: 19.569669\n",
      "Iteration 6175 => Loss: 19.569647\n",
      "Iteration 6176 => Loss: 19.567517\n",
      "Iteration 6177 => Loss: 19.565388\n",
      "Iteration 6178 => Loss: 19.563262\n",
      "Iteration 6179 => Loss: 19.561138\n",
      "Iteration 6180 => Loss: 19.559015\n",
      "Iteration 6181 => Loss: 19.556895\n",
      "Iteration 6182 => Loss: 19.554777\n",
      "Iteration 6183 => Loss: 19.552660\n",
      "Iteration 6184 => Loss: 19.550546\n",
      "Iteration 6185 => Loss: 19.548434\n",
      "Iteration 6186 => Loss: 19.546323\n",
      "Iteration 6187 => Loss: 19.544215\n",
      "Iteration 6188 => Loss: 19.542109\n",
      "Iteration 6189 => Loss: 19.540004\n",
      "Iteration 6190 => Loss: 19.537902\n",
      "Iteration 6191 => Loss: 19.535802\n",
      "Iteration 6192 => Loss: 19.533703\n",
      "Iteration 6193 => Loss: 19.533688\n",
      "Iteration 6194 => Loss: 19.531566\n",
      "Iteration 6195 => Loss: 19.529447\n",
      "Iteration 6196 => Loss: 19.527329\n",
      "Iteration 6197 => Loss: 19.525213\n",
      "Iteration 6198 => Loss: 19.523100\n",
      "Iteration 6199 => Loss: 19.520988\n",
      "Iteration 6200 => Loss: 19.518878\n",
      "Iteration 6201 => Loss: 19.516771\n",
      "Iteration 6202 => Loss: 19.514665\n",
      "Iteration 6203 => Loss: 19.512561\n",
      "Iteration 6204 => Loss: 19.510460\n",
      "Iteration 6205 => Loss: 19.508360\n",
      "Iteration 6206 => Loss: 19.506262\n",
      "Iteration 6207 => Loss: 19.504167\n",
      "Iteration 6208 => Loss: 19.502073\n",
      "Iteration 6209 => Loss: 19.499981\n",
      "Iteration 6210 => Loss: 19.497892\n",
      "Iteration 6211 => Loss: 19.497883\n",
      "Iteration 6212 => Loss: 19.495770\n",
      "Iteration 6213 => Loss: 19.493659\n",
      "Iteration 6214 => Loss: 19.491550\n",
      "Iteration 6215 => Loss: 19.489443\n",
      "Iteration 6216 => Loss: 19.487338\n",
      "Iteration 6217 => Loss: 19.485235\n",
      "Iteration 6218 => Loss: 19.483134\n",
      "Iteration 6219 => Loss: 19.481035\n",
      "Iteration 6220 => Loss: 19.478938\n",
      "Iteration 6221 => Loss: 19.476843\n",
      "Iteration 6222 => Loss: 19.474750\n",
      "Iteration 6223 => Loss: 19.472659\n",
      "Iteration 6224 => Loss: 19.470570\n",
      "Iteration 6225 => Loss: 19.468483\n",
      "Iteration 6226 => Loss: 19.466398\n",
      "Iteration 6227 => Loss: 19.464315\n",
      "Iteration 6228 => Loss: 19.462234\n",
      "Iteration 6229 => Loss: 19.462233\n",
      "Iteration 6230 => Loss: 19.460128\n",
      "Iteration 6231 => Loss: 19.458026\n",
      "Iteration 6232 => Loss: 19.455926\n",
      "Iteration 6233 => Loss: 19.453827\n",
      "Iteration 6234 => Loss: 19.451731\n",
      "Iteration 6235 => Loss: 19.449637\n",
      "Iteration 6236 => Loss: 19.447544\n",
      "Iteration 6237 => Loss: 19.445454\n",
      "Iteration 6238 => Loss: 19.443366\n",
      "Iteration 6239 => Loss: 19.441279\n",
      "Iteration 6240 => Loss: 19.439195\n",
      "Iteration 6241 => Loss: 19.437113\n",
      "Iteration 6242 => Loss: 19.435032\n",
      "Iteration 6243 => Loss: 19.432954\n",
      "Iteration 6244 => Loss: 19.430878\n",
      "Iteration 6245 => Loss: 19.428803\n",
      "Iteration 6246 => Loss: 19.426731\n",
      "Iteration 6247 => Loss: 19.424661\n",
      "Iteration 6248 => Loss: 19.424641\n",
      "Iteration 6249 => Loss: 19.422547\n",
      "Iteration 6250 => Loss: 19.420455\n",
      "Iteration 6251 => Loss: 19.418366\n",
      "Iteration 6252 => Loss: 19.416278\n",
      "Iteration 6253 => Loss: 19.414192\n",
      "Iteration 6254 => Loss: 19.412109\n",
      "Iteration 6255 => Loss: 19.410027\n",
      "Iteration 6256 => Loss: 19.407947\n",
      "Iteration 6257 => Loss: 19.405870\n",
      "Iteration 6258 => Loss: 19.403794\n",
      "Iteration 6259 => Loss: 19.401720\n",
      "Iteration 6260 => Loss: 19.399649\n",
      "Iteration 6261 => Loss: 19.397579\n",
      "Iteration 6262 => Loss: 19.395511\n",
      "Iteration 6263 => Loss: 19.393446\n",
      "Iteration 6264 => Loss: 19.391382\n",
      "Iteration 6265 => Loss: 19.389320\n",
      "Iteration 6266 => Loss: 19.389308\n",
      "Iteration 6267 => Loss: 19.387223\n",
      "Iteration 6268 => Loss: 19.385140\n",
      "Iteration 6269 => Loss: 19.383059\n",
      "Iteration 6270 => Loss: 19.380980\n",
      "Iteration 6271 => Loss: 19.378903\n",
      "Iteration 6272 => Loss: 19.376828\n",
      "Iteration 6273 => Loss: 19.374755\n",
      "Iteration 6274 => Loss: 19.372684\n",
      "Iteration 6275 => Loss: 19.370615\n",
      "Iteration 6276 => Loss: 19.368548\n",
      "Iteration 6277 => Loss: 19.366483\n",
      "Iteration 6278 => Loss: 19.364420\n",
      "Iteration 6279 => Loss: 19.362359\n",
      "Iteration 6280 => Loss: 19.360300\n",
      "Iteration 6281 => Loss: 19.358243\n",
      "Iteration 6282 => Loss: 19.356188\n",
      "Iteration 6283 => Loss: 19.354135\n",
      "Iteration 6284 => Loss: 19.354129\n",
      "Iteration 6285 => Loss: 19.352052\n",
      "Iteration 6286 => Loss: 19.349978\n",
      "Iteration 6287 => Loss: 19.347906\n",
      "Iteration 6288 => Loss: 19.345835\n",
      "Iteration 6289 => Loss: 19.343767\n",
      "Iteration 6290 => Loss: 19.341701\n",
      "Iteration 6291 => Loss: 19.339636\n",
      "Iteration 6292 => Loss: 19.337574\n",
      "Iteration 6293 => Loss: 19.335514\n",
      "Iteration 6294 => Loss: 19.333455\n",
      "Iteration 6295 => Loss: 19.331399\n",
      "Iteration 6296 => Loss: 19.329345\n",
      "Iteration 6297 => Loss: 19.327292\n",
      "Iteration 6298 => Loss: 19.325242\n",
      "Iteration 6299 => Loss: 19.323194\n",
      "Iteration 6300 => Loss: 19.321147\n",
      "Iteration 6301 => Loss: 19.319103\n",
      "Iteration 6302 => Loss: 19.317061\n",
      "Iteration 6303 => Loss: 19.317036\n",
      "Iteration 6304 => Loss: 19.314970\n",
      "Iteration 6305 => Loss: 19.312907\n",
      "Iteration 6306 => Loss: 19.310845\n",
      "Iteration 6307 => Loss: 19.308785\n",
      "Iteration 6308 => Loss: 19.306728\n",
      "Iteration 6309 => Loss: 19.304672\n",
      "Iteration 6310 => Loss: 19.302618\n",
      "Iteration 6311 => Loss: 19.300567\n",
      "Iteration 6312 => Loss: 19.298517\n",
      "Iteration 6313 => Loss: 19.296469\n",
      "Iteration 6314 => Loss: 19.294424\n",
      "Iteration 6315 => Loss: 19.292380\n",
      "Iteration 6316 => Loss: 19.290338\n",
      "Iteration 6317 => Loss: 19.288299\n",
      "Iteration 6318 => Loss: 19.286261\n",
      "Iteration 6319 => Loss: 19.284225\n",
      "Iteration 6320 => Loss: 19.282192\n",
      "Iteration 6321 => Loss: 19.282174\n",
      "Iteration 6322 => Loss: 19.280117\n",
      "Iteration 6323 => Loss: 19.278062\n",
      "Iteration 6324 => Loss: 19.276009\n",
      "Iteration 6325 => Loss: 19.273958\n",
      "Iteration 6326 => Loss: 19.271909\n",
      "Iteration 6327 => Loss: 19.269862\n",
      "Iteration 6328 => Loss: 19.267817\n",
      "Iteration 6329 => Loss: 19.265774\n",
      "Iteration 6330 => Loss: 19.263733\n",
      "Iteration 6331 => Loss: 19.261694\n",
      "Iteration 6332 => Loss: 19.259657\n",
      "Iteration 6333 => Loss: 19.257622\n",
      "Iteration 6334 => Loss: 19.255589\n",
      "Iteration 6335 => Loss: 19.253558\n",
      "Iteration 6336 => Loss: 19.251529\n",
      "Iteration 6337 => Loss: 19.249502\n",
      "Iteration 6338 => Loss: 19.247477\n",
      "Iteration 6339 => Loss: 19.247467\n",
      "Iteration 6340 => Loss: 19.245418\n",
      "Iteration 6341 => Loss: 19.243372\n",
      "Iteration 6342 => Loss: 19.241328\n",
      "Iteration 6343 => Loss: 19.239285\n",
      "Iteration 6344 => Loss: 19.237245\n",
      "Iteration 6345 => Loss: 19.235207\n",
      "Iteration 6346 => Loss: 19.233170\n",
      "Iteration 6347 => Loss: 19.231136\n",
      "Iteration 6348 => Loss: 19.229104\n",
      "Iteration 6349 => Loss: 19.227073\n",
      "Iteration 6350 => Loss: 19.225045\n",
      "Iteration 6351 => Loss: 19.223019\n",
      "Iteration 6352 => Loss: 19.220994\n",
      "Iteration 6353 => Loss: 19.218972\n",
      "Iteration 6354 => Loss: 19.216952\n",
      "Iteration 6355 => Loss: 19.214933\n",
      "Iteration 6356 => Loss: 19.212917\n",
      "Iteration 6357 => Loss: 19.212914\n",
      "Iteration 6358 => Loss: 19.210874\n",
      "Iteration 6359 => Loss: 19.208836\n",
      "Iteration 6360 => Loss: 19.206801\n",
      "Iteration 6361 => Loss: 19.204767\n",
      "Iteration 6362 => Loss: 19.202735\n",
      "Iteration 6363 => Loss: 19.200706\n",
      "Iteration 6364 => Loss: 19.198678\n",
      "Iteration 6365 => Loss: 19.196652\n",
      "Iteration 6366 => Loss: 19.194629\n",
      "Iteration 6367 => Loss: 19.192607\n",
      "Iteration 6368 => Loss: 19.190587\n",
      "Iteration 6369 => Loss: 19.188570\n",
      "Iteration 6370 => Loss: 19.186554\n",
      "Iteration 6371 => Loss: 19.184540\n",
      "Iteration 6372 => Loss: 19.182529\n",
      "Iteration 6373 => Loss: 19.180519\n",
      "Iteration 6374 => Loss: 19.178511\n",
      "Iteration 6375 => Loss: 19.176506\n",
      "Iteration 6376 => Loss: 19.176484\n",
      "Iteration 6377 => Loss: 19.174455\n",
      "Iteration 6378 => Loss: 19.172428\n",
      "Iteration 6379 => Loss: 19.170403\n",
      "Iteration 6380 => Loss: 19.168380\n",
      "Iteration 6381 => Loss: 19.166359\n",
      "Iteration 6382 => Loss: 19.164340\n",
      "Iteration 6383 => Loss: 19.162323\n",
      "Iteration 6384 => Loss: 19.160308\n",
      "Iteration 6385 => Loss: 19.158295\n",
      "Iteration 6386 => Loss: 19.156284\n",
      "Iteration 6387 => Loss: 19.154275\n",
      "Iteration 6388 => Loss: 19.152268\n",
      "Iteration 6389 => Loss: 19.150263\n",
      "Iteration 6390 => Loss: 19.148260\n",
      "Iteration 6391 => Loss: 19.146259\n",
      "Iteration 6392 => Loss: 19.144260\n",
      "Iteration 6393 => Loss: 19.142263\n",
      "Iteration 6394 => Loss: 19.142247\n",
      "Iteration 6395 => Loss: 19.140227\n",
      "Iteration 6396 => Loss: 19.138209\n",
      "Iteration 6397 => Loss: 19.136192\n",
      "Iteration 6398 => Loss: 19.134178\n",
      "Iteration 6399 => Loss: 19.132166\n",
      "Iteration 6400 => Loss: 19.130155\n",
      "Iteration 6401 => Loss: 19.128147\n",
      "Iteration 6402 => Loss: 19.126141\n",
      "Iteration 6403 => Loss: 19.124136\n",
      "Iteration 6404 => Loss: 19.122134\n",
      "Iteration 6405 => Loss: 19.120134\n",
      "Iteration 6406 => Loss: 19.118135\n",
      "Iteration 6407 => Loss: 19.116139\n",
      "Iteration 6408 => Loss: 19.114145\n",
      "Iteration 6409 => Loss: 19.112152\n",
      "Iteration 6410 => Loss: 19.110162\n",
      "Iteration 6411 => Loss: 19.108174\n",
      "Iteration 6412 => Loss: 19.108166\n",
      "Iteration 6413 => Loss: 19.106154\n",
      "Iteration 6414 => Loss: 19.104144\n",
      "Iteration 6415 => Loss: 19.102137\n",
      "Iteration 6416 => Loss: 19.100131\n",
      "Iteration 6417 => Loss: 19.098127\n",
      "Iteration 6418 => Loss: 19.096126\n",
      "Iteration 6419 => Loss: 19.094126\n",
      "Iteration 6420 => Loss: 19.092128\n",
      "Iteration 6421 => Loss: 19.090133\n",
      "Iteration 6422 => Loss: 19.088139\n",
      "Iteration 6423 => Loss: 19.086147\n",
      "Iteration 6424 => Loss: 19.084158\n",
      "Iteration 6425 => Loss: 19.082170\n",
      "Iteration 6426 => Loss: 19.080184\n",
      "Iteration 6427 => Loss: 19.078201\n",
      "Iteration 6428 => Loss: 19.076219\n",
      "Iteration 6429 => Loss: 19.074239\n",
      "Iteration 6430 => Loss: 19.074238\n",
      "Iteration 6431 => Loss: 19.072235\n",
      "Iteration 6432 => Loss: 19.070234\n",
      "Iteration 6433 => Loss: 19.068235\n",
      "Iteration 6434 => Loss: 19.066238\n",
      "Iteration 6435 => Loss: 19.064243\n",
      "Iteration 6436 => Loss: 19.062250\n",
      "Iteration 6437 => Loss: 19.060259\n",
      "Iteration 6438 => Loss: 19.058270\n",
      "Iteration 6439 => Loss: 19.056283\n",
      "Iteration 6440 => Loss: 19.054298\n",
      "Iteration 6441 => Loss: 19.052315\n",
      "Iteration 6442 => Loss: 19.050334\n",
      "Iteration 6443 => Loss: 19.048355\n",
      "Iteration 6444 => Loss: 19.046378\n",
      "Iteration 6445 => Loss: 19.044403\n",
      "Iteration 6446 => Loss: 19.042430\n",
      "Iteration 6447 => Loss: 19.040459\n",
      "Iteration 6448 => Loss: 19.038490\n",
      "Iteration 6449 => Loss: 19.038471\n",
      "Iteration 6450 => Loss: 19.036478\n",
      "Iteration 6451 => Loss: 19.034488\n",
      "Iteration 6452 => Loss: 19.032500\n",
      "Iteration 6453 => Loss: 19.030513\n",
      "Iteration 6454 => Loss: 19.028529\n",
      "Iteration 6455 => Loss: 19.026547\n",
      "Iteration 6456 => Loss: 19.024566\n",
      "Iteration 6457 => Loss: 19.022588\n",
      "Iteration 6458 => Loss: 19.020612\n",
      "Iteration 6459 => Loss: 19.018637\n",
      "Iteration 6460 => Loss: 19.016665\n",
      "Iteration 6461 => Loss: 19.014695\n",
      "Iteration 6462 => Loss: 19.012726\n",
      "Iteration 6463 => Loss: 19.010760\n",
      "Iteration 6464 => Loss: 19.008796\n",
      "Iteration 6465 => Loss: 19.006833\n",
      "Iteration 6466 => Loss: 19.004873\n",
      "Iteration 6467 => Loss: 19.004860\n",
      "Iteration 6468 => Loss: 19.002877\n",
      "Iteration 6469 => Loss: 19.000895\n",
      "Iteration 6470 => Loss: 18.998915\n",
      "Iteration 6471 => Loss: 18.996938\n",
      "Iteration 6472 => Loss: 18.994962\n",
      "Iteration 6473 => Loss: 18.992988\n",
      "Iteration 6474 => Loss: 18.991017\n",
      "Iteration 6475 => Loss: 18.989047\n",
      "Iteration 6476 => Loss: 18.987079\n",
      "Iteration 6477 => Loss: 18.985114\n",
      "Iteration 6478 => Loss: 18.983150\n",
      "Iteration 6479 => Loss: 18.981188\n",
      "Iteration 6480 => Loss: 18.979229\n",
      "Iteration 6481 => Loss: 18.977271\n",
      "Iteration 6482 => Loss: 18.975315\n",
      "Iteration 6483 => Loss: 18.973362\n",
      "Iteration 6484 => Loss: 18.971410\n",
      "Iteration 6485 => Loss: 18.971404\n",
      "Iteration 6486 => Loss: 18.969429\n",
      "Iteration 6487 => Loss: 18.967456\n",
      "Iteration 6488 => Loss: 18.965485\n",
      "Iteration 6489 => Loss: 18.963516\n",
      "Iteration 6490 => Loss: 18.961549\n",
      "Iteration 6491 => Loss: 18.959584\n",
      "Iteration 6492 => Loss: 18.957621\n",
      "Iteration 6493 => Loss: 18.955660\n",
      "Iteration 6494 => Loss: 18.953701\n",
      "Iteration 6495 => Loss: 18.951744\n",
      "Iteration 6496 => Loss: 18.949789\n",
      "Iteration 6497 => Loss: 18.947836\n",
      "Iteration 6498 => Loss: 18.945885\n",
      "Iteration 6499 => Loss: 18.943936\n",
      "Iteration 6500 => Loss: 18.941989\n",
      "Iteration 6501 => Loss: 18.940044\n",
      "Iteration 6502 => Loss: 18.938101\n",
      "Iteration 6503 => Loss: 18.936160\n",
      "Iteration 6504 => Loss: 18.936136\n",
      "Iteration 6505 => Loss: 18.934172\n",
      "Iteration 6506 => Loss: 18.932209\n",
      "Iteration 6507 => Loss: 18.930249\n",
      "Iteration 6508 => Loss: 18.928291\n",
      "Iteration 6509 => Loss: 18.926334\n",
      "Iteration 6510 => Loss: 18.924380\n",
      "Iteration 6511 => Loss: 18.922428\n",
      "Iteration 6512 => Loss: 18.920477\n",
      "Iteration 6513 => Loss: 18.918529\n",
      "Iteration 6514 => Loss: 18.916583\n",
      "Iteration 6515 => Loss: 18.914638\n",
      "Iteration 6516 => Loss: 18.912696\n",
      "Iteration 6517 => Loss: 18.910756\n",
      "Iteration 6518 => Loss: 18.908817\n",
      "Iteration 6519 => Loss: 18.906881\n",
      "Iteration 6520 => Loss: 18.904947\n",
      "Iteration 6521 => Loss: 18.903014\n",
      "Iteration 6522 => Loss: 18.902997\n",
      "Iteration 6523 => Loss: 18.901041\n",
      "Iteration 6524 => Loss: 18.899088\n",
      "Iteration 6525 => Loss: 18.897136\n",
      "Iteration 6526 => Loss: 18.895186\n",
      "Iteration 6527 => Loss: 18.893239\n",
      "Iteration 6528 => Loss: 18.891293\n",
      "Iteration 6529 => Loss: 18.889349\n",
      "Iteration 6530 => Loss: 18.887408\n",
      "Iteration 6531 => Loss: 18.885468\n",
      "Iteration 6532 => Loss: 18.883530\n",
      "Iteration 6533 => Loss: 18.881595\n",
      "Iteration 6534 => Loss: 18.879661\n",
      "Iteration 6535 => Loss: 18.877729\n",
      "Iteration 6536 => Loss: 18.875800\n",
      "Iteration 6537 => Loss: 18.873872\n",
      "Iteration 6538 => Loss: 18.871946\n",
      "Iteration 6539 => Loss: 18.870023\n",
      "Iteration 6540 => Loss: 18.870013\n",
      "Iteration 6541 => Loss: 18.868066\n",
      "Iteration 6542 => Loss: 18.866121\n",
      "Iteration 6543 => Loss: 18.864178\n",
      "Iteration 6544 => Loss: 18.862237\n",
      "Iteration 6545 => Loss: 18.860298\n",
      "Iteration 6546 => Loss: 18.858361\n",
      "Iteration 6547 => Loss: 18.856426\n",
      "Iteration 6548 => Loss: 18.854493\n",
      "Iteration 6549 => Loss: 18.852562\n",
      "Iteration 6550 => Loss: 18.850633\n",
      "Iteration 6551 => Loss: 18.848706\n",
      "Iteration 6552 => Loss: 18.846781\n",
      "Iteration 6553 => Loss: 18.844858\n",
      "Iteration 6554 => Loss: 18.842937\n",
      "Iteration 6555 => Loss: 18.841018\n",
      "Iteration 6556 => Loss: 18.839101\n",
      "Iteration 6557 => Loss: 18.837186\n",
      "Iteration 6558 => Loss: 18.837182\n",
      "Iteration 6559 => Loss: 18.835244\n",
      "Iteration 6560 => Loss: 18.833308\n",
      "Iteration 6561 => Loss: 18.831373\n",
      "Iteration 6562 => Loss: 18.829441\n",
      "Iteration 6563 => Loss: 18.827511\n",
      "Iteration 6564 => Loss: 18.825582\n",
      "Iteration 6565 => Loss: 18.823656\n",
      "Iteration 6566 => Loss: 18.821732\n",
      "Iteration 6567 => Loss: 18.819809\n",
      "Iteration 6568 => Loss: 18.817889\n",
      "Iteration 6569 => Loss: 18.815971\n",
      "Iteration 6570 => Loss: 18.814054\n",
      "Iteration 6571 => Loss: 18.812140\n",
      "Iteration 6572 => Loss: 18.810228\n",
      "Iteration 6573 => Loss: 18.808317\n",
      "Iteration 6574 => Loss: 18.806409\n",
      "Iteration 6575 => Loss: 18.804503\n",
      "Iteration 6576 => Loss: 18.802598\n",
      "Iteration 6577 => Loss: 18.802576\n",
      "Iteration 6578 => Loss: 18.800649\n",
      "Iteration 6579 => Loss: 18.798723\n",
      "Iteration 6580 => Loss: 18.796799\n",
      "Iteration 6581 => Loss: 18.794878\n",
      "Iteration 6582 => Loss: 18.792958\n",
      "Iteration 6583 => Loss: 18.791040\n",
      "Iteration 6584 => Loss: 18.789125\n",
      "Iteration 6585 => Loss: 18.787211\n",
      "Iteration 6586 => Loss: 18.785299\n",
      "Iteration 6587 => Loss: 18.783390\n",
      "Iteration 6588 => Loss: 18.781482\n",
      "Iteration 6589 => Loss: 18.779576\n",
      "Iteration 6590 => Loss: 18.777673\n",
      "Iteration 6591 => Loss: 18.775771\n",
      "Iteration 6592 => Loss: 18.773871\n",
      "Iteration 6593 => Loss: 18.771974\n",
      "Iteration 6594 => Loss: 18.770078\n",
      "Iteration 6595 => Loss: 18.770063\n",
      "Iteration 6596 => Loss: 18.768144\n",
      "Iteration 6597 => Loss: 18.766227\n",
      "Iteration 6598 => Loss: 18.764312\n",
      "Iteration 6599 => Loss: 18.762399\n",
      "Iteration 6600 => Loss: 18.760488\n",
      "Iteration 6601 => Loss: 18.758579\n",
      "Iteration 6602 => Loss: 18.756672\n",
      "Iteration 6603 => Loss: 18.754767\n",
      "Iteration 6604 => Loss: 18.752864\n",
      "Iteration 6605 => Loss: 18.750963\n",
      "Iteration 6606 => Loss: 18.749064\n",
      "Iteration 6607 => Loss: 18.747167\n",
      "Iteration 6608 => Loss: 18.745272\n",
      "Iteration 6609 => Loss: 18.743379\n",
      "Iteration 6610 => Loss: 18.741488\n",
      "Iteration 6611 => Loss: 18.739599\n",
      "Iteration 6612 => Loss: 18.737712\n",
      "Iteration 6613 => Loss: 18.737704\n",
      "Iteration 6614 => Loss: 18.735794\n",
      "Iteration 6615 => Loss: 18.733886\n",
      "Iteration 6616 => Loss: 18.731979\n",
      "Iteration 6617 => Loss: 18.730075\n",
      "Iteration 6618 => Loss: 18.728173\n",
      "Iteration 6619 => Loss: 18.726272\n",
      "Iteration 6620 => Loss: 18.724374\n",
      "Iteration 6621 => Loss: 18.722478\n",
      "Iteration 6622 => Loss: 18.720583\n",
      "Iteration 6623 => Loss: 18.718691\n",
      "Iteration 6624 => Loss: 18.716801\n",
      "Iteration 6625 => Loss: 18.714912\n",
      "Iteration 6626 => Loss: 18.713026\n",
      "Iteration 6627 => Loss: 18.711142\n",
      "Iteration 6628 => Loss: 18.709259\n",
      "Iteration 6629 => Loss: 18.707379\n",
      "Iteration 6630 => Loss: 18.705501\n",
      "Iteration 6631 => Loss: 18.705500\n",
      "Iteration 6632 => Loss: 18.703598\n",
      "Iteration 6633 => Loss: 18.701699\n",
      "Iteration 6634 => Loss: 18.699801\n",
      "Iteration 6635 => Loss: 18.697905\n",
      "Iteration 6636 => Loss: 18.696012\n",
      "Iteration 6637 => Loss: 18.694120\n",
      "Iteration 6638 => Loss: 18.692230\n",
      "Iteration 6639 => Loss: 18.690343\n",
      "Iteration 6640 => Loss: 18.688457\n",
      "Iteration 6641 => Loss: 18.686573\n",
      "Iteration 6642 => Loss: 18.684692\n",
      "Iteration 6643 => Loss: 18.682812\n",
      "Iteration 6644 => Loss: 18.680934\n",
      "Iteration 6645 => Loss: 18.679059\n",
      "Iteration 6646 => Loss: 18.677185\n",
      "Iteration 6647 => Loss: 18.675313\n",
      "Iteration 6648 => Loss: 18.673444\n",
      "Iteration 6649 => Loss: 18.671576\n",
      "Iteration 6650 => Loss: 18.671557\n",
      "Iteration 6651 => Loss: 18.669666\n",
      "Iteration 6652 => Loss: 18.667777\n",
      "Iteration 6653 => Loss: 18.665890\n",
      "Iteration 6654 => Loss: 18.664005\n",
      "Iteration 6655 => Loss: 18.662122\n",
      "Iteration 6656 => Loss: 18.660241\n",
      "Iteration 6657 => Loss: 18.658362\n",
      "Iteration 6658 => Loss: 18.656485\n",
      "Iteration 6659 => Loss: 18.654610\n",
      "Iteration 6660 => Loss: 18.652737\n",
      "Iteration 6661 => Loss: 18.650866\n",
      "Iteration 6662 => Loss: 18.648997\n",
      "Iteration 6663 => Loss: 18.647130\n",
      "Iteration 6664 => Loss: 18.645265\n",
      "Iteration 6665 => Loss: 18.643402\n",
      "Iteration 6666 => Loss: 18.641541\n",
      "Iteration 6667 => Loss: 18.639682\n",
      "Iteration 6668 => Loss: 18.639669\n",
      "Iteration 6669 => Loss: 18.637787\n",
      "Iteration 6670 => Loss: 18.635906\n",
      "Iteration 6671 => Loss: 18.634028\n",
      "Iteration 6672 => Loss: 18.632152\n",
      "Iteration 6673 => Loss: 18.630277\n",
      "Iteration 6674 => Loss: 18.628405\n",
      "Iteration 6675 => Loss: 18.626535\n",
      "Iteration 6676 => Loss: 18.624666\n",
      "Iteration 6677 => Loss: 18.622800\n",
      "Iteration 6678 => Loss: 18.620936\n",
      "Iteration 6679 => Loss: 18.619073\n",
      "Iteration 6680 => Loss: 18.617213\n",
      "Iteration 6681 => Loss: 18.615355\n",
      "Iteration 6682 => Loss: 18.613498\n",
      "Iteration 6683 => Loss: 18.611644\n",
      "Iteration 6684 => Loss: 18.609792\n",
      "Iteration 6685 => Loss: 18.607941\n",
      "Iteration 6686 => Loss: 18.607936\n",
      "Iteration 6687 => Loss: 18.606062\n",
      "Iteration 6688 => Loss: 18.604191\n",
      "Iteration 6689 => Loss: 18.602321\n",
      "Iteration 6690 => Loss: 18.600453\n",
      "Iteration 6691 => Loss: 18.598588\n",
      "Iteration 6692 => Loss: 18.596724\n",
      "Iteration 6693 => Loss: 18.594862\n",
      "Iteration 6694 => Loss: 18.593003\n",
      "Iteration 6695 => Loss: 18.591145\n",
      "Iteration 6696 => Loss: 18.589289\n",
      "Iteration 6697 => Loss: 18.587436\n",
      "Iteration 6698 => Loss: 18.585584\n",
      "Iteration 6699 => Loss: 18.583734\n",
      "Iteration 6700 => Loss: 18.581887\n",
      "Iteration 6701 => Loss: 18.580041\n",
      "Iteration 6702 => Loss: 18.578197\n",
      "Iteration 6703 => Loss: 18.576356\n",
      "Iteration 6704 => Loss: 18.574516\n",
      "Iteration 6705 => Loss: 18.574492\n",
      "Iteration 6706 => Loss: 18.572629\n",
      "Iteration 6707 => Loss: 18.570768\n",
      "Iteration 6708 => Loss: 18.568909\n",
      "Iteration 6709 => Loss: 18.567052\n",
      "Iteration 6710 => Loss: 18.565197\n",
      "Iteration 6711 => Loss: 18.563344\n",
      "Iteration 6712 => Loss: 18.561493\n",
      "Iteration 6713 => Loss: 18.559644\n",
      "Iteration 6714 => Loss: 18.557797\n",
      "Iteration 6715 => Loss: 18.555952\n",
      "Iteration 6716 => Loss: 18.554109\n",
      "Iteration 6717 => Loss: 18.552268\n",
      "Iteration 6718 => Loss: 18.550429\n",
      "Iteration 6719 => Loss: 18.548592\n",
      "Iteration 6720 => Loss: 18.546757\n",
      "Iteration 6721 => Loss: 18.544924\n",
      "Iteration 6722 => Loss: 18.543093\n",
      "Iteration 6723 => Loss: 18.543076\n",
      "Iteration 6724 => Loss: 18.541222\n",
      "Iteration 6725 => Loss: 18.539370\n",
      "Iteration 6726 => Loss: 18.537519\n",
      "Iteration 6727 => Loss: 18.535671\n",
      "Iteration 6728 => Loss: 18.533825\n",
      "Iteration 6729 => Loss: 18.531980\n",
      "Iteration 6730 => Loss: 18.530138\n",
      "Iteration 6731 => Loss: 18.528298\n",
      "Iteration 6732 => Loss: 18.526459\n",
      "Iteration 6733 => Loss: 18.524623\n",
      "Iteration 6734 => Loss: 18.522789\n",
      "Iteration 6735 => Loss: 18.520956\n",
      "Iteration 6736 => Loss: 18.519126\n",
      "Iteration 6737 => Loss: 18.517298\n",
      "Iteration 6738 => Loss: 18.515471\n",
      "Iteration 6739 => Loss: 18.513647\n",
      "Iteration 6740 => Loss: 18.511825\n",
      "Iteration 6741 => Loss: 18.511815\n",
      "Iteration 6742 => Loss: 18.509969\n",
      "Iteration 6743 => Loss: 18.508125\n",
      "Iteration 6744 => Loss: 18.506284\n",
      "Iteration 6745 => Loss: 18.504444\n",
      "Iteration 6746 => Loss: 18.502606\n",
      "Iteration 6747 => Loss: 18.500771\n",
      "Iteration 6748 => Loss: 18.498937\n",
      "Iteration 6749 => Loss: 18.497105\n",
      "Iteration 6750 => Loss: 18.495276\n",
      "Iteration 6751 => Loss: 18.493448\n",
      "Iteration 6752 => Loss: 18.491622\n",
      "Iteration 6753 => Loss: 18.489799\n",
      "Iteration 6754 => Loss: 18.487977\n",
      "Iteration 6755 => Loss: 18.486157\n",
      "Iteration 6756 => Loss: 18.484340\n",
      "Iteration 6757 => Loss: 18.482524\n",
      "Iteration 6758 => Loss: 18.480710\n",
      "Iteration 6759 => Loss: 18.480707\n",
      "Iteration 6760 => Loss: 18.478870\n",
      "Iteration 6761 => Loss: 18.477035\n",
      "Iteration 6762 => Loss: 18.475202\n",
      "Iteration 6763 => Loss: 18.473371\n",
      "Iteration 6764 => Loss: 18.471542\n",
      "Iteration 6765 => Loss: 18.469715\n",
      "Iteration 6766 => Loss: 18.467890\n",
      "Iteration 6767 => Loss: 18.466067\n",
      "Iteration 6768 => Loss: 18.464246\n",
      "Iteration 6769 => Loss: 18.462427\n",
      "Iteration 6770 => Loss: 18.460610\n",
      "Iteration 6771 => Loss: 18.458795\n",
      "Iteration 6772 => Loss: 18.456982\n",
      "Iteration 6773 => Loss: 18.455171\n",
      "Iteration 6774 => Loss: 18.453362\n",
      "Iteration 6775 => Loss: 18.451555\n",
      "Iteration 6776 => Loss: 18.449750\n",
      "Iteration 6777 => Loss: 18.447947\n",
      "Iteration 6778 => Loss: 18.447926\n",
      "Iteration 6779 => Loss: 18.446099\n",
      "Iteration 6780 => Loss: 18.444275\n",
      "Iteration 6781 => Loss: 18.442453\n",
      "Iteration 6782 => Loss: 18.440632\n",
      "Iteration 6783 => Loss: 18.438814\n",
      "Iteration 6784 => Loss: 18.436998\n",
      "Iteration 6785 => Loss: 18.435183\n",
      "Iteration 6786 => Loss: 18.433371\n",
      "Iteration 6787 => Loss: 18.431561\n",
      "Iteration 6788 => Loss: 18.429752\n",
      "Iteration 6789 => Loss: 18.427946\n",
      "Iteration 6790 => Loss: 18.426142\n",
      "Iteration 6791 => Loss: 18.424339\n",
      "Iteration 6792 => Loss: 18.422539\n",
      "Iteration 6793 => Loss: 18.420741\n",
      "Iteration 6794 => Loss: 18.418944\n",
      "Iteration 6795 => Loss: 18.417150\n",
      "Iteration 6796 => Loss: 18.417135\n",
      "Iteration 6797 => Loss: 18.415318\n",
      "Iteration 6798 => Loss: 18.413502\n",
      "Iteration 6799 => Loss: 18.411688\n",
      "Iteration 6800 => Loss: 18.409877\n",
      "Iteration 6801 => Loss: 18.408067\n",
      "Iteration 6802 => Loss: 18.406259\n",
      "Iteration 6803 => Loss: 18.404454\n",
      "Iteration 6804 => Loss: 18.402650\n",
      "Iteration 6805 => Loss: 18.400848\n",
      "Iteration 6806 => Loss: 18.399049\n",
      "Iteration 6807 => Loss: 18.397251\n",
      "Iteration 6808 => Loss: 18.395455\n",
      "Iteration 6809 => Loss: 18.393662\n",
      "Iteration 6810 => Loss: 18.391870\n",
      "Iteration 6811 => Loss: 18.390080\n",
      "Iteration 6812 => Loss: 18.388293\n",
      "Iteration 6813 => Loss: 18.386507\n",
      "Iteration 6814 => Loss: 18.386500\n",
      "Iteration 6815 => Loss: 18.384691\n",
      "Iteration 6816 => Loss: 18.382884\n",
      "Iteration 6817 => Loss: 18.381079\n",
      "Iteration 6818 => Loss: 18.379276\n",
      "Iteration 6819 => Loss: 18.377475\n",
      "Iteration 6820 => Loss: 18.375676\n",
      "Iteration 6821 => Loss: 18.373879\n",
      "Iteration 6822 => Loss: 18.372084\n",
      "Iteration 6823 => Loss: 18.370291\n",
      "Iteration 6824 => Loss: 18.368500\n",
      "Iteration 6825 => Loss: 18.366711\n",
      "Iteration 6826 => Loss: 18.364924\n",
      "Iteration 6827 => Loss: 18.363139\n",
      "Iteration 6828 => Loss: 18.361356\n",
      "Iteration 6829 => Loss: 18.359575\n",
      "Iteration 6830 => Loss: 18.357796\n",
      "Iteration 6831 => Loss: 18.356019\n",
      "Iteration 6832 => Loss: 18.356018\n",
      "Iteration 6833 => Loss: 18.354218\n",
      "Iteration 6834 => Loss: 18.352419\n",
      "Iteration 6835 => Loss: 18.350623\n",
      "Iteration 6836 => Loss: 18.348829\n",
      "Iteration 6837 => Loss: 18.347036\n",
      "Iteration 6838 => Loss: 18.345246\n",
      "Iteration 6839 => Loss: 18.343458\n",
      "Iteration 6840 => Loss: 18.341671\n",
      "Iteration 6841 => Loss: 18.339887\n",
      "Iteration 6842 => Loss: 18.338105\n",
      "Iteration 6843 => Loss: 18.336324\n",
      "Iteration 6844 => Loss: 18.334546\n",
      "Iteration 6845 => Loss: 18.332770\n",
      "Iteration 6846 => Loss: 18.330995\n",
      "Iteration 6847 => Loss: 18.329223\n",
      "Iteration 6848 => Loss: 18.327453\n",
      "Iteration 6849 => Loss: 18.325684\n",
      "Iteration 6850 => Loss: 18.323918\n",
      "Iteration 6851 => Loss: 18.323899\n",
      "Iteration 6852 => Loss: 18.322109\n",
      "Iteration 6853 => Loss: 18.320321\n",
      "Iteration 6854 => Loss: 18.318536\n",
      "Iteration 6855 => Loss: 18.316752\n",
      "Iteration 6856 => Loss: 18.314970\n",
      "Iteration 6857 => Loss: 18.313191\n",
      "Iteration 6858 => Loss: 18.311413\n",
      "Iteration 6859 => Loss: 18.309637\n",
      "Iteration 6860 => Loss: 18.307864\n",
      "Iteration 6861 => Loss: 18.306092\n",
      "Iteration 6862 => Loss: 18.304322\n",
      "Iteration 6863 => Loss: 18.302555\n",
      "Iteration 6864 => Loss: 18.300789\n",
      "Iteration 6865 => Loss: 18.299025\n",
      "Iteration 6866 => Loss: 18.297264\n",
      "Iteration 6867 => Loss: 18.295504\n",
      "Iteration 6868 => Loss: 18.293746\n",
      "Iteration 6869 => Loss: 18.293734\n",
      "Iteration 6870 => Loss: 18.291953\n",
      "Iteration 6871 => Loss: 18.290174\n",
      "Iteration 6872 => Loss: 18.288397\n",
      "Iteration 6873 => Loss: 18.286622\n",
      "Iteration 6874 => Loss: 18.284849\n",
      "Iteration 6875 => Loss: 18.283078\n",
      "Iteration 6876 => Loss: 18.281309\n",
      "Iteration 6877 => Loss: 18.279542\n",
      "Iteration 6878 => Loss: 18.277777\n",
      "Iteration 6879 => Loss: 18.276014\n",
      "Iteration 6880 => Loss: 18.274253\n",
      "Iteration 6881 => Loss: 18.272494\n",
      "Iteration 6882 => Loss: 18.270737\n",
      "Iteration 6883 => Loss: 18.268982\n",
      "Iteration 6884 => Loss: 18.267229\n",
      "Iteration 6885 => Loss: 18.265478\n",
      "Iteration 6886 => Loss: 18.263729\n",
      "Iteration 6887 => Loss: 18.263724\n",
      "Iteration 6888 => Loss: 18.261952\n",
      "Iteration 6889 => Loss: 18.260181\n",
      "Iteration 6890 => Loss: 18.258413\n",
      "Iteration 6891 => Loss: 18.256647\n",
      "Iteration 6892 => Loss: 18.254882\n",
      "Iteration 6893 => Loss: 18.253120\n",
      "Iteration 6894 => Loss: 18.251360\n",
      "Iteration 6895 => Loss: 18.249601\n",
      "Iteration 6896 => Loss: 18.247845\n",
      "Iteration 6897 => Loss: 18.246091\n",
      "Iteration 6898 => Loss: 18.244338\n",
      "Iteration 6899 => Loss: 18.242588\n",
      "Iteration 6900 => Loss: 18.240840\n",
      "Iteration 6901 => Loss: 18.239093\n",
      "Iteration 6902 => Loss: 18.237349\n",
      "Iteration 6903 => Loss: 18.235607\n",
      "Iteration 6904 => Loss: 18.233866\n",
      "Iteration 6905 => Loss: 18.232128\n",
      "Iteration 6906 => Loss: 18.232105\n",
      "Iteration 6907 => Loss: 18.230343\n",
      "Iteration 6908 => Loss: 18.228583\n",
      "Iteration 6909 => Loss: 18.226826\n",
      "Iteration 6910 => Loss: 18.225070\n",
      "Iteration 6911 => Loss: 18.223316\n",
      "Iteration 6912 => Loss: 18.221565\n",
      "Iteration 6913 => Loss: 18.219815\n",
      "Iteration 6914 => Loss: 18.218067\n",
      "Iteration 6915 => Loss: 18.216322\n",
      "Iteration 6916 => Loss: 18.214578\n",
      "Iteration 6917 => Loss: 18.212836\n",
      "Iteration 6918 => Loss: 18.211097\n",
      "Iteration 6919 => Loss: 18.209359\n",
      "Iteration 6920 => Loss: 18.207623\n",
      "Iteration 6921 => Loss: 18.205890\n",
      "Iteration 6922 => Loss: 18.204158\n",
      "Iteration 6923 => Loss: 18.202428\n",
      "Iteration 6924 => Loss: 18.202412\n",
      "Iteration 6925 => Loss: 18.200659\n",
      "Iteration 6926 => Loss: 18.198908\n",
      "Iteration 6927 => Loss: 18.197159\n",
      "Iteration 6928 => Loss: 18.195412\n",
      "Iteration 6929 => Loss: 18.193667\n",
      "Iteration 6930 => Loss: 18.191924\n",
      "Iteration 6931 => Loss: 18.190183\n",
      "Iteration 6932 => Loss: 18.188444\n",
      "Iteration 6933 => Loss: 18.186707\n",
      "Iteration 6934 => Loss: 18.184972\n",
      "Iteration 6935 => Loss: 18.183239\n",
      "Iteration 6936 => Loss: 18.181508\n",
      "Iteration 6937 => Loss: 18.179779\n",
      "Iteration 6938 => Loss: 18.178052\n",
      "Iteration 6939 => Loss: 18.176327\n",
      "Iteration 6940 => Loss: 18.174604\n",
      "Iteration 6941 => Loss: 18.172883\n",
      "Iteration 6942 => Loss: 18.172873\n",
      "Iteration 6943 => Loss: 18.171128\n",
      "Iteration 6944 => Loss: 18.169386\n",
      "Iteration 6945 => Loss: 18.167646\n",
      "Iteration 6946 => Loss: 18.165907\n",
      "Iteration 6947 => Loss: 18.164171\n",
      "Iteration 6948 => Loss: 18.162437\n",
      "Iteration 6949 => Loss: 18.160704\n",
      "Iteration 6950 => Loss: 18.158974\n",
      "Iteration 6951 => Loss: 18.157246\n",
      "Iteration 6952 => Loss: 18.155519\n",
      "Iteration 6953 => Loss: 18.153795\n",
      "Iteration 6954 => Loss: 18.152073\n",
      "Iteration 6955 => Loss: 18.150352\n",
      "Iteration 6956 => Loss: 18.148634\n",
      "Iteration 6957 => Loss: 18.146918\n",
      "Iteration 6958 => Loss: 18.145203\n",
      "Iteration 6959 => Loss: 18.143491\n",
      "Iteration 6960 => Loss: 18.143488\n",
      "Iteration 6961 => Loss: 18.141753\n",
      "Iteration 6962 => Loss: 18.140019\n",
      "Iteration 6963 => Loss: 18.138287\n",
      "Iteration 6964 => Loss: 18.136558\n",
      "Iteration 6965 => Loss: 18.134830\n",
      "Iteration 6966 => Loss: 18.133104\n",
      "Iteration 6967 => Loss: 18.131381\n",
      "Iteration 6968 => Loss: 18.129659\n",
      "Iteration 6969 => Loss: 18.127939\n",
      "Iteration 6970 => Loss: 18.126222\n",
      "Iteration 6971 => Loss: 18.124506\n",
      "Iteration 6972 => Loss: 18.122792\n",
      "Iteration 6973 => Loss: 18.121081\n",
      "Iteration 6974 => Loss: 18.119371\n",
      "Iteration 6975 => Loss: 18.117663\n",
      "Iteration 6976 => Loss: 18.115958\n",
      "Iteration 6977 => Loss: 18.114254\n",
      "Iteration 6978 => Loss: 18.112552\n",
      "Iteration 6979 => Loss: 18.112531\n",
      "Iteration 6980 => Loss: 18.110806\n",
      "Iteration 6981 => Loss: 18.109083\n",
      "Iteration 6982 => Loss: 18.107362\n",
      "Iteration 6983 => Loss: 18.105643\n",
      "Iteration 6984 => Loss: 18.103926\n",
      "Iteration 6985 => Loss: 18.102211\n",
      "Iteration 6986 => Loss: 18.100498\n",
      "Iteration 6987 => Loss: 18.098787\n",
      "Iteration 6988 => Loss: 18.097078\n",
      "Iteration 6989 => Loss: 18.095371\n",
      "Iteration 6990 => Loss: 18.093666\n",
      "Iteration 6991 => Loss: 18.091963\n",
      "Iteration 6992 => Loss: 18.090262\n",
      "Iteration 6993 => Loss: 18.088563\n",
      "Iteration 6994 => Loss: 18.086866\n",
      "Iteration 6995 => Loss: 18.085171\n",
      "Iteration 6996 => Loss: 18.083478\n",
      "Iteration 6997 => Loss: 18.083464\n",
      "Iteration 6998 => Loss: 18.081748\n",
      "Iteration 6999 => Loss: 18.080033\n",
      "Iteration 7000 => Loss: 18.078321\n",
      "Iteration 7001 => Loss: 18.076611\n",
      "Iteration 7002 => Loss: 18.074902\n",
      "Iteration 7003 => Loss: 18.073196\n",
      "Iteration 7004 => Loss: 18.071492\n",
      "Iteration 7005 => Loss: 18.069789\n",
      "Iteration 7006 => Loss: 18.068089\n",
      "Iteration 7007 => Loss: 18.066391\n",
      "Iteration 7008 => Loss: 18.064694\n",
      "Iteration 7009 => Loss: 18.063000\n",
      "Iteration 7010 => Loss: 18.061308\n",
      "Iteration 7011 => Loss: 18.059617\n",
      "Iteration 7012 => Loss: 18.057929\n",
      "Iteration 7013 => Loss: 18.056243\n",
      "Iteration 7014 => Loss: 18.054558\n",
      "Iteration 7015 => Loss: 18.054551\n",
      "Iteration 7016 => Loss: 18.052843\n",
      "Iteration 7017 => Loss: 18.051138\n",
      "Iteration 7018 => Loss: 18.049434\n",
      "Iteration 7019 => Loss: 18.047732\n",
      "Iteration 7020 => Loss: 18.046033\n",
      "Iteration 7021 => Loss: 18.044335\n",
      "Iteration 7022 => Loss: 18.042639\n",
      "Iteration 7023 => Loss: 18.040946\n",
      "Iteration 7024 => Loss: 18.039254\n",
      "Iteration 7025 => Loss: 18.037564\n",
      "Iteration 7026 => Loss: 18.035877\n",
      "Iteration 7027 => Loss: 18.034191\n",
      "Iteration 7028 => Loss: 18.032507\n",
      "Iteration 7029 => Loss: 18.030826\n",
      "Iteration 7030 => Loss: 18.029146\n",
      "Iteration 7031 => Loss: 18.027468\n",
      "Iteration 7032 => Loss: 18.025793\n",
      "Iteration 7033 => Loss: 18.025792\n",
      "Iteration 7034 => Loss: 18.024093\n",
      "Iteration 7035 => Loss: 18.022396\n",
      "Iteration 7036 => Loss: 18.020701\n",
      "Iteration 7037 => Loss: 18.019008\n",
      "Iteration 7038 => Loss: 18.017317\n",
      "Iteration 7039 => Loss: 18.015628\n",
      "Iteration 7040 => Loss: 18.013941\n",
      "Iteration 7041 => Loss: 18.012256\n",
      "Iteration 7042 => Loss: 18.010573\n",
      "Iteration 7043 => Loss: 18.008892\n",
      "Iteration 7044 => Loss: 18.007213\n",
      "Iteration 7045 => Loss: 18.005536\n",
      "Iteration 7046 => Loss: 18.003861\n",
      "Iteration 7047 => Loss: 18.002188\n",
      "Iteration 7048 => Loss: 18.000517\n",
      "Iteration 7049 => Loss: 17.998848\n",
      "Iteration 7050 => Loss: 17.997181\n",
      "Iteration 7051 => Loss: 17.995516\n",
      "Iteration 7052 => Loss: 17.995497\n",
      "Iteration 7053 => Loss: 17.993809\n",
      "Iteration 7054 => Loss: 17.992123\n",
      "Iteration 7055 => Loss: 17.990438\n",
      "Iteration 7056 => Loss: 17.988756\n",
      "Iteration 7057 => Loss: 17.987076\n",
      "Iteration 7058 => Loss: 17.985397\n",
      "Iteration 7059 => Loss: 17.983721\n",
      "Iteration 7060 => Loss: 17.982047\n",
      "Iteration 7061 => Loss: 17.980374\n",
      "Iteration 7062 => Loss: 17.978704\n",
      "Iteration 7063 => Loss: 17.977036\n",
      "Iteration 7064 => Loss: 17.975369\n",
      "Iteration 7065 => Loss: 17.973705\n",
      "Iteration 7066 => Loss: 17.972043\n",
      "Iteration 7067 => Loss: 17.970382\n",
      "Iteration 7068 => Loss: 17.968724\n",
      "Iteration 7069 => Loss: 17.967068\n",
      "Iteration 7070 => Loss: 17.967056\n",
      "Iteration 7071 => Loss: 17.965376\n",
      "Iteration 7072 => Loss: 17.963698\n",
      "Iteration 7073 => Loss: 17.962023\n",
      "Iteration 7074 => Loss: 17.960349\n",
      "Iteration 7075 => Loss: 17.958677\n",
      "Iteration 7076 => Loss: 17.957008\n",
      "Iteration 7077 => Loss: 17.955340\n",
      "Iteration 7078 => Loss: 17.953674\n",
      "Iteration 7079 => Loss: 17.952011\n",
      "Iteration 7080 => Loss: 17.950349\n",
      "Iteration 7081 => Loss: 17.948689\n",
      "Iteration 7082 => Loss: 17.947032\n",
      "Iteration 7083 => Loss: 17.945376\n",
      "Iteration 7084 => Loss: 17.943722\n",
      "Iteration 7085 => Loss: 17.942071\n",
      "Iteration 7086 => Loss: 17.940421\n",
      "Iteration 7087 => Loss: 17.938773\n",
      "Iteration 7088 => Loss: 17.938769\n",
      "Iteration 7089 => Loss: 17.937098\n",
      "Iteration 7090 => Loss: 17.935429\n",
      "Iteration 7091 => Loss: 17.933762\n",
      "Iteration 7092 => Loss: 17.932097\n",
      "Iteration 7093 => Loss: 17.930434\n",
      "Iteration 7094 => Loss: 17.928773\n",
      "Iteration 7095 => Loss: 17.927114\n",
      "Iteration 7096 => Loss: 17.925457\n",
      "Iteration 7097 => Loss: 17.923802\n",
      "Iteration 7098 => Loss: 17.922149\n",
      "Iteration 7099 => Loss: 17.920498\n",
      "Iteration 7100 => Loss: 17.918849\n",
      "Iteration 7101 => Loss: 17.917202\n",
      "Iteration 7102 => Loss: 17.915557\n",
      "Iteration 7103 => Loss: 17.913914\n",
      "Iteration 7104 => Loss: 17.912273\n",
      "Iteration 7105 => Loss: 17.910634\n",
      "Iteration 7106 => Loss: 17.908997\n",
      "Iteration 7107 => Loss: 17.908973\n",
      "Iteration 7108 => Loss: 17.907313\n",
      "Iteration 7109 => Loss: 17.905655\n",
      "Iteration 7110 => Loss: 17.903998\n",
      "Iteration 7111 => Loss: 17.902344\n",
      "Iteration 7112 => Loss: 17.900692\n",
      "Iteration 7113 => Loss: 17.899041\n",
      "Iteration 7114 => Loss: 17.897393\n",
      "Iteration 7115 => Loss: 17.895747\n",
      "Iteration 7116 => Loss: 17.894102\n",
      "Iteration 7117 => Loss: 17.892460\n",
      "Iteration 7118 => Loss: 17.890820\n",
      "Iteration 7119 => Loss: 17.889181\n",
      "Iteration 7120 => Loss: 17.887545\n",
      "Iteration 7121 => Loss: 17.885911\n",
      "Iteration 7122 => Loss: 17.884278\n",
      "Iteration 7123 => Loss: 17.882648\n",
      "Iteration 7124 => Loss: 17.881020\n",
      "Iteration 7125 => Loss: 17.881003\n",
      "Iteration 7126 => Loss: 17.879351\n",
      "Iteration 7127 => Loss: 17.877702\n",
      "Iteration 7128 => Loss: 17.876054\n",
      "Iteration 7129 => Loss: 17.874408\n",
      "Iteration 7130 => Loss: 17.872765\n",
      "Iteration 7131 => Loss: 17.871123\n",
      "Iteration 7132 => Loss: 17.869483\n",
      "Iteration 7133 => Loss: 17.867846\n",
      "Iteration 7134 => Loss: 17.866210\n",
      "Iteration 7135 => Loss: 17.864576\n",
      "Iteration 7136 => Loss: 17.862945\n",
      "Iteration 7137 => Loss: 17.861315\n",
      "Iteration 7138 => Loss: 17.859687\n",
      "Iteration 7139 => Loss: 17.858062\n",
      "Iteration 7140 => Loss: 17.856438\n",
      "Iteration 7141 => Loss: 17.854816\n",
      "Iteration 7142 => Loss: 17.853197\n",
      "Iteration 7143 => Loss: 17.853187\n",
      "Iteration 7144 => Loss: 17.851544\n",
      "Iteration 7145 => Loss: 17.849903\n",
      "Iteration 7146 => Loss: 17.848264\n",
      "Iteration 7147 => Loss: 17.846627\n",
      "Iteration 7148 => Loss: 17.844992\n",
      "Iteration 7149 => Loss: 17.843359\n",
      "Iteration 7150 => Loss: 17.841728\n",
      "Iteration 7151 => Loss: 17.840099\n",
      "Iteration 7152 => Loss: 17.838472\n",
      "Iteration 7153 => Loss: 17.836847\n",
      "Iteration 7154 => Loss: 17.835224\n",
      "Iteration 7155 => Loss: 17.833603\n",
      "Iteration 7156 => Loss: 17.831984\n",
      "Iteration 7157 => Loss: 17.830367\n",
      "Iteration 7158 => Loss: 17.828752\n",
      "Iteration 7159 => Loss: 17.827139\n",
      "Iteration 7160 => Loss: 17.825528\n",
      "Iteration 7161 => Loss: 17.825526\n",
      "Iteration 7162 => Loss: 17.823891\n",
      "Iteration 7163 => Loss: 17.822259\n",
      "Iteration 7164 => Loss: 17.820629\n",
      "Iteration 7165 => Loss: 17.819000\n",
      "Iteration 7166 => Loss: 17.817374\n",
      "Iteration 7167 => Loss: 17.815750\n",
      "Iteration 7168 => Loss: 17.814127\n",
      "Iteration 7169 => Loss: 17.812507\n",
      "Iteration 7170 => Loss: 17.810889\n",
      "Iteration 7171 => Loss: 17.809272\n",
      "Iteration 7172 => Loss: 17.807658\n",
      "Iteration 7173 => Loss: 17.806046\n",
      "Iteration 7174 => Loss: 17.804435\n",
      "Iteration 7175 => Loss: 17.802827\n",
      "Iteration 7176 => Loss: 17.801221\n",
      "Iteration 7177 => Loss: 17.799616\n",
      "Iteration 7178 => Loss: 17.798014\n",
      "Iteration 7179 => Loss: 17.796414\n",
      "Iteration 7180 => Loss: 17.796393\n",
      "Iteration 7181 => Loss: 17.794769\n",
      "Iteration 7182 => Loss: 17.793148\n",
      "Iteration 7183 => Loss: 17.791528\n",
      "Iteration 7184 => Loss: 17.789910\n",
      "Iteration 7185 => Loss: 17.788295\n",
      "Iteration 7186 => Loss: 17.786681\n",
      "Iteration 7187 => Loss: 17.785069\n",
      "Iteration 7188 => Loss: 17.783460\n",
      "Iteration 7189 => Loss: 17.781852\n",
      "Iteration 7190 => Loss: 17.780246\n",
      "Iteration 7191 => Loss: 17.778643\n",
      "Iteration 7192 => Loss: 17.777041\n",
      "Iteration 7193 => Loss: 17.775441\n",
      "Iteration 7194 => Loss: 17.773844\n",
      "Iteration 7195 => Loss: 17.772248\n",
      "Iteration 7196 => Loss: 17.770654\n",
      "Iteration 7197 => Loss: 17.769063\n",
      "Iteration 7198 => Loss: 17.769049\n",
      "Iteration 7199 => Loss: 17.767434\n",
      "Iteration 7200 => Loss: 17.765821\n",
      "Iteration 7201 => Loss: 17.764210\n",
      "Iteration 7202 => Loss: 17.762601\n",
      "Iteration 7203 => Loss: 17.760994\n",
      "Iteration 7204 => Loss: 17.759389\n",
      "Iteration 7205 => Loss: 17.757786\n",
      "Iteration 7206 => Loss: 17.756185\n",
      "Iteration 7207 => Loss: 17.754586\n",
      "Iteration 7208 => Loss: 17.752989\n",
      "Iteration 7209 => Loss: 17.751394\n",
      "Iteration 7210 => Loss: 17.749801\n",
      "Iteration 7211 => Loss: 17.748210\n",
      "Iteration 7212 => Loss: 17.746621\n",
      "Iteration 7213 => Loss: 17.745034\n",
      "Iteration 7214 => Loss: 17.743449\n",
      "Iteration 7215 => Loss: 17.741866\n",
      "Iteration 7216 => Loss: 17.741858\n",
      "Iteration 7217 => Loss: 17.740252\n",
      "Iteration 7218 => Loss: 17.738648\n",
      "Iteration 7219 => Loss: 17.737045\n",
      "Iteration 7220 => Loss: 17.735445\n",
      "Iteration 7221 => Loss: 17.733847\n",
      "Iteration 7222 => Loss: 17.732250\n",
      "Iteration 7223 => Loss: 17.730656\n",
      "Iteration 7224 => Loss: 17.729064\n",
      "Iteration 7225 => Loss: 17.727473\n",
      "Iteration 7226 => Loss: 17.725885\n",
      "Iteration 7227 => Loss: 17.724299\n",
      "Iteration 7228 => Loss: 17.722714\n",
      "Iteration 7229 => Loss: 17.721132\n",
      "Iteration 7230 => Loss: 17.719552\n",
      "Iteration 7231 => Loss: 17.717973\n",
      "Iteration 7232 => Loss: 17.716397\n",
      "Iteration 7233 => Loss: 17.714823\n",
      "Iteration 7234 => Loss: 17.714823\n",
      "Iteration 7235 => Loss: 17.713225\n",
      "Iteration 7236 => Loss: 17.711629\n",
      "Iteration 7237 => Loss: 17.710036\n",
      "Iteration 7238 => Loss: 17.708444\n",
      "Iteration 7239 => Loss: 17.706854\n",
      "Iteration 7240 => Loss: 17.705267\n",
      "Iteration 7241 => Loss: 17.703681\n",
      "Iteration 7242 => Loss: 17.702097\n",
      "Iteration 7243 => Loss: 17.700516\n",
      "Iteration 7244 => Loss: 17.698936\n",
      "Iteration 7245 => Loss: 17.697358\n",
      "Iteration 7246 => Loss: 17.695783\n",
      "Iteration 7247 => Loss: 17.694209\n",
      "Iteration 7248 => Loss: 17.692637\n",
      "Iteration 7249 => Loss: 17.691068\n",
      "Iteration 7250 => Loss: 17.689500\n",
      "Iteration 7251 => Loss: 17.687934\n",
      "Iteration 7252 => Loss: 17.686371\n",
      "Iteration 7253 => Loss: 17.686352\n",
      "Iteration 7254 => Loss: 17.684765\n",
      "Iteration 7255 => Loss: 17.683180\n",
      "Iteration 7256 => Loss: 17.681597\n",
      "Iteration 7257 => Loss: 17.680016\n",
      "Iteration 7258 => Loss: 17.678437\n",
      "Iteration 7259 => Loss: 17.676860\n",
      "Iteration 7260 => Loss: 17.675285\n",
      "Iteration 7261 => Loss: 17.673712\n",
      "Iteration 7262 => Loss: 17.672141\n",
      "Iteration 7263 => Loss: 17.670572\n",
      "Iteration 7264 => Loss: 17.669005\n",
      "Iteration 7265 => Loss: 17.667440\n",
      "Iteration 7266 => Loss: 17.665877\n",
      "Iteration 7267 => Loss: 17.664316\n",
      "Iteration 7268 => Loss: 17.662757\n",
      "Iteration 7269 => Loss: 17.661200\n",
      "Iteration 7270 => Loss: 17.659645\n",
      "Iteration 7271 => Loss: 17.659634\n",
      "Iteration 7272 => Loss: 17.658055\n",
      "Iteration 7273 => Loss: 17.656479\n",
      "Iteration 7274 => Loss: 17.654905\n",
      "Iteration 7275 => Loss: 17.653332\n",
      "Iteration 7276 => Loss: 17.651762\n",
      "Iteration 7277 => Loss: 17.650194\n",
      "Iteration 7278 => Loss: 17.648627\n",
      "Iteration 7279 => Loss: 17.647063\n",
      "Iteration 7280 => Loss: 17.645501\n",
      "Iteration 7281 => Loss: 17.643940\n",
      "Iteration 7282 => Loss: 17.642382\n",
      "Iteration 7283 => Loss: 17.640826\n",
      "Iteration 7284 => Loss: 17.639271\n",
      "Iteration 7285 => Loss: 17.637719\n",
      "Iteration 7286 => Loss: 17.636169\n",
      "Iteration 7287 => Loss: 17.634620\n",
      "Iteration 7288 => Loss: 17.633074\n",
      "Iteration 7289 => Loss: 17.633069\n",
      "Iteration 7290 => Loss: 17.631500\n",
      "Iteration 7291 => Loss: 17.629932\n",
      "Iteration 7292 => Loss: 17.628366\n",
      "Iteration 7293 => Loss: 17.626803\n",
      "Iteration 7294 => Loss: 17.625241\n",
      "Iteration 7295 => Loss: 17.623681\n",
      "Iteration 7296 => Loss: 17.622124\n",
      "Iteration 7297 => Loss: 17.620568\n",
      "Iteration 7298 => Loss: 17.619014\n",
      "Iteration 7299 => Loss: 17.617463\n",
      "Iteration 7300 => Loss: 17.615913\n",
      "Iteration 7301 => Loss: 17.614365\n",
      "Iteration 7302 => Loss: 17.612820\n",
      "Iteration 7303 => Loss: 17.611276\n",
      "Iteration 7304 => Loss: 17.609734\n",
      "Iteration 7305 => Loss: 17.608195\n",
      "Iteration 7306 => Loss: 17.606657\n",
      "Iteration 7307 => Loss: 17.605121\n",
      "Iteration 7308 => Loss: 17.605098\n",
      "Iteration 7309 => Loss: 17.603539\n",
      "Iteration 7310 => Loss: 17.601982\n",
      "Iteration 7311 => Loss: 17.600427\n",
      "Iteration 7312 => Loss: 17.598874\n",
      "Iteration 7313 => Loss: 17.597323\n",
      "Iteration 7314 => Loss: 17.595774\n",
      "Iteration 7315 => Loss: 17.594227\n",
      "Iteration 7316 => Loss: 17.592682\n",
      "Iteration 7317 => Loss: 17.591139\n",
      "Iteration 7318 => Loss: 17.589598\n",
      "Iteration 7319 => Loss: 17.588059\n",
      "Iteration 7320 => Loss: 17.586522\n",
      "Iteration 7321 => Loss: 17.584987\n",
      "Iteration 7322 => Loss: 17.583454\n",
      "Iteration 7323 => Loss: 17.581923\n",
      "Iteration 7324 => Loss: 17.580394\n",
      "Iteration 7325 => Loss: 17.578867\n",
      "Iteration 7326 => Loss: 17.578851\n",
      "Iteration 7327 => Loss: 17.577301\n",
      "Iteration 7328 => Loss: 17.575752\n",
      "Iteration 7329 => Loss: 17.574206\n",
      "Iteration 7330 => Loss: 17.572662\n",
      "Iteration 7331 => Loss: 17.571119\n",
      "Iteration 7332 => Loss: 17.569579\n",
      "Iteration 7333 => Loss: 17.568041\n",
      "Iteration 7334 => Loss: 17.566504\n",
      "Iteration 7335 => Loss: 17.564970\n",
      "Iteration 7336 => Loss: 17.563438\n",
      "Iteration 7337 => Loss: 17.561907\n",
      "Iteration 7338 => Loss: 17.560379\n",
      "Iteration 7339 => Loss: 17.558853\n",
      "Iteration 7340 => Loss: 17.557328\n",
      "Iteration 7341 => Loss: 17.555806\n",
      "Iteration 7342 => Loss: 17.554286\n",
      "Iteration 7343 => Loss: 17.552767\n",
      "Iteration 7344 => Loss: 17.552758\n",
      "Iteration 7345 => Loss: 17.551216\n",
      "Iteration 7346 => Loss: 17.549677\n",
      "Iteration 7347 => Loss: 17.548139\n",
      "Iteration 7348 => Loss: 17.546603\n",
      "Iteration 7349 => Loss: 17.545070\n",
      "Iteration 7350 => Loss: 17.543538\n",
      "Iteration 7351 => Loss: 17.542008\n",
      "Iteration 7352 => Loss: 17.540481\n",
      "Iteration 7353 => Loss: 17.538955\n",
      "Iteration 7354 => Loss: 17.537431\n",
      "Iteration 7355 => Loss: 17.535910\n",
      "Iteration 7356 => Loss: 17.534390\n",
      "Iteration 7357 => Loss: 17.532872\n",
      "Iteration 7358 => Loss: 17.531357\n",
      "Iteration 7359 => Loss: 17.529843\n",
      "Iteration 7360 => Loss: 17.528331\n",
      "Iteration 7361 => Loss: 17.526822\n",
      "Iteration 7362 => Loss: 17.526820\n",
      "Iteration 7363 => Loss: 17.525287\n",
      "Iteration 7364 => Loss: 17.523756\n",
      "Iteration 7365 => Loss: 17.522227\n",
      "Iteration 7366 => Loss: 17.520700\n",
      "Iteration 7367 => Loss: 17.519175\n",
      "Iteration 7368 => Loss: 17.517652\n",
      "Iteration 7369 => Loss: 17.516131\n",
      "Iteration 7370 => Loss: 17.514612\n",
      "Iteration 7371 => Loss: 17.513095\n",
      "Iteration 7372 => Loss: 17.511580\n",
      "Iteration 7373 => Loss: 17.510067\n",
      "Iteration 7374 => Loss: 17.508556\n",
      "Iteration 7375 => Loss: 17.507047\n",
      "Iteration 7376 => Loss: 17.505540\n",
      "Iteration 7377 => Loss: 17.504035\n",
      "Iteration 7378 => Loss: 17.502532\n",
      "Iteration 7379 => Loss: 17.501031\n",
      "Iteration 7380 => Loss: 17.499532\n",
      "Iteration 7381 => Loss: 17.499511\n",
      "Iteration 7382 => Loss: 17.497989\n",
      "Iteration 7383 => Loss: 17.496468\n",
      "Iteration 7384 => Loss: 17.494950\n",
      "Iteration 7385 => Loss: 17.493434\n",
      "Iteration 7386 => Loss: 17.491919\n",
      "Iteration 7387 => Loss: 17.490407\n",
      "Iteration 7388 => Loss: 17.488897\n",
      "Iteration 7389 => Loss: 17.487388\n",
      "Iteration 7390 => Loss: 17.485882\n",
      "Iteration 7391 => Loss: 17.484378\n",
      "Iteration 7392 => Loss: 17.482875\n",
      "Iteration 7393 => Loss: 17.481375\n",
      "Iteration 7394 => Loss: 17.479877\n",
      "Iteration 7395 => Loss: 17.478380\n",
      "Iteration 7396 => Loss: 17.476886\n",
      "Iteration 7397 => Loss: 17.475394\n",
      "Iteration 7398 => Loss: 17.473903\n",
      "Iteration 7399 => Loss: 17.473889\n",
      "Iteration 7400 => Loss: 17.472376\n",
      "Iteration 7401 => Loss: 17.470864\n",
      "Iteration 7402 => Loss: 17.469354\n",
      "Iteration 7403 => Loss: 17.467847\n",
      "Iteration 7404 => Loss: 17.466341\n",
      "Iteration 7405 => Loss: 17.464837\n",
      "Iteration 7406 => Loss: 17.463336\n",
      "Iteration 7407 => Loss: 17.461836\n",
      "Iteration 7408 => Loss: 17.460338\n",
      "Iteration 7409 => Loss: 17.458843\n",
      "Iteration 7410 => Loss: 17.457349\n",
      "Iteration 7411 => Loss: 17.455857\n",
      "Iteration 7412 => Loss: 17.454368\n",
      "Iteration 7413 => Loss: 17.452880\n",
      "Iteration 7414 => Loss: 17.451394\n",
      "Iteration 7415 => Loss: 17.449911\n",
      "Iteration 7416 => Loss: 17.448429\n",
      "Iteration 7417 => Loss: 17.448422\n",
      "Iteration 7418 => Loss: 17.446917\n",
      "Iteration 7419 => Loss: 17.445414\n",
      "Iteration 7420 => Loss: 17.443913\n",
      "Iteration 7421 => Loss: 17.442414\n",
      "Iteration 7422 => Loss: 17.440917\n",
      "Iteration 7423 => Loss: 17.439422\n",
      "Iteration 7424 => Loss: 17.437929\n",
      "Iteration 7425 => Loss: 17.436438\n",
      "Iteration 7426 => Loss: 17.434949\n",
      "Iteration 7427 => Loss: 17.433462\n",
      "Iteration 7428 => Loss: 17.431977\n",
      "Iteration 7429 => Loss: 17.430494\n",
      "Iteration 7430 => Loss: 17.429013\n",
      "Iteration 7431 => Loss: 17.427534\n",
      "Iteration 7432 => Loss: 17.426057\n",
      "Iteration 7433 => Loss: 17.424582\n",
      "Iteration 7434 => Loss: 17.423109\n",
      "Iteration 7435 => Loss: 17.421638\n",
      "Iteration 7436 => Loss: 17.421613\n",
      "Iteration 7437 => Loss: 17.420119\n",
      "Iteration 7438 => Loss: 17.418626\n",
      "Iteration 7439 => Loss: 17.417136\n",
      "Iteration 7440 => Loss: 17.415648\n",
      "Iteration 7441 => Loss: 17.414161\n",
      "Iteration 7442 => Loss: 17.412677\n",
      "Iteration 7443 => Loss: 17.411195\n",
      "Iteration 7444 => Loss: 17.409714\n",
      "Iteration 7445 => Loss: 17.408236\n",
      "Iteration 7446 => Loss: 17.406760\n",
      "Iteration 7447 => Loss: 17.405285\n",
      "Iteration 7448 => Loss: 17.403813\n",
      "Iteration 7449 => Loss: 17.402343\n",
      "Iteration 7450 => Loss: 17.400874\n",
      "Iteration 7451 => Loss: 17.399408\n",
      "Iteration 7452 => Loss: 17.397944\n",
      "Iteration 7453 => Loss: 17.396481\n",
      "Iteration 7454 => Loss: 17.396463\n",
      "Iteration 7455 => Loss: 17.394978\n",
      "Iteration 7456 => Loss: 17.393494\n",
      "Iteration 7457 => Loss: 17.392012\n",
      "Iteration 7458 => Loss: 17.390533\n",
      "Iteration 7459 => Loss: 17.389055\n",
      "Iteration 7460 => Loss: 17.387579\n",
      "Iteration 7461 => Loss: 17.386106\n",
      "Iteration 7462 => Loss: 17.384634\n",
      "Iteration 7463 => Loss: 17.383164\n",
      "Iteration 7464 => Loss: 17.381697\n",
      "Iteration 7465 => Loss: 17.380231\n",
      "Iteration 7466 => Loss: 17.378767\n",
      "Iteration 7467 => Loss: 17.377306\n",
      "Iteration 7468 => Loss: 17.375846\n",
      "Iteration 7469 => Loss: 17.374388\n",
      "Iteration 7470 => Loss: 17.372933\n",
      "Iteration 7471 => Loss: 17.371479\n",
      "Iteration 7472 => Loss: 17.371468\n",
      "Iteration 7473 => Loss: 17.369991\n",
      "Iteration 7474 => Loss: 17.368516\n",
      "Iteration 7475 => Loss: 17.367043\n",
      "Iteration 7476 => Loss: 17.365572\n",
      "Iteration 7477 => Loss: 17.364103\n",
      "Iteration 7478 => Loss: 17.362636\n",
      "Iteration 7479 => Loss: 17.361171\n",
      "Iteration 7480 => Loss: 17.359708\n",
      "Iteration 7481 => Loss: 17.358247\n",
      "Iteration 7482 => Loss: 17.356788\n",
      "Iteration 7483 => Loss: 17.355331\n",
      "Iteration 7484 => Loss: 17.353876\n",
      "Iteration 7485 => Loss: 17.352423\n",
      "Iteration 7486 => Loss: 17.350972\n",
      "Iteration 7487 => Loss: 17.349523\n",
      "Iteration 7488 => Loss: 17.348076\n",
      "Iteration 7489 => Loss: 17.346631\n",
      "Iteration 7490 => Loss: 17.346626\n",
      "Iteration 7491 => Loss: 17.345158\n",
      "Iteration 7492 => Loss: 17.343691\n",
      "Iteration 7493 => Loss: 17.342227\n",
      "Iteration 7494 => Loss: 17.340765\n",
      "Iteration 7495 => Loss: 17.339304\n",
      "Iteration 7496 => Loss: 17.337846\n",
      "Iteration 7497 => Loss: 17.336390\n",
      "Iteration 7498 => Loss: 17.334935\n",
      "Iteration 7499 => Loss: 17.333483\n",
      "Iteration 7500 => Loss: 17.332033\n",
      "Iteration 7501 => Loss: 17.330584\n",
      "Iteration 7502 => Loss: 17.329138\n",
      "Iteration 7503 => Loss: 17.327694\n",
      "Iteration 7504 => Loss: 17.326251\n",
      "Iteration 7505 => Loss: 17.324811\n",
      "Iteration 7506 => Loss: 17.323373\n",
      "Iteration 7507 => Loss: 17.321936\n",
      "Iteration 7508 => Loss: 17.320502\n",
      "Iteration 7509 => Loss: 17.320479\n",
      "Iteration 7510 => Loss: 17.319022\n",
      "Iteration 7511 => Loss: 17.317566\n",
      "Iteration 7512 => Loss: 17.316112\n",
      "Iteration 7513 => Loss: 17.314661\n",
      "Iteration 7514 => Loss: 17.313211\n",
      "Iteration 7515 => Loss: 17.311763\n",
      "Iteration 7516 => Loss: 17.310318\n",
      "Iteration 7517 => Loss: 17.308874\n",
      "Iteration 7518 => Loss: 17.307432\n",
      "Iteration 7519 => Loss: 17.305993\n",
      "Iteration 7520 => Loss: 17.304555\n",
      "Iteration 7521 => Loss: 17.303119\n",
      "Iteration 7522 => Loss: 17.301686\n",
      "Iteration 7523 => Loss: 17.300254\n",
      "Iteration 7524 => Loss: 17.298824\n",
      "Iteration 7525 => Loss: 17.297397\n",
      "Iteration 7526 => Loss: 17.295971\n",
      "Iteration 7527 => Loss: 17.295955\n",
      "Iteration 7528 => Loss: 17.294506\n",
      "Iteration 7529 => Loss: 17.293059\n",
      "Iteration 7530 => Loss: 17.291614\n",
      "Iteration 7531 => Loss: 17.290171\n",
      "Iteration 7532 => Loss: 17.288730\n",
      "Iteration 7533 => Loss: 17.287291\n",
      "Iteration 7534 => Loss: 17.285854\n",
      "Iteration 7535 => Loss: 17.284419\n",
      "Iteration 7536 => Loss: 17.282986\n",
      "Iteration 7537 => Loss: 17.281555\n",
      "Iteration 7538 => Loss: 17.280126\n",
      "Iteration 7539 => Loss: 17.278699\n",
      "Iteration 7540 => Loss: 17.277274\n",
      "Iteration 7541 => Loss: 17.275851\n",
      "Iteration 7542 => Loss: 17.274430\n",
      "Iteration 7543 => Loss: 17.273011\n",
      "Iteration 7544 => Loss: 17.271594\n",
      "Iteration 7545 => Loss: 17.271585\n",
      "Iteration 7546 => Loss: 17.270145\n",
      "Iteration 7547 => Loss: 17.268707\n",
      "Iteration 7548 => Loss: 17.267270\n",
      "Iteration 7549 => Loss: 17.265836\n",
      "Iteration 7550 => Loss: 17.264404\n",
      "Iteration 7551 => Loss: 17.262973\n",
      "Iteration 7552 => Loss: 17.261545\n",
      "Iteration 7553 => Loss: 17.260119\n",
      "Iteration 7554 => Loss: 17.258694\n",
      "Iteration 7555 => Loss: 17.257272\n",
      "Iteration 7556 => Loss: 17.255852\n",
      "Iteration 7557 => Loss: 17.254433\n",
      "Iteration 7558 => Loss: 17.253017\n",
      "Iteration 7559 => Loss: 17.251603\n",
      "Iteration 7560 => Loss: 17.250190\n",
      "Iteration 7561 => Loss: 17.248780\n",
      "Iteration 7562 => Loss: 17.247372\n",
      "Iteration 7563 => Loss: 17.247370\n",
      "Iteration 7564 => Loss: 17.245938\n",
      "Iteration 7565 => Loss: 17.244508\n",
      "Iteration 7566 => Loss: 17.243081\n",
      "Iteration 7567 => Loss: 17.241655\n",
      "Iteration 7568 => Loss: 17.240231\n",
      "Iteration 7569 => Loss: 17.238810\n",
      "Iteration 7570 => Loss: 17.237390\n",
      "Iteration 7571 => Loss: 17.235972\n",
      "Iteration 7572 => Loss: 17.234557\n",
      "Iteration 7573 => Loss: 17.233143\n",
      "Iteration 7574 => Loss: 17.231731\n",
      "Iteration 7575 => Loss: 17.230322\n",
      "Iteration 7576 => Loss: 17.228914\n",
      "Iteration 7577 => Loss: 17.227508\n",
      "Iteration 7578 => Loss: 17.226105\n",
      "Iteration 7579 => Loss: 17.224703\n",
      "Iteration 7580 => Loss: 17.223303\n",
      "Iteration 7581 => Loss: 17.221906\n",
      "Iteration 7582 => Loss: 17.221885\n",
      "Iteration 7583 => Loss: 17.220464\n",
      "Iteration 7584 => Loss: 17.219045\n",
      "Iteration 7585 => Loss: 17.217628\n",
      "Iteration 7586 => Loss: 17.216213\n",
      "Iteration 7587 => Loss: 17.214800\n",
      "Iteration 7588 => Loss: 17.213389\n",
      "Iteration 7589 => Loss: 17.211980\n",
      "Iteration 7590 => Loss: 17.210573\n",
      "Iteration 7591 => Loss: 17.209168\n",
      "Iteration 7592 => Loss: 17.207765\n",
      "Iteration 7593 => Loss: 17.206364\n",
      "Iteration 7594 => Loss: 17.204965\n",
      "Iteration 7595 => Loss: 17.203568\n",
      "Iteration 7596 => Loss: 17.202173\n",
      "Iteration 7597 => Loss: 17.200780\n",
      "Iteration 7598 => Loss: 17.199389\n",
      "Iteration 7599 => Loss: 17.198000\n",
      "Iteration 7600 => Loss: 17.197987\n",
      "Iteration 7601 => Loss: 17.196574\n",
      "Iteration 7602 => Loss: 17.195164\n",
      "Iteration 7603 => Loss: 17.193756\n",
      "Iteration 7604 => Loss: 17.192349\n",
      "Iteration 7605 => Loss: 17.190945\n",
      "Iteration 7606 => Loss: 17.189543\n",
      "Iteration 7607 => Loss: 17.188142\n",
      "Iteration 7608 => Loss: 17.186744\n",
      "Iteration 7609 => Loss: 17.185348\n",
      "Iteration 7610 => Loss: 17.183953\n",
      "Iteration 7611 => Loss: 17.182561\n",
      "Iteration 7612 => Loss: 17.181171\n",
      "Iteration 7613 => Loss: 17.179782\n",
      "Iteration 7614 => Loss: 17.178396\n",
      "Iteration 7615 => Loss: 17.177012\n",
      "Iteration 7616 => Loss: 17.175629\n",
      "Iteration 7617 => Loss: 17.174249\n",
      "Iteration 7618 => Loss: 17.174242\n",
      "Iteration 7619 => Loss: 17.172839\n",
      "Iteration 7620 => Loss: 17.171437\n",
      "Iteration 7621 => Loss: 17.170037\n",
      "Iteration 7622 => Loss: 17.168640\n",
      "Iteration 7623 => Loss: 17.167244\n",
      "Iteration 7624 => Loss: 17.165850\n",
      "Iteration 7625 => Loss: 17.164459\n",
      "Iteration 7626 => Loss: 17.163069\n",
      "Iteration 7627 => Loss: 17.161681\n",
      "Iteration 7628 => Loss: 17.160296\n",
      "Iteration 7629 => Loss: 17.158912\n",
      "Iteration 7630 => Loss: 17.157530\n",
      "Iteration 7631 => Loss: 17.156151\n",
      "Iteration 7632 => Loss: 17.154773\n",
      "Iteration 7633 => Loss: 17.153397\n",
      "Iteration 7634 => Loss: 17.152024\n",
      "Iteration 7635 => Loss: 17.150652\n",
      "Iteration 7636 => Loss: 17.149282\n",
      "Iteration 7637 => Loss: 17.149258\n",
      "Iteration 7638 => Loss: 17.147865\n",
      "Iteration 7639 => Loss: 17.146474\n",
      "Iteration 7640 => Loss: 17.145085\n",
      "Iteration 7641 => Loss: 17.143698\n",
      "Iteration 7642 => Loss: 17.142313\n",
      "Iteration 7643 => Loss: 17.140930\n",
      "Iteration 7644 => Loss: 17.139549\n",
      "Iteration 7645 => Loss: 17.138170\n",
      "Iteration 7646 => Loss: 17.136793\n",
      "Iteration 7647 => Loss: 17.135418\n",
      "Iteration 7648 => Loss: 17.134045\n",
      "Iteration 7649 => Loss: 17.132674\n",
      "Iteration 7650 => Loss: 17.131305\n",
      "Iteration 7651 => Loss: 17.129938\n",
      "Iteration 7652 => Loss: 17.128573\n",
      "Iteration 7653 => Loss: 17.127210\n",
      "Iteration 7654 => Loss: 17.125849\n",
      "Iteration 7655 => Loss: 17.125831\n",
      "Iteration 7656 => Loss: 17.124446\n",
      "Iteration 7657 => Loss: 17.123064\n",
      "Iteration 7658 => Loss: 17.121684\n",
      "Iteration 7659 => Loss: 17.120305\n",
      "Iteration 7660 => Loss: 17.118929\n",
      "Iteration 7661 => Loss: 17.117555\n",
      "Iteration 7662 => Loss: 17.116182\n",
      "Iteration 7663 => Loss: 17.114812\n",
      "Iteration 7664 => Loss: 17.113444\n",
      "Iteration 7665 => Loss: 17.112077\n",
      "Iteration 7666 => Loss: 17.110713\n",
      "Iteration 7667 => Loss: 17.109351\n",
      "Iteration 7668 => Loss: 17.107990\n",
      "Iteration 7669 => Loss: 17.106632\n",
      "Iteration 7670 => Loss: 17.105276\n",
      "Iteration 7671 => Loss: 17.103921\n",
      "Iteration 7672 => Loss: 17.102569\n",
      "Iteration 7673 => Loss: 17.102558\n",
      "Iteration 7674 => Loss: 17.101182\n",
      "Iteration 7675 => Loss: 17.099808\n",
      "Iteration 7676 => Loss: 17.098437\n",
      "Iteration 7677 => Loss: 17.097067\n",
      "Iteration 7678 => Loss: 17.095699\n",
      "Iteration 7679 => Loss: 17.094334\n",
      "Iteration 7680 => Loss: 17.092970\n",
      "Iteration 7681 => Loss: 17.091608\n",
      "Iteration 7682 => Loss: 17.090249\n",
      "Iteration 7683 => Loss: 17.088891\n",
      "Iteration 7684 => Loss: 17.087535\n",
      "Iteration 7685 => Loss: 17.086182\n",
      "Iteration 7686 => Loss: 17.084830\n",
      "Iteration 7687 => Loss: 17.083480\n",
      "Iteration 7688 => Loss: 17.082133\n",
      "Iteration 7689 => Loss: 17.080787\n",
      "Iteration 7690 => Loss: 17.079443\n",
      "Iteration 7691 => Loss: 17.079439\n",
      "Iteration 7692 => Loss: 17.078072\n",
      "Iteration 7693 => Loss: 17.076707\n",
      "Iteration 7694 => Loss: 17.075344\n",
      "Iteration 7695 => Loss: 17.073983\n",
      "Iteration 7696 => Loss: 17.072624\n",
      "Iteration 7697 => Loss: 17.071267\n",
      "Iteration 7698 => Loss: 17.069912\n",
      "Iteration 7699 => Loss: 17.068559\n",
      "Iteration 7700 => Loss: 17.067208\n",
      "Iteration 7701 => Loss: 17.065859\n",
      "Iteration 7702 => Loss: 17.064512\n",
      "Iteration 7703 => Loss: 17.063167\n",
      "Iteration 7704 => Loss: 17.061824\n",
      "Iteration 7705 => Loss: 17.060483\n",
      "Iteration 7706 => Loss: 17.059144\n",
      "Iteration 7707 => Loss: 17.057807\n",
      "Iteration 7708 => Loss: 17.056472\n",
      "Iteration 7709 => Loss: 17.055139\n",
      "Iteration 7710 => Loss: 17.055117\n",
      "Iteration 7711 => Loss: 17.053760\n",
      "Iteration 7712 => Loss: 17.052406\n",
      "Iteration 7713 => Loss: 17.051054\n",
      "Iteration 7714 => Loss: 17.049703\n",
      "Iteration 7715 => Loss: 17.048355\n",
      "Iteration 7716 => Loss: 17.047009\n",
      "Iteration 7717 => Loss: 17.045664\n",
      "Iteration 7718 => Loss: 17.044322\n",
      "Iteration 7719 => Loss: 17.042982\n",
      "Iteration 7720 => Loss: 17.041643\n",
      "Iteration 7721 => Loss: 17.040307\n",
      "Iteration 7722 => Loss: 17.038973\n",
      "Iteration 7723 => Loss: 17.037640\n",
      "Iteration 7724 => Loss: 17.036310\n",
      "Iteration 7725 => Loss: 17.034982\n",
      "Iteration 7726 => Loss: 17.033655\n",
      "Iteration 7727 => Loss: 17.032331\n",
      "Iteration 7728 => Loss: 17.032316\n",
      "Iteration 7729 => Loss: 17.030968\n",
      "Iteration 7730 => Loss: 17.029622\n",
      "Iteration 7731 => Loss: 17.028279\n",
      "Iteration 7732 => Loss: 17.026937\n",
      "Iteration 7733 => Loss: 17.025597\n",
      "Iteration 7734 => Loss: 17.024260\n",
      "Iteration 7735 => Loss: 17.022924\n",
      "Iteration 7736 => Loss: 17.021590\n",
      "Iteration 7737 => Loss: 17.020259\n",
      "Iteration 7738 => Loss: 17.018929\n",
      "Iteration 7739 => Loss: 17.017601\n",
      "Iteration 7740 => Loss: 17.016276\n",
      "Iteration 7741 => Loss: 17.014952\n",
      "Iteration 7742 => Loss: 17.013630\n",
      "Iteration 7743 => Loss: 17.012311\n",
      "Iteration 7744 => Loss: 17.010993\n",
      "Iteration 7745 => Loss: 17.009677\n",
      "Iteration 7746 => Loss: 17.009669\n",
      "Iteration 7747 => Loss: 17.008330\n",
      "Iteration 7748 => Loss: 17.006993\n",
      "Iteration 7749 => Loss: 17.005658\n",
      "Iteration 7750 => Loss: 17.004325\n",
      "Iteration 7751 => Loss: 17.002994\n",
      "Iteration 7752 => Loss: 17.001665\n",
      "Iteration 7753 => Loss: 17.000338\n",
      "Iteration 7754 => Loss: 16.999013\n",
      "Iteration 7755 => Loss: 16.997690\n",
      "Iteration 7756 => Loss: 16.996369\n",
      "Iteration 7757 => Loss: 16.995050\n",
      "Iteration 7758 => Loss: 16.993733\n",
      "Iteration 7759 => Loss: 16.992418\n",
      "Iteration 7760 => Loss: 16.991105\n",
      "Iteration 7761 => Loss: 16.989794\n",
      "Iteration 7762 => Loss: 16.988485\n",
      "Iteration 7763 => Loss: 16.987178\n",
      "Iteration 7764 => Loss: 16.987176\n",
      "Iteration 7765 => Loss: 16.985845\n",
      "Iteration 7766 => Loss: 16.984517\n",
      "Iteration 7767 => Loss: 16.983191\n",
      "Iteration 7768 => Loss: 16.981866\n",
      "Iteration 7769 => Loss: 16.980544\n",
      "Iteration 7770 => Loss: 16.979224\n",
      "Iteration 7771 => Loss: 16.977905\n",
      "Iteration 7772 => Loss: 16.976589\n",
      "Iteration 7773 => Loss: 16.975275\n",
      "Iteration 7774 => Loss: 16.973962\n",
      "Iteration 7775 => Loss: 16.972652\n",
      "Iteration 7776 => Loss: 16.971344\n",
      "Iteration 7777 => Loss: 16.970037\n",
      "Iteration 7778 => Loss: 16.968733\n",
      "Iteration 7779 => Loss: 16.967431\n",
      "Iteration 7780 => Loss: 16.966130\n",
      "Iteration 7781 => Loss: 16.964832\n",
      "Iteration 7782 => Loss: 16.963536\n",
      "Iteration 7783 => Loss: 16.963516\n",
      "Iteration 7784 => Loss: 16.962196\n",
      "Iteration 7785 => Loss: 16.960878\n",
      "Iteration 7786 => Loss: 16.959563\n",
      "Iteration 7787 => Loss: 16.958249\n",
      "Iteration 7788 => Loss: 16.956937\n",
      "Iteration 7789 => Loss: 16.955628\n",
      "Iteration 7790 => Loss: 16.954320\n",
      "Iteration 7791 => Loss: 16.953014\n",
      "Iteration 7792 => Loss: 16.951711\n",
      "Iteration 7793 => Loss: 16.950409\n",
      "Iteration 7794 => Loss: 16.949109\n",
      "Iteration 7795 => Loss: 16.947812\n",
      "Iteration 7796 => Loss: 16.946516\n",
      "Iteration 7797 => Loss: 16.945222\n",
      "Iteration 7798 => Loss: 16.943931\n",
      "Iteration 7799 => Loss: 16.942641\n",
      "Iteration 7800 => Loss: 16.941353\n",
      "Iteration 7801 => Loss: 16.941340\n",
      "Iteration 7802 => Loss: 16.940029\n",
      "Iteration 7803 => Loss: 16.938720\n",
      "Iteration 7804 => Loss: 16.937413\n",
      "Iteration 7805 => Loss: 16.936108\n",
      "Iteration 7806 => Loss: 16.934805\n",
      "Iteration 7807 => Loss: 16.933504\n",
      "Iteration 7808 => Loss: 16.932205\n",
      "Iteration 7809 => Loss: 16.930908\n",
      "Iteration 7810 => Loss: 16.929613\n",
      "Iteration 7811 => Loss: 16.928320\n",
      "Iteration 7812 => Loss: 16.927029\n",
      "Iteration 7813 => Loss: 16.925740\n",
      "Iteration 7814 => Loss: 16.924453\n",
      "Iteration 7815 => Loss: 16.923168\n",
      "Iteration 7816 => Loss: 16.921885\n",
      "Iteration 7817 => Loss: 16.920604\n",
      "Iteration 7818 => Loss: 16.919325\n",
      "Iteration 7819 => Loss: 16.919319\n",
      "Iteration 7820 => Loss: 16.918017\n",
      "Iteration 7821 => Loss: 16.916716\n",
      "Iteration 7822 => Loss: 16.915418\n",
      "Iteration 7823 => Loss: 16.914122\n",
      "Iteration 7824 => Loss: 16.912827\n",
      "Iteration 7825 => Loss: 16.911535\n",
      "Iteration 7826 => Loss: 16.910245\n",
      "Iteration 7827 => Loss: 16.908956\n",
      "Iteration 7828 => Loss: 16.907670\n",
      "Iteration 7829 => Loss: 16.906386\n",
      "Iteration 7830 => Loss: 16.905103\n",
      "Iteration 7831 => Loss: 16.903823\n",
      "Iteration 7832 => Loss: 16.902545\n",
      "Iteration 7833 => Loss: 16.901268\n",
      "Iteration 7834 => Loss: 16.899994\n",
      "Iteration 7835 => Loss: 16.898722\n",
      "Iteration 7836 => Loss: 16.897451\n",
      "Iteration 7837 => Loss: 16.896183\n",
      "Iteration 7838 => Loss: 16.896158\n",
      "Iteration 7839 => Loss: 16.894867\n",
      "Iteration 7840 => Loss: 16.893577\n",
      "Iteration 7841 => Loss: 16.892289\n",
      "Iteration 7842 => Loss: 16.891004\n",
      "Iteration 7843 => Loss: 16.889720\n",
      "Iteration 7844 => Loss: 16.888438\n",
      "Iteration 7845 => Loss: 16.887159\n",
      "Iteration 7846 => Loss: 16.885881\n",
      "Iteration 7847 => Loss: 16.884605\n",
      "Iteration 7848 => Loss: 16.883332\n",
      "Iteration 7849 => Loss: 16.882060\n",
      "Iteration 7850 => Loss: 16.880790\n",
      "Iteration 7851 => Loss: 16.879523\n",
      "Iteration 7852 => Loss: 16.878257\n",
      "Iteration 7853 => Loss: 16.876993\n",
      "Iteration 7854 => Loss: 16.875732\n",
      "Iteration 7855 => Loss: 16.874472\n",
      "Iteration 7856 => Loss: 16.874454\n",
      "Iteration 7857 => Loss: 16.873171\n",
      "Iteration 7858 => Loss: 16.871890\n",
      "Iteration 7859 => Loss: 16.870611\n",
      "Iteration 7860 => Loss: 16.869334\n",
      "Iteration 7861 => Loss: 16.868059\n",
      "Iteration 7862 => Loss: 16.866786\n",
      "Iteration 7863 => Loss: 16.865515\n",
      "Iteration 7864 => Loss: 16.864246\n",
      "Iteration 7865 => Loss: 16.862979\n",
      "Iteration 7866 => Loss: 16.861714\n",
      "Iteration 7867 => Loss: 16.860451\n",
      "Iteration 7868 => Loss: 16.859190\n",
      "Iteration 7869 => Loss: 16.857931\n",
      "Iteration 7870 => Loss: 16.856674\n",
      "Iteration 7871 => Loss: 16.855419\n",
      "Iteration 7872 => Loss: 16.854166\n",
      "Iteration 7873 => Loss: 16.852915\n",
      "Iteration 7874 => Loss: 16.852904\n",
      "Iteration 7875 => Loss: 16.851630\n",
      "Iteration 7876 => Loss: 16.850358\n",
      "Iteration 7877 => Loss: 16.849087\n",
      "Iteration 7878 => Loss: 16.847819\n",
      "Iteration 7879 => Loss: 16.846553\n",
      "Iteration 7880 => Loss: 16.845288\n",
      "Iteration 7881 => Loss: 16.844026\n",
      "Iteration 7882 => Loss: 16.842766\n",
      "Iteration 7883 => Loss: 16.841507\n",
      "Iteration 7884 => Loss: 16.840251\n",
      "Iteration 7885 => Loss: 16.838997\n",
      "Iteration 7886 => Loss: 16.837744\n",
      "Iteration 7887 => Loss: 16.836494\n",
      "Iteration 7888 => Loss: 16.835246\n",
      "Iteration 7889 => Loss: 16.833999\n",
      "Iteration 7890 => Loss: 16.832755\n",
      "Iteration 7891 => Loss: 16.831513\n",
      "Iteration 7892 => Loss: 16.831509\n",
      "Iteration 7893 => Loss: 16.830243\n",
      "Iteration 7894 => Loss: 16.828979\n",
      "Iteration 7895 => Loss: 16.827718\n",
      "Iteration 7896 => Loss: 16.826458\n",
      "Iteration 7897 => Loss: 16.825200\n",
      "Iteration 7898 => Loss: 16.823945\n",
      "Iteration 7899 => Loss: 16.822691\n",
      "Iteration 7900 => Loss: 16.821439\n",
      "Iteration 7901 => Loss: 16.820190\n",
      "Iteration 7902 => Loss: 16.818942\n",
      "Iteration 7903 => Loss: 16.817696\n",
      "Iteration 7904 => Loss: 16.816453\n",
      "Iteration 7905 => Loss: 16.815211\n",
      "Iteration 7906 => Loss: 16.813971\n",
      "Iteration 7907 => Loss: 16.812734\n",
      "Iteration 7908 => Loss: 16.811498\n",
      "Iteration 7909 => Loss: 16.810264\n",
      "Iteration 7910 => Loss: 16.809033\n",
      "Iteration 7911 => Loss: 16.809011\n",
      "Iteration 7912 => Loss: 16.807756\n",
      "Iteration 7913 => Loss: 16.806503\n",
      "Iteration 7914 => Loss: 16.805252\n",
      "Iteration 7915 => Loss: 16.804003\n",
      "Iteration 7916 => Loss: 16.802756\n",
      "Iteration 7917 => Loss: 16.801511\n",
      "Iteration 7918 => Loss: 16.800268\n",
      "Iteration 7919 => Loss: 16.799027\n",
      "Iteration 7920 => Loss: 16.797788\n",
      "Iteration 7921 => Loss: 16.796551\n",
      "Iteration 7922 => Loss: 16.795316\n",
      "Iteration 7923 => Loss: 16.794083\n",
      "Iteration 7924 => Loss: 16.792852\n",
      "Iteration 7925 => Loss: 16.791623\n",
      "Iteration 7926 => Loss: 16.790396\n",
      "Iteration 7927 => Loss: 16.789171\n",
      "Iteration 7928 => Loss: 16.787948\n",
      "Iteration 7929 => Loss: 16.787932\n",
      "Iteration 7930 => Loss: 16.786686\n",
      "Iteration 7931 => Loss: 16.785442\n",
      "Iteration 7932 => Loss: 16.784199\n",
      "Iteration 7933 => Loss: 16.782959\n",
      "Iteration 7934 => Loss: 16.781721\n",
      "Iteration 7935 => Loss: 16.780484\n",
      "Iteration 7936 => Loss: 16.779250\n",
      "Iteration 7937 => Loss: 16.778018\n",
      "Iteration 7938 => Loss: 16.776787\n",
      "Iteration 7939 => Loss: 16.775559\n",
      "Iteration 7940 => Loss: 16.774333\n",
      "Iteration 7941 => Loss: 16.773108\n",
      "Iteration 7942 => Loss: 16.771886\n",
      "Iteration 7943 => Loss: 16.770666\n",
      "Iteration 7944 => Loss: 16.769447\n",
      "Iteration 7945 => Loss: 16.768231\n",
      "Iteration 7946 => Loss: 16.767017\n",
      "Iteration 7947 => Loss: 16.767008\n",
      "Iteration 7948 => Loss: 16.765770\n",
      "Iteration 7949 => Loss: 16.764535\n",
      "Iteration 7950 => Loss: 16.763301\n",
      "Iteration 7951 => Loss: 16.762069\n",
      "Iteration 7952 => Loss: 16.760840\n",
      "Iteration 7953 => Loss: 16.759612\n",
      "Iteration 7954 => Loss: 16.758386\n",
      "Iteration 7955 => Loss: 16.757163\n",
      "Iteration 7956 => Loss: 16.755941\n",
      "Iteration 7957 => Loss: 16.754721\n",
      "Iteration 7958 => Loss: 16.753504\n",
      "Iteration 7959 => Loss: 16.752288\n",
      "Iteration 7960 => Loss: 16.751074\n",
      "Iteration 7961 => Loss: 16.749863\n",
      "Iteration 7962 => Loss: 16.748653\n",
      "Iteration 7963 => Loss: 16.747445\n",
      "Iteration 7964 => Loss: 16.746240\n",
      "Iteration 7965 => Loss: 16.746238\n",
      "Iteration 7966 => Loss: 16.745009\n",
      "Iteration 7967 => Loss: 16.743782\n",
      "Iteration 7968 => Loss: 16.742557\n",
      "Iteration 7969 => Loss: 16.741334\n",
      "Iteration 7970 => Loss: 16.740113\n",
      "Iteration 7971 => Loss: 16.738894\n",
      "Iteration 7972 => Loss: 16.737677\n",
      "Iteration 7973 => Loss: 16.736462\n",
      "Iteration 7974 => Loss: 16.735249\n",
      "Iteration 7975 => Loss: 16.734038\n",
      "Iteration 7976 => Loss: 16.732829\n",
      "Iteration 7977 => Loss: 16.731622\n",
      "Iteration 7978 => Loss: 16.730417\n",
      "Iteration 7979 => Loss: 16.729214\n",
      "Iteration 7980 => Loss: 16.728013\n",
      "Iteration 7981 => Loss: 16.726814\n",
      "Iteration 7982 => Loss: 16.725617\n",
      "Iteration 7983 => Loss: 16.724422\n",
      "Iteration 7984 => Loss: 16.724402\n",
      "Iteration 7985 => Loss: 16.723184\n",
      "Iteration 7986 => Loss: 16.721968\n",
      "Iteration 7987 => Loss: 16.720753\n",
      "Iteration 7988 => Loss: 16.719541\n",
      "Iteration 7989 => Loss: 16.718331\n",
      "Iteration 7990 => Loss: 16.717122\n",
      "Iteration 7991 => Loss: 16.715916\n",
      "Iteration 7992 => Loss: 16.714712\n",
      "Iteration 7993 => Loss: 16.713509\n",
      "Iteration 7994 => Loss: 16.712309\n",
      "Iteration 7995 => Loss: 16.711111\n",
      "Iteration 7996 => Loss: 16.709914\n",
      "Iteration 7997 => Loss: 16.708720\n",
      "Iteration 7998 => Loss: 16.707528\n",
      "Iteration 7999 => Loss: 16.706337\n",
      "Iteration 8000 => Loss: 16.705149\n",
      "Iteration 8001 => Loss: 16.703963\n",
      "Iteration 8002 => Loss: 16.703950\n",
      "Iteration 8003 => Loss: 16.702740\n",
      "Iteration 8004 => Loss: 16.701533\n",
      "Iteration 8005 => Loss: 16.700327\n",
      "Iteration 8006 => Loss: 16.699123\n",
      "Iteration 8007 => Loss: 16.697922\n",
      "Iteration 8008 => Loss: 16.696722\n",
      "Iteration 8009 => Loss: 16.695524\n",
      "Iteration 8010 => Loss: 16.694329\n",
      "Iteration 8011 => Loss: 16.693135\n",
      "Iteration 8012 => Loss: 16.691943\n",
      "Iteration 8013 => Loss: 16.690754\n",
      "Iteration 8014 => Loss: 16.689566\n",
      "Iteration 8015 => Loss: 16.688380\n",
      "Iteration 8016 => Loss: 16.687197\n",
      "Iteration 8017 => Loss: 16.686015\n",
      "Iteration 8018 => Loss: 16.684835\n",
      "Iteration 8019 => Loss: 16.683658\n",
      "Iteration 8020 => Loss: 16.683652\n",
      "Iteration 8021 => Loss: 16.682451\n",
      "Iteration 8022 => Loss: 16.681252\n",
      "Iteration 8023 => Loss: 16.680055\n",
      "Iteration 8024 => Loss: 16.678860\n",
      "Iteration 8025 => Loss: 16.677667\n",
      "Iteration 8026 => Loss: 16.676476\n",
      "Iteration 8027 => Loss: 16.675287\n",
      "Iteration 8028 => Loss: 16.674100\n",
      "Iteration 8029 => Loss: 16.672915\n",
      "Iteration 8030 => Loss: 16.671732\n",
      "Iteration 8031 => Loss: 16.670551\n",
      "Iteration 8032 => Loss: 16.669372\n",
      "Iteration 8033 => Loss: 16.668195\n",
      "Iteration 8034 => Loss: 16.667020\n",
      "Iteration 8035 => Loss: 16.665847\n",
      "Iteration 8036 => Loss: 16.664676\n",
      "Iteration 8037 => Loss: 16.663507\n",
      "Iteration 8038 => Loss: 16.662340\n",
      "Iteration 8039 => Loss: 16.662315\n",
      "Iteration 8040 => Loss: 16.661125\n",
      "Iteration 8041 => Loss: 16.659936\n",
      "Iteration 8042 => Loss: 16.658750\n",
      "Iteration 8043 => Loss: 16.657566\n",
      "Iteration 8044 => Loss: 16.656383\n",
      "Iteration 8045 => Loss: 16.655203\n",
      "Iteration 8046 => Loss: 16.654025\n",
      "Iteration 8047 => Loss: 16.652848\n",
      "Iteration 8048 => Loss: 16.651674\n",
      "Iteration 8049 => Loss: 16.650502\n",
      "Iteration 8050 => Loss: 16.649331\n",
      "Iteration 8051 => Loss: 16.648163\n",
      "Iteration 8052 => Loss: 16.646997\n",
      "Iteration 8053 => Loss: 16.645832\n",
      "Iteration 8054 => Loss: 16.644670\n",
      "Iteration 8055 => Loss: 16.643510\n",
      "Iteration 8056 => Loss: 16.642351\n",
      "Iteration 8057 => Loss: 16.642334\n",
      "Iteration 8058 => Loss: 16.641152\n",
      "Iteration 8059 => Loss: 16.639973\n",
      "Iteration 8060 => Loss: 16.638795\n",
      "Iteration 8061 => Loss: 16.637619\n",
      "Iteration 8062 => Loss: 16.636446\n",
      "Iteration 8063 => Loss: 16.635274\n",
      "Iteration 8064 => Loss: 16.634104\n",
      "Iteration 8065 => Loss: 16.632937\n",
      "Iteration 8066 => Loss: 16.631771\n",
      "Iteration 8067 => Loss: 16.630607\n",
      "Iteration 8068 => Loss: 16.629446\n",
      "Iteration 8069 => Loss: 16.628286\n",
      "Iteration 8070 => Loss: 16.627128\n",
      "Iteration 8071 => Loss: 16.625973\n",
      "Iteration 8072 => Loss: 16.624819\n",
      "Iteration 8073 => Loss: 16.623667\n",
      "Iteration 8074 => Loss: 16.622518\n",
      "Iteration 8075 => Loss: 16.622507\n",
      "Iteration 8076 => Loss: 16.621334\n",
      "Iteration 8077 => Loss: 16.620163\n",
      "Iteration 8078 => Loss: 16.618994\n",
      "Iteration 8079 => Loss: 16.617827\n",
      "Iteration 8080 => Loss: 16.616662\n",
      "Iteration 8081 => Loss: 16.615499\n",
      "Iteration 8082 => Loss: 16.614338\n",
      "Iteration 8083 => Loss: 16.613179\n",
      "Iteration 8084 => Loss: 16.612022\n",
      "Iteration 8085 => Loss: 16.610867\n",
      "Iteration 8086 => Loss: 16.609714\n",
      "Iteration 8087 => Loss: 16.608563\n",
      "Iteration 8088 => Loss: 16.607414\n",
      "Iteration 8089 => Loss: 16.606267\n",
      "Iteration 8090 => Loss: 16.605122\n",
      "Iteration 8091 => Loss: 16.603979\n",
      "Iteration 8092 => Loss: 16.602838\n",
      "Iteration 8093 => Loss: 16.602835\n",
      "Iteration 8094 => Loss: 16.601670\n",
      "Iteration 8095 => Loss: 16.600508\n",
      "Iteration 8096 => Loss: 16.599348\n",
      "Iteration 8097 => Loss: 16.598189\n",
      "Iteration 8098 => Loss: 16.597033\n",
      "Iteration 8099 => Loss: 16.595879\n",
      "Iteration 8100 => Loss: 16.594726\n",
      "Iteration 8101 => Loss: 16.593576\n",
      "Iteration 8102 => Loss: 16.592428\n",
      "Iteration 8103 => Loss: 16.591281\n",
      "Iteration 8104 => Loss: 16.590137\n",
      "Iteration 8105 => Loss: 16.588995\n",
      "Iteration 8106 => Loss: 16.587854\n",
      "Iteration 8107 => Loss: 16.586716\n",
      "Iteration 8108 => Loss: 16.585580\n",
      "Iteration 8109 => Loss: 16.584445\n",
      "Iteration 8110 => Loss: 16.583313\n",
      "Iteration 8111 => Loss: 16.582183\n",
      "Iteration 8112 => Loss: 16.582161\n",
      "Iteration 8113 => Loss: 16.581007\n",
      "Iteration 8114 => Loss: 16.579855\n",
      "Iteration 8115 => Loss: 16.578706\n",
      "Iteration 8116 => Loss: 16.577558\n",
      "Iteration 8117 => Loss: 16.576412\n",
      "Iteration 8118 => Loss: 16.575269\n",
      "Iteration 8119 => Loss: 16.574127\n",
      "Iteration 8120 => Loss: 16.572987\n",
      "Iteration 8121 => Loss: 16.571850\n",
      "Iteration 8122 => Loss: 16.570714\n",
      "Iteration 8123 => Loss: 16.569580\n",
      "Iteration 8124 => Loss: 16.568449\n",
      "Iteration 8125 => Loss: 16.567319\n",
      "Iteration 8126 => Loss: 16.566191\n",
      "Iteration 8127 => Loss: 16.565066\n",
      "Iteration 8128 => Loss: 16.563942\n",
      "Iteration 8129 => Loss: 16.562820\n",
      "Iteration 8130 => Loss: 16.562805\n",
      "Iteration 8131 => Loss: 16.561660\n",
      "Iteration 8132 => Loss: 16.560517\n",
      "Iteration 8133 => Loss: 16.559376\n",
      "Iteration 8134 => Loss: 16.558237\n",
      "Iteration 8135 => Loss: 16.557100\n",
      "Iteration 8136 => Loss: 16.555965\n",
      "Iteration 8137 => Loss: 16.554832\n",
      "Iteration 8138 => Loss: 16.553701\n",
      "Iteration 8139 => Loss: 16.552572\n",
      "Iteration 8140 => Loss: 16.551445\n",
      "Iteration 8141 => Loss: 16.550320\n",
      "Iteration 8142 => Loss: 16.549197\n",
      "Iteration 8143 => Loss: 16.548076\n",
      "Iteration 8144 => Loss: 16.546957\n",
      "Iteration 8145 => Loss: 16.545840\n",
      "Iteration 8146 => Loss: 16.544725\n",
      "Iteration 8147 => Loss: 16.543612\n",
      "Iteration 8148 => Loss: 16.543604\n",
      "Iteration 8149 => Loss: 16.542468\n",
      "Iteration 8150 => Loss: 16.541333\n",
      "Iteration 8151 => Loss: 16.540201\n",
      "Iteration 8152 => Loss: 16.539071\n",
      "Iteration 8153 => Loss: 16.537942\n",
      "Iteration 8154 => Loss: 16.536816\n",
      "Iteration 8155 => Loss: 16.535692\n",
      "Iteration 8156 => Loss: 16.534569\n",
      "Iteration 8157 => Loss: 16.533449\n",
      "Iteration 8158 => Loss: 16.532331\n",
      "Iteration 8159 => Loss: 16.531214\n",
      "Iteration 8160 => Loss: 16.530100\n",
      "Iteration 8161 => Loss: 16.528988\n",
      "Iteration 8162 => Loss: 16.527877\n",
      "Iteration 8163 => Loss: 16.526769\n",
      "Iteration 8164 => Loss: 16.525663\n",
      "Iteration 8165 => Loss: 16.524558\n",
      "Iteration 8166 => Loss: 16.524557\n",
      "Iteration 8167 => Loss: 16.523429\n",
      "Iteration 8168 => Loss: 16.522304\n",
      "Iteration 8169 => Loss: 16.521180\n",
      "Iteration 8170 => Loss: 16.520058\n",
      "Iteration 8171 => Loss: 16.518939\n",
      "Iteration 8172 => Loss: 16.517821\n",
      "Iteration 8173 => Loss: 16.516705\n",
      "Iteration 8174 => Loss: 16.515592\n",
      "Iteration 8175 => Loss: 16.514480\n",
      "Iteration 8176 => Loss: 16.513370\n",
      "Iteration 8177 => Loss: 16.512263\n",
      "Iteration 8178 => Loss: 16.511157\n",
      "Iteration 8179 => Loss: 16.510053\n",
      "Iteration 8180 => Loss: 16.508952\n",
      "Iteration 8181 => Loss: 16.507852\n",
      "Iteration 8182 => Loss: 16.506754\n",
      "Iteration 8183 => Loss: 16.505659\n",
      "Iteration 8184 => Loss: 16.504565\n",
      "Iteration 8185 => Loss: 16.504546\n",
      "Iteration 8186 => Loss: 16.503429\n",
      "Iteration 8187 => Loss: 16.502314\n",
      "Iteration 8188 => Loss: 16.501201\n",
      "Iteration 8189 => Loss: 16.500090\n",
      "Iteration 8190 => Loss: 16.498981\n",
      "Iteration 8191 => Loss: 16.497874\n",
      "Iteration 8192 => Loss: 16.496769\n",
      "Iteration 8193 => Loss: 16.495666\n",
      "Iteration 8194 => Loss: 16.494565\n",
      "Iteration 8195 => Loss: 16.493466\n",
      "Iteration 8196 => Loss: 16.492369\n",
      "Iteration 8197 => Loss: 16.491274\n",
      "Iteration 8198 => Loss: 16.490181\n",
      "Iteration 8199 => Loss: 16.489090\n",
      "Iteration 8200 => Loss: 16.488001\n",
      "Iteration 8201 => Loss: 16.486914\n",
      "Iteration 8202 => Loss: 16.485829\n",
      "Iteration 8203 => Loss: 16.485816\n",
      "Iteration 8204 => Loss: 16.484708\n",
      "Iteration 8205 => Loss: 16.483601\n",
      "Iteration 8206 => Loss: 16.482497\n",
      "Iteration 8207 => Loss: 16.481395\n",
      "Iteration 8208 => Loss: 16.480294\n",
      "Iteration 8209 => Loss: 16.479196\n",
      "Iteration 8210 => Loss: 16.478100\n",
      "Iteration 8211 => Loss: 16.477005\n",
      "Iteration 8212 => Loss: 16.475913\n",
      "Iteration 8213 => Loss: 16.474823\n",
      "Iteration 8214 => Loss: 16.473734\n",
      "Iteration 8215 => Loss: 16.472648\n",
      "Iteration 8216 => Loss: 16.471564\n",
      "Iteration 8217 => Loss: 16.470481\n",
      "Iteration 8218 => Loss: 16.469401\n",
      "Iteration 8219 => Loss: 16.468323\n",
      "Iteration 8220 => Loss: 16.467246\n",
      "Iteration 8221 => Loss: 16.467240\n",
      "Iteration 8222 => Loss: 16.466141\n",
      "Iteration 8223 => Loss: 16.465043\n",
      "Iteration 8224 => Loss: 16.463947\n",
      "Iteration 8225 => Loss: 16.462854\n",
      "Iteration 8226 => Loss: 16.461762\n",
      "Iteration 8227 => Loss: 16.460672\n",
      "Iteration 8228 => Loss: 16.459585\n",
      "Iteration 8229 => Loss: 16.458499\n",
      "Iteration 8230 => Loss: 16.457415\n",
      "Iteration 8231 => Loss: 16.456334\n",
      "Iteration 8232 => Loss: 16.455254\n",
      "Iteration 8233 => Loss: 16.454176\n",
      "Iteration 8234 => Loss: 16.453101\n",
      "Iteration 8235 => Loss: 16.452027\n",
      "Iteration 8236 => Loss: 16.450955\n",
      "Iteration 8237 => Loss: 16.449886\n",
      "Iteration 8238 => Loss: 16.448818\n",
      "Iteration 8239 => Loss: 16.447752\n",
      "Iteration 8240 => Loss: 16.447728\n",
      "Iteration 8241 => Loss: 16.446639\n",
      "Iteration 8242 => Loss: 16.445552\n",
      "Iteration 8243 => Loss: 16.444467\n",
      "Iteration 8244 => Loss: 16.443384\n",
      "Iteration 8245 => Loss: 16.442303\n",
      "Iteration 8246 => Loss: 16.441224\n",
      "Iteration 8247 => Loss: 16.440147\n",
      "Iteration 8248 => Loss: 16.439072\n",
      "Iteration 8249 => Loss: 16.437999\n",
      "Iteration 8250 => Loss: 16.436928\n",
      "Iteration 8251 => Loss: 16.435859\n",
      "Iteration 8252 => Loss: 16.434792\n",
      "Iteration 8253 => Loss: 16.433727\n",
      "Iteration 8254 => Loss: 16.432664\n",
      "Iteration 8255 => Loss: 16.431603\n",
      "Iteration 8256 => Loss: 16.430544\n",
      "Iteration 8257 => Loss: 16.429487\n",
      "Iteration 8258 => Loss: 16.429470\n",
      "Iteration 8259 => Loss: 16.428390\n",
      "Iteration 8260 => Loss: 16.427311\n",
      "Iteration 8261 => Loss: 16.426235\n",
      "Iteration 8262 => Loss: 16.425161\n",
      "Iteration 8263 => Loss: 16.424088\n",
      "Iteration 8264 => Loss: 16.423018\n",
      "Iteration 8265 => Loss: 16.421950\n",
      "Iteration 8266 => Loss: 16.420883\n",
      "Iteration 8267 => Loss: 16.419819\n",
      "Iteration 8268 => Loss: 16.418757\n",
      "Iteration 8269 => Loss: 16.417696\n",
      "Iteration 8270 => Loss: 16.416638\n",
      "Iteration 8271 => Loss: 16.415582\n",
      "Iteration 8272 => Loss: 16.414527\n",
      "Iteration 8273 => Loss: 16.413475\n",
      "Iteration 8274 => Loss: 16.412425\n",
      "Iteration 8275 => Loss: 16.411376\n",
      "Iteration 8276 => Loss: 16.411366\n",
      "Iteration 8277 => Loss: 16.410295\n",
      "Iteration 8278 => Loss: 16.409225\n",
      "Iteration 8279 => Loss: 16.408157\n",
      "Iteration 8280 => Loss: 16.407092\n",
      "Iteration 8281 => Loss: 16.406028\n",
      "Iteration 8282 => Loss: 16.404966\n",
      "Iteration 8283 => Loss: 16.403907\n",
      "Iteration 8284 => Loss: 16.402849\n",
      "Iteration 8285 => Loss: 16.401793\n",
      "Iteration 8286 => Loss: 16.400740\n",
      "Iteration 8287 => Loss: 16.399688\n",
      "Iteration 8288 => Loss: 16.398638\n",
      "Iteration 8289 => Loss: 16.397591\n",
      "Iteration 8290 => Loss: 16.396545\n",
      "Iteration 8291 => Loss: 16.395501\n",
      "Iteration 8292 => Loss: 16.394460\n",
      "Iteration 8293 => Loss: 16.393420\n",
      "Iteration 8294 => Loss: 16.393417\n",
      "Iteration 8295 => Loss: 16.392354\n",
      "Iteration 8296 => Loss: 16.391293\n",
      "Iteration 8297 => Loss: 16.390234\n",
      "Iteration 8298 => Loss: 16.389177\n",
      "Iteration 8299 => Loss: 16.388122\n",
      "Iteration 8300 => Loss: 16.387069\n",
      "Iteration 8301 => Loss: 16.386018\n",
      "Iteration 8302 => Loss: 16.384969\n",
      "Iteration 8303 => Loss: 16.383922\n",
      "Iteration 8304 => Loss: 16.382877\n",
      "Iteration 8305 => Loss: 16.381834\n",
      "Iteration 8306 => Loss: 16.380793\n",
      "Iteration 8307 => Loss: 16.379754\n",
      "Iteration 8308 => Loss: 16.378717\n",
      "Iteration 8309 => Loss: 16.377682\n",
      "Iteration 8310 => Loss: 16.376649\n",
      "Iteration 8311 => Loss: 16.375618\n",
      "Iteration 8312 => Loss: 16.374589\n",
      "Iteration 8313 => Loss: 16.374567\n",
      "Iteration 8314 => Loss: 16.373514\n",
      "Iteration 8315 => Loss: 16.372464\n",
      "Iteration 8316 => Loss: 16.371416\n",
      "Iteration 8317 => Loss: 16.370369\n",
      "Iteration 8318 => Loss: 16.369325\n",
      "Iteration 8319 => Loss: 16.368283\n",
      "Iteration 8320 => Loss: 16.367242\n",
      "Iteration 8321 => Loss: 16.366204\n",
      "Iteration 8322 => Loss: 16.365168\n",
      "Iteration 8323 => Loss: 16.364133\n",
      "Iteration 8324 => Loss: 16.363101\n",
      "Iteration 8325 => Loss: 16.362071\n",
      "Iteration 8326 => Loss: 16.361042\n",
      "Iteration 8327 => Loss: 16.360016\n",
      "Iteration 8328 => Loss: 16.358992\n",
      "Iteration 8329 => Loss: 16.357969\n",
      "Iteration 8330 => Loss: 16.356949\n",
      "Iteration 8331 => Loss: 16.356934\n",
      "Iteration 8332 => Loss: 16.355891\n",
      "Iteration 8333 => Loss: 16.354849\n",
      "Iteration 8334 => Loss: 16.353809\n",
      "Iteration 8335 => Loss: 16.352772\n",
      "Iteration 8336 => Loss: 16.351736\n",
      "Iteration 8337 => Loss: 16.350702\n",
      "Iteration 8338 => Loss: 16.349671\n",
      "Iteration 8339 => Loss: 16.348641\n",
      "Iteration 8340 => Loss: 16.347613\n",
      "Iteration 8341 => Loss: 16.346588\n",
      "Iteration 8342 => Loss: 16.345564\n",
      "Iteration 8343 => Loss: 16.344542\n",
      "Iteration 8344 => Loss: 16.343523\n",
      "Iteration 8345 => Loss: 16.342505\n",
      "Iteration 8346 => Loss: 16.341489\n",
      "Iteration 8347 => Loss: 16.340476\n",
      "Iteration 8348 => Loss: 16.339464\n",
      "Iteration 8349 => Loss: 16.339456\n",
      "Iteration 8350 => Loss: 16.338421\n",
      "Iteration 8351 => Loss: 16.337388\n",
      "Iteration 8352 => Loss: 16.336357\n",
      "Iteration 8353 => Loss: 16.335328\n",
      "Iteration 8354 => Loss: 16.334301\n",
      "Iteration 8355 => Loss: 16.333276\n",
      "Iteration 8356 => Loss: 16.332253\n",
      "Iteration 8357 => Loss: 16.331232\n",
      "Iteration 8358 => Loss: 16.330213\n",
      "Iteration 8359 => Loss: 16.329196\n",
      "Iteration 8360 => Loss: 16.328181\n",
      "Iteration 8361 => Loss: 16.327168\n",
      "Iteration 8362 => Loss: 16.326157\n",
      "Iteration 8363 => Loss: 16.325148\n",
      "Iteration 8364 => Loss: 16.324141\n",
      "Iteration 8365 => Loss: 16.323136\n",
      "Iteration 8366 => Loss: 16.322133\n",
      "Iteration 8367 => Loss: 16.322132\n",
      "Iteration 8368 => Loss: 16.321106\n",
      "Iteration 8369 => Loss: 16.320082\n",
      "Iteration 8370 => Loss: 16.319059\n",
      "Iteration 8371 => Loss: 16.318039\n",
      "Iteration 8372 => Loss: 16.317021\n",
      "Iteration 8373 => Loss: 16.316004\n",
      "Iteration 8374 => Loss: 16.314990\n",
      "Iteration 8375 => Loss: 16.313978\n",
      "Iteration 8376 => Loss: 16.312967\n",
      "Iteration 8377 => Loss: 16.311959\n",
      "Iteration 8378 => Loss: 16.310953\n",
      "Iteration 8379 => Loss: 16.309948\n",
      "Iteration 8380 => Loss: 16.308946\n",
      "Iteration 8381 => Loss: 16.307946\n",
      "Iteration 8382 => Loss: 16.306947\n",
      "Iteration 8383 => Loss: 16.305951\n",
      "Iteration 8384 => Loss: 16.304957\n",
      "Iteration 8385 => Loss: 16.303964\n",
      "Iteration 8386 => Loss: 16.303945\n",
      "Iteration 8387 => Loss: 16.302929\n",
      "Iteration 8388 => Loss: 16.301916\n",
      "Iteration 8389 => Loss: 16.300904\n",
      "Iteration 8390 => Loss: 16.299894\n",
      "Iteration 8391 => Loss: 16.298887\n",
      "Iteration 8392 => Loss: 16.297881\n",
      "Iteration 8393 => Loss: 16.296877\n",
      "Iteration 8394 => Loss: 16.295876\n",
      "Iteration 8395 => Loss: 16.294876\n",
      "Iteration 8396 => Loss: 16.293878\n",
      "Iteration 8397 => Loss: 16.292883\n",
      "Iteration 8398 => Loss: 16.291889\n",
      "Iteration 8399 => Loss: 16.290897\n",
      "Iteration 8400 => Loss: 16.289908\n",
      "Iteration 8401 => Loss: 16.288920\n",
      "Iteration 8402 => Loss: 16.287934\n",
      "Iteration 8403 => Loss: 16.286951\n",
      "Iteration 8404 => Loss: 16.286938\n",
      "Iteration 8405 => Loss: 16.285931\n",
      "Iteration 8406 => Loss: 16.284926\n",
      "Iteration 8407 => Loss: 16.283923\n",
      "Iteration 8408 => Loss: 16.282922\n",
      "Iteration 8409 => Loss: 16.281923\n",
      "Iteration 8410 => Loss: 16.280926\n",
      "Iteration 8411 => Loss: 16.279931\n",
      "Iteration 8412 => Loss: 16.278938\n",
      "Iteration 8413 => Loss: 16.277947\n",
      "Iteration 8414 => Loss: 16.276958\n",
      "Iteration 8415 => Loss: 16.275971\n",
      "Iteration 8416 => Loss: 16.274986\n",
      "Iteration 8417 => Loss: 16.274003\n",
      "Iteration 8418 => Loss: 16.273022\n",
      "Iteration 8419 => Loss: 16.272043\n",
      "Iteration 8420 => Loss: 16.271066\n",
      "Iteration 8421 => Loss: 16.270091\n",
      "Iteration 8422 => Loss: 16.270086\n",
      "Iteration 8423 => Loss: 16.269087\n",
      "Iteration 8424 => Loss: 16.268091\n",
      "Iteration 8425 => Loss: 16.267097\n",
      "Iteration 8426 => Loss: 16.266104\n",
      "Iteration 8427 => Loss: 16.265114\n",
      "Iteration 8428 => Loss: 16.264126\n",
      "Iteration 8429 => Loss: 16.263139\n",
      "Iteration 8430 => Loss: 16.262155\n",
      "Iteration 8431 => Loss: 16.261173\n",
      "Iteration 8432 => Loss: 16.260192\n",
      "Iteration 8433 => Loss: 16.259214\n",
      "Iteration 8434 => Loss: 16.258238\n",
      "Iteration 8435 => Loss: 16.257263\n",
      "Iteration 8436 => Loss: 16.256291\n",
      "Iteration 8437 => Loss: 16.255321\n",
      "Iteration 8438 => Loss: 16.254352\n",
      "Iteration 8439 => Loss: 16.253386\n",
      "Iteration 8440 => Loss: 16.252422\n",
      "Iteration 8441 => Loss: 16.252398\n",
      "Iteration 8442 => Loss: 16.251410\n",
      "Iteration 8443 => Loss: 16.250424\n",
      "Iteration 8444 => Loss: 16.249441\n",
      "Iteration 8445 => Loss: 16.248459\n",
      "Iteration 8446 => Loss: 16.247479\n",
      "Iteration 8447 => Loss: 16.246502\n",
      "Iteration 8448 => Loss: 16.245526\n",
      "Iteration 8449 => Loss: 16.244552\n",
      "Iteration 8450 => Loss: 16.243581\n",
      "Iteration 8451 => Loss: 16.242611\n",
      "Iteration 8452 => Loss: 16.241643\n",
      "Iteration 8453 => Loss: 16.240678\n",
      "Iteration 8454 => Loss: 16.239714\n",
      "Iteration 8455 => Loss: 16.238752\n",
      "Iteration 8456 => Loss: 16.237793\n",
      "Iteration 8457 => Loss: 16.236835\n",
      "Iteration 8458 => Loss: 16.235879\n",
      "Iteration 8459 => Loss: 16.235863\n",
      "Iteration 8460 => Loss: 16.234884\n",
      "Iteration 8461 => Loss: 16.233907\n",
      "Iteration 8462 => Loss: 16.232932\n",
      "Iteration 8463 => Loss: 16.231959\n",
      "Iteration 8464 => Loss: 16.230988\n",
      "Iteration 8465 => Loss: 16.230019\n",
      "Iteration 8466 => Loss: 16.229052\n",
      "Iteration 8467 => Loss: 16.228087\n",
      "Iteration 8468 => Loss: 16.227124\n",
      "Iteration 8469 => Loss: 16.226163\n",
      "Iteration 8470 => Loss: 16.225204\n",
      "Iteration 8471 => Loss: 16.224247\n",
      "Iteration 8472 => Loss: 16.223292\n",
      "Iteration 8473 => Loss: 16.222339\n",
      "Iteration 8474 => Loss: 16.221388\n",
      "Iteration 8475 => Loss: 16.220439\n",
      "Iteration 8476 => Loss: 16.219492\n",
      "Iteration 8477 => Loss: 16.219482\n",
      "Iteration 8478 => Loss: 16.218511\n",
      "Iteration 8479 => Loss: 16.217543\n",
      "Iteration 8480 => Loss: 16.216577\n",
      "Iteration 8481 => Loss: 16.215612\n",
      "Iteration 8482 => Loss: 16.214650\n",
      "Iteration 8483 => Loss: 16.213690\n",
      "Iteration 8484 => Loss: 16.212731\n",
      "Iteration 8485 => Loss: 16.211775\n",
      "Iteration 8486 => Loss: 16.210821\n",
      "Iteration 8487 => Loss: 16.209868\n",
      "Iteration 8488 => Loss: 16.208918\n",
      "Iteration 8489 => Loss: 16.207970\n",
      "Iteration 8490 => Loss: 16.207023\n",
      "Iteration 8491 => Loss: 16.206079\n",
      "Iteration 8492 => Loss: 16.205137\n",
      "Iteration 8493 => Loss: 16.204196\n",
      "Iteration 8494 => Loss: 16.203258\n",
      "Iteration 8495 => Loss: 16.203255\n",
      "Iteration 8496 => Loss: 16.202293\n",
      "Iteration 8497 => Loss: 16.201333\n",
      "Iteration 8498 => Loss: 16.200376\n",
      "Iteration 8499 => Loss: 16.199420\n",
      "Iteration 8500 => Loss: 16.198466\n",
      "Iteration 8501 => Loss: 16.197515\n",
      "Iteration 8502 => Loss: 16.196565\n",
      "Iteration 8503 => Loss: 16.195617\n",
      "Iteration 8504 => Loss: 16.194672\n",
      "Iteration 8505 => Loss: 16.193728\n",
      "Iteration 8506 => Loss: 16.192786\n",
      "Iteration 8507 => Loss: 16.191847\n",
      "Iteration 8508 => Loss: 16.190909\n",
      "Iteration 8509 => Loss: 16.189973\n",
      "Iteration 8510 => Loss: 16.189040\n",
      "Iteration 8511 => Loss: 16.188108\n",
      "Iteration 8512 => Loss: 16.187178\n",
      "Iteration 8513 => Loss: 16.186251\n",
      "Iteration 8514 => Loss: 16.186229\n",
      "Iteration 8515 => Loss: 16.185278\n",
      "Iteration 8516 => Loss: 16.184329\n",
      "Iteration 8517 => Loss: 16.183382\n",
      "Iteration 8518 => Loss: 16.182437\n",
      "Iteration 8519 => Loss: 16.181494\n",
      "Iteration 8520 => Loss: 16.180553\n",
      "Iteration 8521 => Loss: 16.179614\n",
      "Iteration 8522 => Loss: 16.178677\n",
      "Iteration 8523 => Loss: 16.177742\n",
      "Iteration 8524 => Loss: 16.176809\n",
      "Iteration 8525 => Loss: 16.175878\n",
      "Iteration 8526 => Loss: 16.174949\n",
      "Iteration 8527 => Loss: 16.174022\n",
      "Iteration 8528 => Loss: 16.173097\n",
      "Iteration 8529 => Loss: 16.172174\n",
      "Iteration 8530 => Loss: 16.171253\n",
      "Iteration 8531 => Loss: 16.170334\n",
      "Iteration 8532 => Loss: 16.170320\n",
      "Iteration 8533 => Loss: 16.169377\n",
      "Iteration 8534 => Loss: 16.168437\n",
      "Iteration 8535 => Loss: 16.167499\n",
      "Iteration 8536 => Loss: 16.166562\n",
      "Iteration 8537 => Loss: 16.165628\n",
      "Iteration 8538 => Loss: 16.164696\n",
      "Iteration 8539 => Loss: 16.163765\n",
      "Iteration 8540 => Loss: 16.162837\n",
      "Iteration 8541 => Loss: 16.161911\n",
      "Iteration 8542 => Loss: 16.160986\n",
      "Iteration 8543 => Loss: 16.160064\n",
      "Iteration 8544 => Loss: 16.159144\n",
      "Iteration 8545 => Loss: 16.158225\n",
      "Iteration 8546 => Loss: 16.157309\n",
      "Iteration 8547 => Loss: 16.156395\n",
      "Iteration 8548 => Loss: 16.155482\n",
      "Iteration 8549 => Loss: 16.154572\n",
      "Iteration 8550 => Loss: 16.154565\n",
      "Iteration 8551 => Loss: 16.153631\n",
      "Iteration 8552 => Loss: 16.152699\n",
      "Iteration 8553 => Loss: 16.151770\n",
      "Iteration 8554 => Loss: 16.150842\n",
      "Iteration 8555 => Loss: 16.149916\n",
      "Iteration 8556 => Loss: 16.148993\n",
      "Iteration 8557 => Loss: 16.148071\n",
      "Iteration 8558 => Loss: 16.147151\n",
      "Iteration 8559 => Loss: 16.146234\n",
      "Iteration 8560 => Loss: 16.145318\n",
      "Iteration 8561 => Loss: 16.144404\n",
      "Iteration 8562 => Loss: 16.143493\n",
      "Iteration 8563 => Loss: 16.142583\n",
      "Iteration 8564 => Loss: 16.141675\n",
      "Iteration 8565 => Loss: 16.140770\n",
      "Iteration 8566 => Loss: 16.139866\n",
      "Iteration 8567 => Loss: 16.138964\n",
      "Iteration 8568 => Loss: 16.138964\n",
      "Iteration 8569 => Loss: 16.138039\n",
      "Iteration 8570 => Loss: 16.137116\n",
      "Iteration 8571 => Loss: 16.136195\n",
      "Iteration 8572 => Loss: 16.135276\n",
      "Iteration 8573 => Loss: 16.134359\n",
      "Iteration 8574 => Loss: 16.133444\n",
      "Iteration 8575 => Loss: 16.132531\n",
      "Iteration 8576 => Loss: 16.131620\n",
      "Iteration 8577 => Loss: 16.130711\n",
      "Iteration 8578 => Loss: 16.129804\n",
      "Iteration 8579 => Loss: 16.128899\n",
      "Iteration 8580 => Loss: 16.127996\n",
      "Iteration 8581 => Loss: 16.127095\n",
      "Iteration 8582 => Loss: 16.126196\n",
      "Iteration 8583 => Loss: 16.125299\n",
      "Iteration 8584 => Loss: 16.124404\n",
      "Iteration 8585 => Loss: 16.123511\n",
      "Iteration 8586 => Loss: 16.122620\n",
      "Iteration 8587 => Loss: 16.122600\n",
      "Iteration 8588 => Loss: 16.121686\n",
      "Iteration 8589 => Loss: 16.120774\n",
      "Iteration 8590 => Loss: 16.119863\n",
      "Iteration 8591 => Loss: 16.118955\n",
      "Iteration 8592 => Loss: 16.118049\n",
      "Iteration 8593 => Loss: 16.117144\n",
      "Iteration 8594 => Loss: 16.116242\n",
      "Iteration 8595 => Loss: 16.115342\n",
      "Iteration 8596 => Loss: 16.114443\n",
      "Iteration 8597 => Loss: 16.113547\n",
      "Iteration 8598 => Loss: 16.112653\n",
      "Iteration 8599 => Loss: 16.111760\n",
      "Iteration 8600 => Loss: 16.110870\n",
      "Iteration 8601 => Loss: 16.109982\n",
      "Iteration 8602 => Loss: 16.109095\n",
      "Iteration 8603 => Loss: 16.108211\n",
      "Iteration 8604 => Loss: 16.107329\n",
      "Iteration 8605 => Loss: 16.107317\n",
      "Iteration 8606 => Loss: 16.106411\n",
      "Iteration 8607 => Loss: 16.105507\n",
      "Iteration 8608 => Loss: 16.104606\n",
      "Iteration 8609 => Loss: 16.103706\n",
      "Iteration 8610 => Loss: 16.102808\n",
      "Iteration 8611 => Loss: 16.101913\n",
      "Iteration 8612 => Loss: 16.101019\n",
      "Iteration 8613 => Loss: 16.100127\n",
      "Iteration 8614 => Loss: 16.099238\n",
      "Iteration 8615 => Loss: 16.098350\n",
      "Iteration 8616 => Loss: 16.097464\n",
      "Iteration 8617 => Loss: 16.096581\n",
      "Iteration 8618 => Loss: 16.095699\n",
      "Iteration 8619 => Loss: 16.094819\n",
      "Iteration 8620 => Loss: 16.093942\n",
      "Iteration 8621 => Loss: 16.093066\n",
      "Iteration 8622 => Loss: 16.092192\n",
      "Iteration 8623 => Loss: 16.092187\n",
      "Iteration 8624 => Loss: 16.091290\n",
      "Iteration 8625 => Loss: 16.090395\n",
      "Iteration 8626 => Loss: 16.089502\n",
      "Iteration 8627 => Loss: 16.088611\n",
      "Iteration 8628 => Loss: 16.087722\n",
      "Iteration 8629 => Loss: 16.086835\n",
      "Iteration 8630 => Loss: 16.085950\n",
      "Iteration 8631 => Loss: 16.085067\n",
      "Iteration 8632 => Loss: 16.084186\n",
      "Iteration 8633 => Loss: 16.083307\n",
      "Iteration 8634 => Loss: 16.082430\n",
      "Iteration 8635 => Loss: 16.081555\n",
      "Iteration 8636 => Loss: 16.080682\n",
      "Iteration 8637 => Loss: 16.079811\n",
      "Iteration 8638 => Loss: 16.078942\n",
      "Iteration 8639 => Loss: 16.078075\n",
      "Iteration 8640 => Loss: 16.077210\n",
      "Iteration 8641 => Loss: 16.076347\n",
      "Iteration 8642 => Loss: 16.076324\n",
      "Iteration 8643 => Loss: 16.075437\n",
      "Iteration 8644 => Loss: 16.074553\n",
      "Iteration 8645 => Loss: 16.073671\n",
      "Iteration 8646 => Loss: 16.072790\n",
      "Iteration 8647 => Loss: 16.071912\n",
      "Iteration 8648 => Loss: 16.071036\n",
      "Iteration 8649 => Loss: 16.070161\n",
      "Iteration 8650 => Loss: 16.069289\n",
      "Iteration 8651 => Loss: 16.068419\n",
      "Iteration 8652 => Loss: 16.067550\n",
      "Iteration 8653 => Loss: 16.066684\n",
      "Iteration 8654 => Loss: 16.065820\n",
      "Iteration 8655 => Loss: 16.064957\n",
      "Iteration 8656 => Loss: 16.064097\n",
      "Iteration 8657 => Loss: 16.063239\n",
      "Iteration 8658 => Loss: 16.062382\n",
      "Iteration 8659 => Loss: 16.061528\n",
      "Iteration 8660 => Loss: 16.061511\n",
      "Iteration 8661 => Loss: 16.060634\n",
      "Iteration 8662 => Loss: 16.059758\n",
      "Iteration 8663 => Loss: 16.058884\n",
      "Iteration 8664 => Loss: 16.058013\n",
      "Iteration 8665 => Loss: 16.057143\n",
      "Iteration 8666 => Loss: 16.056275\n",
      "Iteration 8667 => Loss: 16.055410\n",
      "Iteration 8668 => Loss: 16.054546\n",
      "Iteration 8669 => Loss: 16.053684\n",
      "Iteration 8670 => Loss: 16.052825\n",
      "Iteration 8671 => Loss: 16.051967\n",
      "Iteration 8672 => Loss: 16.051111\n",
      "Iteration 8673 => Loss: 16.050258\n",
      "Iteration 8674 => Loss: 16.049406\n",
      "Iteration 8675 => Loss: 16.048556\n",
      "Iteration 8676 => Loss: 16.047709\n",
      "Iteration 8677 => Loss: 16.046863\n",
      "Iteration 8678 => Loss: 16.046853\n",
      "Iteration 8679 => Loss: 16.045984\n",
      "Iteration 8680 => Loss: 16.045117\n",
      "Iteration 8681 => Loss: 16.044252\n",
      "Iteration 8682 => Loss: 16.043389\n",
      "Iteration 8683 => Loss: 16.042528\n",
      "Iteration 8684 => Loss: 16.041669\n",
      "Iteration 8685 => Loss: 16.040812\n",
      "Iteration 8686 => Loss: 16.039957\n",
      "Iteration 8687 => Loss: 16.039104\n",
      "Iteration 8688 => Loss: 16.038253\n",
      "Iteration 8689 => Loss: 16.037404\n",
      "Iteration 8690 => Loss: 16.036557\n",
      "Iteration 8691 => Loss: 16.035712\n",
      "Iteration 8692 => Loss: 16.034869\n",
      "Iteration 8693 => Loss: 16.034028\n",
      "Iteration 8694 => Loss: 16.033189\n",
      "Iteration 8695 => Loss: 16.032352\n",
      "Iteration 8696 => Loss: 16.032349\n",
      "Iteration 8697 => Loss: 16.031489\n",
      "Iteration 8698 => Loss: 16.030631\n",
      "Iteration 8699 => Loss: 16.029774\n",
      "Iteration 8700 => Loss: 16.028920\n",
      "Iteration 8701 => Loss: 16.028068\n",
      "Iteration 8702 => Loss: 16.027217\n",
      "Iteration 8703 => Loss: 16.026369\n",
      "Iteration 8704 => Loss: 16.025523\n",
      "Iteration 8705 => Loss: 16.024678\n",
      "Iteration 8706 => Loss: 16.023836\n",
      "Iteration 8707 => Loss: 16.022996\n",
      "Iteration 8708 => Loss: 16.022157\n",
      "Iteration 8709 => Loss: 16.021321\n",
      "Iteration 8710 => Loss: 16.020487\n",
      "Iteration 8711 => Loss: 16.019654\n",
      "Iteration 8712 => Loss: 16.018824\n",
      "Iteration 8713 => Loss: 16.017996\n",
      "Iteration 8714 => Loss: 16.017169\n",
      "Iteration 8715 => Loss: 16.017148\n",
      "Iteration 8716 => Loss: 16.016298\n",
      "Iteration 8717 => Loss: 16.015451\n",
      "Iteration 8718 => Loss: 16.014605\n",
      "Iteration 8719 => Loss: 16.013761\n",
      "Iteration 8720 => Loss: 16.012920\n",
      "Iteration 8721 => Loss: 16.012080\n",
      "Iteration 8722 => Loss: 16.011242\n",
      "Iteration 8723 => Loss: 16.010407\n",
      "Iteration 8724 => Loss: 16.009573\n",
      "Iteration 8725 => Loss: 16.008741\n",
      "Iteration 8726 => Loss: 16.007912\n",
      "Iteration 8727 => Loss: 16.007084\n",
      "Iteration 8728 => Loss: 16.006258\n",
      "Iteration 8729 => Loss: 16.005435\n",
      "Iteration 8730 => Loss: 16.004613\n",
      "Iteration 8731 => Loss: 16.003793\n",
      "Iteration 8732 => Loss: 16.002976\n",
      "Iteration 8733 => Loss: 16.002962\n",
      "Iteration 8734 => Loss: 16.002121\n",
      "Iteration 8735 => Loss: 16.001282\n",
      "Iteration 8736 => Loss: 16.000445\n",
      "Iteration 8737 => Loss: 15.999610\n",
      "Iteration 8738 => Loss: 15.998777\n",
      "Iteration 8739 => Loss: 15.997946\n",
      "Iteration 8740 => Loss: 15.997117\n",
      "Iteration 8741 => Loss: 15.996290\n",
      "Iteration 8742 => Loss: 15.995465\n",
      "Iteration 8743 => Loss: 15.994642\n",
      "Iteration 8744 => Loss: 15.993821\n",
      "Iteration 8745 => Loss: 15.993002\n",
      "Iteration 8746 => Loss: 15.992185\n",
      "Iteration 8747 => Loss: 15.991370\n",
      "Iteration 8748 => Loss: 15.990557\n",
      "Iteration 8749 => Loss: 15.989746\n",
      "Iteration 8750 => Loss: 15.988937\n",
      "Iteration 8751 => Loss: 15.988929\n",
      "Iteration 8752 => Loss: 15.988097\n",
      "Iteration 8753 => Loss: 15.987267\n",
      "Iteration 8754 => Loss: 15.986438\n",
      "Iteration 8755 => Loss: 15.985612\n",
      "Iteration 8756 => Loss: 15.984788\n",
      "Iteration 8757 => Loss: 15.983965\n",
      "Iteration 8758 => Loss: 15.983145\n",
      "Iteration 8759 => Loss: 15.982327\n",
      "Iteration 8760 => Loss: 15.981510\n",
      "Iteration 8761 => Loss: 15.980696\n",
      "Iteration 8762 => Loss: 15.979884\n",
      "Iteration 8763 => Loss: 15.979073\n",
      "Iteration 8764 => Loss: 15.978265\n",
      "Iteration 8765 => Loss: 15.977459\n",
      "Iteration 8766 => Loss: 15.976654\n",
      "Iteration 8767 => Loss: 15.975852\n",
      "Iteration 8768 => Loss: 15.975052\n",
      "Iteration 8769 => Loss: 15.975051\n",
      "Iteration 8770 => Loss: 15.974227\n",
      "Iteration 8771 => Loss: 15.973406\n",
      "Iteration 8772 => Loss: 15.972586\n",
      "Iteration 8773 => Loss: 15.971768\n",
      "Iteration 8774 => Loss: 15.970953\n",
      "Iteration 8775 => Loss: 15.970139\n",
      "Iteration 8776 => Loss: 15.969327\n",
      "Iteration 8777 => Loss: 15.968518\n",
      "Iteration 8778 => Loss: 15.967710\n",
      "Iteration 8779 => Loss: 15.966904\n",
      "Iteration 8780 => Loss: 15.966101\n",
      "Iteration 8781 => Loss: 15.965299\n",
      "Iteration 8782 => Loss: 15.964499\n",
      "Iteration 8783 => Loss: 15.963702\n",
      "Iteration 8784 => Loss: 15.962906\n",
      "Iteration 8785 => Loss: 15.962112\n",
      "Iteration 8786 => Loss: 15.961321\n",
      "Iteration 8787 => Loss: 15.960531\n",
      "Iteration 8788 => Loss: 15.960512\n",
      "Iteration 8789 => Loss: 15.959699\n",
      "Iteration 8790 => Loss: 15.958888\n",
      "Iteration 8791 => Loss: 15.958079\n",
      "Iteration 8792 => Loss: 15.957272\n",
      "Iteration 8793 => Loss: 15.956467\n",
      "Iteration 8794 => Loss: 15.955664\n",
      "Iteration 8795 => Loss: 15.954863\n",
      "Iteration 8796 => Loss: 15.954064\n",
      "Iteration 8797 => Loss: 15.953267\n",
      "Iteration 8798 => Loss: 15.952472\n",
      "Iteration 8799 => Loss: 15.951679\n",
      "Iteration 8800 => Loss: 15.950888\n",
      "Iteration 8801 => Loss: 15.950099\n",
      "Iteration 8802 => Loss: 15.949312\n",
      "Iteration 8803 => Loss: 15.948527\n",
      "Iteration 8804 => Loss: 15.947744\n",
      "Iteration 8805 => Loss: 15.946963\n",
      "Iteration 8806 => Loss: 15.946951\n",
      "Iteration 8807 => Loss: 15.946147\n",
      "Iteration 8808 => Loss: 15.945345\n",
      "Iteration 8809 => Loss: 15.944544\n",
      "Iteration 8810 => Loss: 15.943746\n",
      "Iteration 8811 => Loss: 15.942950\n",
      "Iteration 8812 => Loss: 15.942155\n",
      "Iteration 8813 => Loss: 15.941363\n",
      "Iteration 8814 => Loss: 15.940573\n",
      "Iteration 8815 => Loss: 15.939784\n",
      "Iteration 8816 => Loss: 15.938998\n",
      "Iteration 8817 => Loss: 15.938214\n",
      "Iteration 8818 => Loss: 15.937431\n",
      "Iteration 8819 => Loss: 15.936651\n",
      "Iteration 8820 => Loss: 15.935873\n",
      "Iteration 8821 => Loss: 15.935096\n",
      "Iteration 8822 => Loss: 15.934322\n",
      "Iteration 8823 => Loss: 15.933550\n",
      "Iteration 8824 => Loss: 15.933545\n",
      "Iteration 8825 => Loss: 15.932749\n",
      "Iteration 8826 => Loss: 15.931956\n",
      "Iteration 8827 => Loss: 15.931164\n",
      "Iteration 8828 => Loss: 15.930374\n",
      "Iteration 8829 => Loss: 15.929587\n",
      "Iteration 8830 => Loss: 15.928801\n",
      "Iteration 8831 => Loss: 15.928017\n",
      "Iteration 8832 => Loss: 15.927236\n",
      "Iteration 8833 => Loss: 15.926456\n",
      "Iteration 8834 => Loss: 15.925678\n",
      "Iteration 8835 => Loss: 15.924903\n",
      "Iteration 8836 => Loss: 15.924129\n",
      "Iteration 8837 => Loss: 15.923357\n",
      "Iteration 8838 => Loss: 15.922588\n",
      "Iteration 8839 => Loss: 15.921820\n",
      "Iteration 8840 => Loss: 15.921054\n",
      "Iteration 8841 => Loss: 15.920291\n",
      "Iteration 8842 => Loss: 15.919529\n",
      "Iteration 8843 => Loss: 15.919506\n",
      "Iteration 8844 => Loss: 15.918721\n",
      "Iteration 8845 => Loss: 15.917938\n",
      "Iteration 8846 => Loss: 15.917157\n",
      "Iteration 8847 => Loss: 15.916378\n",
      "Iteration 8848 => Loss: 15.915601\n",
      "Iteration 8849 => Loss: 15.914826\n",
      "Iteration 8850 => Loss: 15.914053\n",
      "Iteration 8851 => Loss: 15.913282\n",
      "Iteration 8852 => Loss: 15.912513\n",
      "Iteration 8853 => Loss: 15.911746\n",
      "Iteration 8854 => Loss: 15.910981\n",
      "Iteration 8855 => Loss: 15.910218\n",
      "Iteration 8856 => Loss: 15.909457\n",
      "Iteration 8857 => Loss: 15.908698\n",
      "Iteration 8858 => Loss: 15.907941\n",
      "Iteration 8859 => Loss: 15.907186\n",
      "Iteration 8860 => Loss: 15.906433\n",
      "Iteration 8861 => Loss: 15.906416\n",
      "Iteration 8862 => Loss: 15.905640\n",
      "Iteration 8863 => Loss: 15.904865\n",
      "Iteration 8864 => Loss: 15.904093\n",
      "Iteration 8865 => Loss: 15.903323\n",
      "Iteration 8866 => Loss: 15.902554\n",
      "Iteration 8867 => Loss: 15.901788\n",
      "Iteration 8868 => Loss: 15.901024\n",
      "Iteration 8869 => Loss: 15.900261\n",
      "Iteration 8870 => Loss: 15.899501\n",
      "Iteration 8871 => Loss: 15.898743\n",
      "Iteration 8872 => Loss: 15.897986\n",
      "Iteration 8873 => Loss: 15.897232\n",
      "Iteration 8874 => Loss: 15.896480\n",
      "Iteration 8875 => Loss: 15.895729\n",
      "Iteration 8876 => Loss: 15.894981\n",
      "Iteration 8877 => Loss: 15.894235\n",
      "Iteration 8878 => Loss: 15.893490\n",
      "Iteration 8879 => Loss: 15.893481\n",
      "Iteration 8880 => Loss: 15.892713\n",
      "Iteration 8881 => Loss: 15.891948\n",
      "Iteration 8882 => Loss: 15.891184\n",
      "Iteration 8883 => Loss: 15.890422\n",
      "Iteration 8884 => Loss: 15.889663\n",
      "Iteration 8885 => Loss: 15.888905\n",
      "Iteration 8886 => Loss: 15.888149\n",
      "Iteration 8887 => Loss: 15.887396\n",
      "Iteration 8888 => Loss: 15.886644\n",
      "Iteration 8889 => Loss: 15.885894\n",
      "Iteration 8890 => Loss: 15.885147\n",
      "Iteration 8891 => Loss: 15.884401\n",
      "Iteration 8892 => Loss: 15.883657\n",
      "Iteration 8893 => Loss: 15.882916\n",
      "Iteration 8894 => Loss: 15.882176\n",
      "Iteration 8895 => Loss: 15.881438\n",
      "Iteration 8896 => Loss: 15.880703\n",
      "Iteration 8897 => Loss: 15.880700\n",
      "Iteration 8898 => Loss: 15.879941\n",
      "Iteration 8899 => Loss: 15.879184\n",
      "Iteration 8900 => Loss: 15.878429\n",
      "Iteration 8901 => Loss: 15.877676\n",
      "Iteration 8902 => Loss: 15.876925\n",
      "Iteration 8903 => Loss: 15.876176\n",
      "Iteration 8904 => Loss: 15.875429\n",
      "Iteration 8905 => Loss: 15.874684\n",
      "Iteration 8906 => Loss: 15.873941\n",
      "Iteration 8907 => Loss: 15.873200\n",
      "Iteration 8908 => Loss: 15.872461\n",
      "Iteration 8909 => Loss: 15.871724\n",
      "Iteration 8910 => Loss: 15.870989\n",
      "Iteration 8911 => Loss: 15.870256\n",
      "Iteration 8912 => Loss: 15.869525\n",
      "Iteration 8913 => Loss: 15.868796\n",
      "Iteration 8914 => Loss: 15.868069\n",
      "Iteration 8915 => Loss: 15.867344\n",
      "Iteration 8916 => Loss: 15.867323\n",
      "Iteration 8917 => Loss: 15.866575\n",
      "Iteration 8918 => Loss: 15.865829\n",
      "Iteration 8919 => Loss: 15.865084\n",
      "Iteration 8920 => Loss: 15.864342\n",
      "Iteration 8921 => Loss: 15.863602\n",
      "Iteration 8922 => Loss: 15.862863\n",
      "Iteration 8923 => Loss: 15.862127\n",
      "Iteration 8924 => Loss: 15.861393\n",
      "Iteration 8925 => Loss: 15.860660\n",
      "Iteration 8926 => Loss: 15.859930\n",
      "Iteration 8927 => Loss: 15.859202\n",
      "Iteration 8928 => Loss: 15.858475\n",
      "Iteration 8929 => Loss: 15.857751\n",
      "Iteration 8930 => Loss: 15.857029\n",
      "Iteration 8931 => Loss: 15.856308\n",
      "Iteration 8932 => Loss: 15.855590\n",
      "Iteration 8933 => Loss: 15.854874\n",
      "Iteration 8934 => Loss: 15.854860\n",
      "Iteration 8935 => Loss: 15.854120\n",
      "Iteration 8936 => Loss: 15.853382\n",
      "Iteration 8937 => Loss: 15.852647\n",
      "Iteration 8938 => Loss: 15.851913\n",
      "Iteration 8939 => Loss: 15.851181\n",
      "Iteration 8940 => Loss: 15.850452\n",
      "Iteration 8941 => Loss: 15.849724\n",
      "Iteration 8942 => Loss: 15.848998\n",
      "Iteration 8943 => Loss: 15.848275\n",
      "Iteration 8944 => Loss: 15.847553\n",
      "Iteration 8945 => Loss: 15.846833\n",
      "Iteration 8946 => Loss: 15.846116\n",
      "Iteration 8947 => Loss: 15.845400\n",
      "Iteration 8948 => Loss: 15.844686\n",
      "Iteration 8949 => Loss: 15.843975\n",
      "Iteration 8950 => Loss: 15.843265\n",
      "Iteration 8951 => Loss: 15.842557\n",
      "Iteration 8952 => Loss: 15.842550\n",
      "Iteration 8953 => Loss: 15.841819\n",
      "Iteration 8954 => Loss: 15.841090\n",
      "Iteration 8955 => Loss: 15.840363\n",
      "Iteration 8956 => Loss: 15.839638\n",
      "Iteration 8957 => Loss: 15.838915\n",
      "Iteration 8958 => Loss: 15.838194\n",
      "Iteration 8959 => Loss: 15.837475\n",
      "Iteration 8960 => Loss: 15.836758\n",
      "Iteration 8961 => Loss: 15.836043\n",
      "Iteration 8962 => Loss: 15.835330\n",
      "Iteration 8963 => Loss: 15.834619\n",
      "Iteration 8964 => Loss: 15.833910\n",
      "Iteration 8965 => Loss: 15.833203\n",
      "Iteration 8966 => Loss: 15.832498\n",
      "Iteration 8967 => Loss: 15.831795\n",
      "Iteration 8968 => Loss: 15.831094\n",
      "Iteration 8969 => Loss: 15.830395\n",
      "Iteration 8970 => Loss: 15.830395\n",
      "Iteration 8971 => Loss: 15.829673\n",
      "Iteration 8972 => Loss: 15.828952\n",
      "Iteration 8973 => Loss: 15.828234\n",
      "Iteration 8974 => Loss: 15.827518\n",
      "Iteration 8975 => Loss: 15.826803\n",
      "Iteration 8976 => Loss: 15.826091\n",
      "Iteration 8977 => Loss: 15.825381\n",
      "Iteration 8978 => Loss: 15.824672\n",
      "Iteration 8979 => Loss: 15.823966\n",
      "Iteration 8980 => Loss: 15.823262\n",
      "Iteration 8981 => Loss: 15.822559\n",
      "Iteration 8982 => Loss: 15.821859\n",
      "Iteration 8983 => Loss: 15.821161\n",
      "Iteration 8984 => Loss: 15.820464\n",
      "Iteration 8985 => Loss: 15.819770\n",
      "Iteration 8986 => Loss: 15.819078\n",
      "Iteration 8987 => Loss: 15.818387\n",
      "Iteration 8988 => Loss: 15.817699\n",
      "Iteration 8989 => Loss: 15.817680\n",
      "Iteration 8990 => Loss: 15.816969\n",
      "Iteration 8991 => Loss: 15.816259\n",
      "Iteration 8992 => Loss: 15.815551\n",
      "Iteration 8993 => Loss: 15.814846\n",
      "Iteration 8994 => Loss: 15.814142\n",
      "Iteration 8995 => Loss: 15.813440\n",
      "Iteration 8996 => Loss: 15.812741\n",
      "Iteration 8997 => Loss: 15.812043\n",
      "Iteration 8998 => Loss: 15.811347\n",
      "Iteration 8999 => Loss: 15.810654\n",
      "Iteration 9000 => Loss: 15.809962\n",
      "Iteration 9001 => Loss: 15.809272\n",
      "Iteration 9002 => Loss: 15.808585\n",
      "Iteration 9003 => Loss: 15.807899\n",
      "Iteration 9004 => Loss: 15.807215\n",
      "Iteration 9005 => Loss: 15.806534\n",
      "Iteration 9006 => Loss: 15.805854\n",
      "Iteration 9007 => Loss: 15.805843\n",
      "Iteration 9008 => Loss: 15.805140\n",
      "Iteration 9009 => Loss: 15.804439\n",
      "Iteration 9010 => Loss: 15.803740\n",
      "Iteration 9011 => Loss: 15.803043\n",
      "Iteration 9012 => Loss: 15.802348\n",
      "Iteration 9013 => Loss: 15.801655\n",
      "Iteration 9014 => Loss: 15.800964\n",
      "Iteration 9015 => Loss: 15.800275\n",
      "Iteration 9016 => Loss: 15.799588\n",
      "Iteration 9017 => Loss: 15.798903\n",
      "Iteration 9018 => Loss: 15.798220\n",
      "Iteration 9019 => Loss: 15.797539\n",
      "Iteration 9020 => Loss: 15.796860\n",
      "Iteration 9021 => Loss: 15.796183\n",
      "Iteration 9022 => Loss: 15.795508\n",
      "Iteration 9023 => Loss: 15.794835\n",
      "Iteration 9024 => Loss: 15.794164\n",
      "Iteration 9025 => Loss: 15.794159\n",
      "Iteration 9026 => Loss: 15.793465\n",
      "Iteration 9027 => Loss: 15.792772\n",
      "Iteration 9028 => Loss: 15.792082\n",
      "Iteration 9029 => Loss: 15.791394\n",
      "Iteration 9030 => Loss: 15.790707\n",
      "Iteration 9031 => Loss: 15.790023\n",
      "Iteration 9032 => Loss: 15.789341\n",
      "Iteration 9033 => Loss: 15.788660\n",
      "Iteration 9034 => Loss: 15.787982\n",
      "Iteration 9035 => Loss: 15.787306\n",
      "Iteration 9036 => Loss: 15.786631\n",
      "Iteration 9037 => Loss: 15.785959\n",
      "Iteration 9038 => Loss: 15.785289\n",
      "Iteration 9039 => Loss: 15.784620\n",
      "Iteration 9040 => Loss: 15.783954\n",
      "Iteration 9041 => Loss: 15.783290\n",
      "Iteration 9042 => Loss: 15.782627\n",
      "Iteration 9043 => Loss: 15.781967\n",
      "Iteration 9044 => Loss: 15.781944\n",
      "Iteration 9045 => Loss: 15.781260\n",
      "Iteration 9046 => Loss: 15.780578\n",
      "Iteration 9047 => Loss: 15.779899\n",
      "Iteration 9048 => Loss: 15.779221\n",
      "Iteration 9049 => Loss: 15.778545\n",
      "Iteration 9050 => Loss: 15.777872\n",
      "Iteration 9051 => Loss: 15.777200\n",
      "Iteration 9052 => Loss: 15.776530\n",
      "Iteration 9053 => Loss: 15.775863\n",
      "Iteration 9054 => Loss: 15.775197\n",
      "Iteration 9055 => Loss: 15.774533\n",
      "Iteration 9056 => Loss: 15.773872\n",
      "Iteration 9057 => Loss: 15.773212\n",
      "Iteration 9058 => Loss: 15.772554\n",
      "Iteration 9059 => Loss: 15.771899\n",
      "Iteration 9060 => Loss: 15.771245\n",
      "Iteration 9061 => Loss: 15.770593\n",
      "Iteration 9062 => Loss: 15.770577\n",
      "Iteration 9063 => Loss: 15.769902\n",
      "Iteration 9064 => Loss: 15.769229\n",
      "Iteration 9065 => Loss: 15.768558\n",
      "Iteration 9066 => Loss: 15.767889\n",
      "Iteration 9067 => Loss: 15.767222\n",
      "Iteration 9068 => Loss: 15.766557\n",
      "Iteration 9069 => Loss: 15.765894\n",
      "Iteration 9070 => Loss: 15.765233\n",
      "Iteration 9071 => Loss: 15.764574\n",
      "Iteration 9072 => Loss: 15.763917\n",
      "Iteration 9073 => Loss: 15.763262\n",
      "Iteration 9074 => Loss: 15.762609\n",
      "Iteration 9075 => Loss: 15.761958\n",
      "Iteration 9076 => Loss: 15.761309\n",
      "Iteration 9077 => Loss: 15.760662\n",
      "Iteration 9078 => Loss: 15.760017\n",
      "Iteration 9079 => Loss: 15.759374\n",
      "Iteration 9080 => Loss: 15.759365\n",
      "Iteration 9081 => Loss: 15.758699\n",
      "Iteration 9082 => Loss: 15.758034\n",
      "Iteration 9083 => Loss: 15.757372\n",
      "Iteration 9084 => Loss: 15.756712\n",
      "Iteration 9085 => Loss: 15.756053\n",
      "Iteration 9086 => Loss: 15.755397\n",
      "Iteration 9087 => Loss: 15.754743\n",
      "Iteration 9088 => Loss: 15.754090\n",
      "Iteration 9089 => Loss: 15.753440\n",
      "Iteration 9090 => Loss: 15.752792\n",
      "Iteration 9091 => Loss: 15.752145\n",
      "Iteration 9092 => Loss: 15.751501\n",
      "Iteration 9093 => Loss: 15.750859\n",
      "Iteration 9094 => Loss: 15.750218\n",
      "Iteration 9095 => Loss: 15.749580\n",
      "Iteration 9096 => Loss: 15.748944\n",
      "Iteration 9097 => Loss: 15.748309\n",
      "Iteration 9098 => Loss: 15.748307\n",
      "Iteration 9099 => Loss: 15.747650\n",
      "Iteration 9100 => Loss: 15.746994\n",
      "Iteration 9101 => Loss: 15.746340\n",
      "Iteration 9102 => Loss: 15.745689\n",
      "Iteration 9103 => Loss: 15.745039\n",
      "Iteration 9104 => Loss: 15.744391\n",
      "Iteration 9105 => Loss: 15.743746\n",
      "Iteration 9106 => Loss: 15.743102\n",
      "Iteration 9107 => Loss: 15.742460\n",
      "Iteration 9108 => Loss: 15.741821\n",
      "Iteration 9109 => Loss: 15.741183\n",
      "Iteration 9110 => Loss: 15.740547\n",
      "Iteration 9111 => Loss: 15.739914\n",
      "Iteration 9112 => Loss: 15.739282\n",
      "Iteration 9113 => Loss: 15.738652\n",
      "Iteration 9114 => Loss: 15.738025\n",
      "Iteration 9115 => Loss: 15.737399\n",
      "Iteration 9116 => Loss: 15.736775\n",
      "Iteration 9117 => Loss: 15.736755\n",
      "Iteration 9118 => Loss: 15.736108\n",
      "Iteration 9119 => Loss: 15.735463\n",
      "Iteration 9120 => Loss: 15.734820\n",
      "Iteration 9121 => Loss: 15.734179\n",
      "Iteration 9122 => Loss: 15.733540\n",
      "Iteration 9123 => Loss: 15.732903\n",
      "Iteration 9124 => Loss: 15.732268\n",
      "Iteration 9125 => Loss: 15.731635\n",
      "Iteration 9126 => Loss: 15.731004\n",
      "Iteration 9127 => Loss: 15.730375\n",
      "Iteration 9128 => Loss: 15.729748\n",
      "Iteration 9129 => Loss: 15.729123\n",
      "Iteration 9130 => Loss: 15.728500\n",
      "Iteration 9131 => Loss: 15.727879\n",
      "Iteration 9132 => Loss: 15.727260\n",
      "Iteration 9133 => Loss: 15.726643\n",
      "Iteration 9134 => Loss: 15.726028\n",
      "Iteration 9135 => Loss: 15.726014\n",
      "Iteration 9136 => Loss: 15.725375\n",
      "Iteration 9137 => Loss: 15.724739\n",
      "Iteration 9138 => Loss: 15.724105\n",
      "Iteration 9139 => Loss: 15.723472\n",
      "Iteration 9140 => Loss: 15.722842\n",
      "Iteration 9141 => Loss: 15.722214\n",
      "Iteration 9142 => Loss: 15.721587\n",
      "Iteration 9143 => Loss: 15.720963\n",
      "Iteration 9144 => Loss: 15.720341\n",
      "Iteration 9145 => Loss: 15.719720\n",
      "Iteration 9146 => Loss: 15.719102\n",
      "Iteration 9147 => Loss: 15.718486\n",
      "Iteration 9148 => Loss: 15.717871\n",
      "Iteration 9149 => Loss: 15.717259\n",
      "Iteration 9150 => Loss: 15.716649\n",
      "Iteration 9151 => Loss: 15.716040\n",
      "Iteration 9152 => Loss: 15.715434\n",
      "Iteration 9153 => Loss: 15.715427\n",
      "Iteration 9154 => Loss: 15.714798\n",
      "Iteration 9155 => Loss: 15.714170\n",
      "Iteration 9156 => Loss: 15.713544\n",
      "Iteration 9157 => Loss: 15.712921\n",
      "Iteration 9158 => Loss: 15.712299\n",
      "Iteration 9159 => Loss: 15.711679\n",
      "Iteration 9160 => Loss: 15.711062\n",
      "Iteration 9161 => Loss: 15.710446\n",
      "Iteration 9162 => Loss: 15.709832\n",
      "Iteration 9163 => Loss: 15.709221\n",
      "Iteration 9164 => Loss: 15.708611\n",
      "Iteration 9165 => Loss: 15.708003\n",
      "Iteration 9166 => Loss: 15.707398\n",
      "Iteration 9167 => Loss: 15.706794\n",
      "Iteration 9168 => Loss: 15.706192\n",
      "Iteration 9169 => Loss: 15.705593\n",
      "Iteration 9170 => Loss: 15.704995\n",
      "Iteration 9171 => Loss: 15.704399\n",
      "Iteration 9172 => Loss: 15.704374\n",
      "Iteration 9173 => Loss: 15.703755\n",
      "Iteration 9174 => Loss: 15.703138\n",
      "Iteration 9175 => Loss: 15.702523\n",
      "Iteration 9176 => Loss: 15.701910\n",
      "Iteration 9177 => Loss: 15.701299\n",
      "Iteration 9178 => Loss: 15.700690\n",
      "Iteration 9179 => Loss: 15.700083\n",
      "Iteration 9180 => Loss: 15.699478\n",
      "Iteration 9181 => Loss: 15.698875\n",
      "Iteration 9182 => Loss: 15.698274\n",
      "Iteration 9183 => Loss: 15.697675\n",
      "Iteration 9184 => Loss: 15.697078\n",
      "Iteration 9185 => Loss: 15.696483\n",
      "Iteration 9186 => Loss: 15.695890\n",
      "Iteration 9187 => Loss: 15.695299\n",
      "Iteration 9188 => Loss: 15.694710\n",
      "Iteration 9189 => Loss: 15.694123\n",
      "Iteration 9190 => Loss: 15.694105\n",
      "Iteration 9191 => Loss: 15.693495\n",
      "Iteration 9192 => Loss: 15.692886\n",
      "Iteration 9193 => Loss: 15.692280\n",
      "Iteration 9194 => Loss: 15.691676\n",
      "Iteration 9195 => Loss: 15.691073\n",
      "Iteration 9196 => Loss: 15.690473\n",
      "Iteration 9197 => Loss: 15.689875\n",
      "Iteration 9198 => Loss: 15.689278\n",
      "Iteration 9199 => Loss: 15.688684\n",
      "Iteration 9200 => Loss: 15.688092\n",
      "Iteration 9201 => Loss: 15.687501\n",
      "Iteration 9202 => Loss: 15.686913\n",
      "Iteration 9203 => Loss: 15.686327\n",
      "Iteration 9204 => Loss: 15.685742\n",
      "Iteration 9205 => Loss: 15.685160\n",
      "Iteration 9206 => Loss: 15.684580\n",
      "Iteration 9207 => Loss: 15.684001\n",
      "Iteration 9208 => Loss: 15.683990\n",
      "Iteration 9209 => Loss: 15.683388\n",
      "Iteration 9210 => Loss: 15.682789\n",
      "Iteration 9211 => Loss: 15.682191\n",
      "Iteration 9212 => Loss: 15.681595\n",
      "Iteration 9213 => Loss: 15.681002\n",
      "Iteration 9214 => Loss: 15.680410\n",
      "Iteration 9215 => Loss: 15.679820\n",
      "Iteration 9216 => Loss: 15.679233\n",
      "Iteration 9217 => Loss: 15.678647\n",
      "Iteration 9218 => Loss: 15.678063\n",
      "Iteration 9219 => Loss: 15.677482\n",
      "Iteration 9220 => Loss: 15.676902\n",
      "Iteration 9221 => Loss: 15.676324\n",
      "Iteration 9222 => Loss: 15.675749\n",
      "Iteration 9223 => Loss: 15.675175\n",
      "Iteration 9224 => Loss: 15.674603\n",
      "Iteration 9225 => Loss: 15.674034\n",
      "Iteration 9226 => Loss: 15.674029\n",
      "Iteration 9227 => Loss: 15.673436\n",
      "Iteration 9228 => Loss: 15.672845\n",
      "Iteration 9229 => Loss: 15.672256\n",
      "Iteration 9230 => Loss: 15.671669\n",
      "Iteration 9231 => Loss: 15.671084\n",
      "Iteration 9232 => Loss: 15.670501\n",
      "Iteration 9233 => Loss: 15.669920\n",
      "Iteration 9234 => Loss: 15.669341\n",
      "Iteration 9235 => Loss: 15.668764\n",
      "Iteration 9236 => Loss: 15.668189\n",
      "Iteration 9237 => Loss: 15.667616\n",
      "Iteration 9238 => Loss: 15.667045\n",
      "Iteration 9239 => Loss: 15.666476\n",
      "Iteration 9240 => Loss: 15.665909\n",
      "Iteration 9241 => Loss: 15.665344\n",
      "Iteration 9242 => Loss: 15.664781\n",
      "Iteration 9243 => Loss: 15.664220\n",
      "Iteration 9244 => Loss: 15.663661\n",
      "Iteration 9245 => Loss: 15.663638\n",
      "Iteration 9246 => Loss: 15.663056\n",
      "Iteration 9247 => Loss: 15.662476\n",
      "Iteration 9248 => Loss: 15.661897\n",
      "Iteration 9249 => Loss: 15.661321\n",
      "Iteration 9250 => Loss: 15.660747\n",
      "Iteration 9251 => Loss: 15.660174\n",
      "Iteration 9252 => Loss: 15.659604\n",
      "Iteration 9253 => Loss: 15.659036\n",
      "Iteration 9254 => Loss: 15.658469\n",
      "Iteration 9255 => Loss: 15.657905\n",
      "Iteration 9256 => Loss: 15.657343\n",
      "Iteration 9257 => Loss: 15.656782\n",
      "Iteration 9258 => Loss: 15.656224\n",
      "Iteration 9259 => Loss: 15.655668\n",
      "Iteration 9260 => Loss: 15.655113\n",
      "Iteration 9261 => Loss: 15.654561\n",
      "Iteration 9262 => Loss: 15.654011\n",
      "Iteration 9263 => Loss: 15.653995\n",
      "Iteration 9264 => Loss: 15.653421\n",
      "Iteration 9265 => Loss: 15.652849\n",
      "Iteration 9266 => Loss: 15.652280\n",
      "Iteration 9267 => Loss: 15.651712\n",
      "Iteration 9268 => Loss: 15.651146\n",
      "Iteration 9269 => Loss: 15.650583\n",
      "Iteration 9270 => Loss: 15.650021\n",
      "Iteration 9271 => Loss: 15.649461\n",
      "Iteration 9272 => Loss: 15.648904\n",
      "Iteration 9273 => Loss: 15.648348\n",
      "Iteration 9274 => Loss: 15.647794\n",
      "Iteration 9275 => Loss: 15.647243\n",
      "Iteration 9276 => Loss: 15.646693\n",
      "Iteration 9277 => Loss: 15.646145\n",
      "Iteration 9278 => Loss: 15.645600\n",
      "Iteration 9279 => Loss: 15.645056\n",
      "Iteration 9280 => Loss: 15.644514\n",
      "Iteration 9281 => Loss: 15.644506\n",
      "Iteration 9282 => Loss: 15.643941\n",
      "Iteration 9283 => Loss: 15.643378\n",
      "Iteration 9284 => Loss: 15.642817\n",
      "Iteration 9285 => Loss: 15.642258\n",
      "Iteration 9286 => Loss: 15.641701\n",
      "Iteration 9287 => Loss: 15.641146\n",
      "Iteration 9288 => Loss: 15.640593\n",
      "Iteration 9289 => Loss: 15.640042\n",
      "Iteration 9290 => Loss: 15.639493\n",
      "Iteration 9291 => Loss: 15.638946\n",
      "Iteration 9292 => Loss: 15.638401\n",
      "Iteration 9293 => Loss: 15.637858\n",
      "Iteration 9294 => Loss: 15.637317\n",
      "Iteration 9295 => Loss: 15.636778\n",
      "Iteration 9296 => Loss: 15.636241\n",
      "Iteration 9297 => Loss: 15.635706\n",
      "Iteration 9298 => Loss: 15.635173\n",
      "Iteration 9299 => Loss: 15.635171\n",
      "Iteration 9300 => Loss: 15.634614\n",
      "Iteration 9301 => Loss: 15.634060\n",
      "Iteration 9302 => Loss: 15.633508\n",
      "Iteration 9303 => Loss: 15.632957\n",
      "Iteration 9304 => Loss: 15.632409\n",
      "Iteration 9305 => Loss: 15.631863\n",
      "Iteration 9306 => Loss: 15.631318\n",
      "Iteration 9307 => Loss: 15.630776\n",
      "Iteration 9308 => Loss: 15.630236\n",
      "Iteration 9309 => Loss: 15.629697\n",
      "Iteration 9310 => Loss: 15.629161\n",
      "Iteration 9311 => Loss: 15.628627\n",
      "Iteration 9312 => Loss: 15.628094\n",
      "Iteration 9313 => Loss: 15.627564\n",
      "Iteration 9314 => Loss: 15.627036\n",
      "Iteration 9315 => Loss: 15.626509\n",
      "Iteration 9316 => Loss: 15.625985\n",
      "Iteration 9317 => Loss: 15.625463\n",
      "Iteration 9318 => Loss: 15.625442\n",
      "Iteration 9319 => Loss: 15.624896\n",
      "Iteration 9320 => Loss: 15.624353\n",
      "Iteration 9321 => Loss: 15.623811\n",
      "Iteration 9322 => Loss: 15.623271\n",
      "Iteration 9323 => Loss: 15.622734\n",
      "Iteration 9324 => Loss: 15.622198\n",
      "Iteration 9325 => Loss: 15.621664\n",
      "Iteration 9326 => Loss: 15.621133\n",
      "Iteration 9327 => Loss: 15.620603\n",
      "Iteration 9328 => Loss: 15.620075\n",
      "Iteration 9329 => Loss: 15.619550\n",
      "Iteration 9330 => Loss: 15.619026\n",
      "Iteration 9331 => Loss: 15.618504\n",
      "Iteration 9332 => Loss: 15.617985\n",
      "Iteration 9333 => Loss: 15.617467\n",
      "Iteration 9334 => Loss: 15.616951\n",
      "Iteration 9335 => Loss: 15.616438\n",
      "Iteration 9336 => Loss: 15.616424\n",
      "Iteration 9337 => Loss: 15.615887\n",
      "Iteration 9338 => Loss: 15.615352\n",
      "Iteration 9339 => Loss: 15.614819\n",
      "Iteration 9340 => Loss: 15.614288\n",
      "Iteration 9341 => Loss: 15.613759\n",
      "Iteration 9342 => Loss: 15.613232\n",
      "Iteration 9343 => Loss: 15.612707\n",
      "Iteration 9344 => Loss: 15.612184\n",
      "Iteration 9345 => Loss: 15.611663\n",
      "Iteration 9346 => Loss: 15.611144\n",
      "Iteration 9347 => Loss: 15.610627\n",
      "Iteration 9348 => Loss: 15.610112\n",
      "Iteration 9349 => Loss: 15.609599\n",
      "Iteration 9350 => Loss: 15.609088\n",
      "Iteration 9351 => Loss: 15.608579\n",
      "Iteration 9352 => Loss: 15.608072\n",
      "Iteration 9353 => Loss: 15.607567\n",
      "Iteration 9354 => Loss: 15.607561\n",
      "Iteration 9355 => Loss: 15.607032\n",
      "Iteration 9356 => Loss: 15.606506\n",
      "Iteration 9357 => Loss: 15.605982\n",
      "Iteration 9358 => Loss: 15.605459\n",
      "Iteration 9359 => Loss: 15.604939\n",
      "Iteration 9360 => Loss: 15.604421\n",
      "Iteration 9361 => Loss: 15.603904\n",
      "Iteration 9362 => Loss: 15.603390\n",
      "Iteration 9363 => Loss: 15.602878\n",
      "Iteration 9364 => Loss: 15.602367\n",
      "Iteration 9365 => Loss: 15.601859\n",
      "Iteration 9366 => Loss: 15.601353\n",
      "Iteration 9367 => Loss: 15.600848\n",
      "Iteration 9368 => Loss: 15.600346\n",
      "Iteration 9369 => Loss: 15.599846\n",
      "Iteration 9370 => Loss: 15.599347\n",
      "Iteration 9371 => Loss: 15.598851\n",
      "Iteration 9372 => Loss: 15.598357\n",
      "Iteration 9373 => Loss: 15.598332\n",
      "Iteration 9374 => Loss: 15.597814\n",
      "Iteration 9375 => Loss: 15.597299\n",
      "Iteration 9376 => Loss: 15.596785\n",
      "Iteration 9377 => Loss: 15.596273\n",
      "Iteration 9378 => Loss: 15.595764\n",
      "Iteration 9379 => Loss: 15.595256\n",
      "Iteration 9380 => Loss: 15.594750\n",
      "Iteration 9381 => Loss: 15.594247\n",
      "Iteration 9382 => Loss: 15.593745\n",
      "Iteration 9383 => Loss: 15.593245\n",
      "Iteration 9384 => Loss: 15.592748\n",
      "Iteration 9385 => Loss: 15.592252\n",
      "Iteration 9386 => Loss: 15.591758\n",
      "Iteration 9387 => Loss: 15.591267\n",
      "Iteration 9388 => Loss: 15.590777\n",
      "Iteration 9389 => Loss: 15.590289\n",
      "Iteration 9390 => Loss: 15.589804\n",
      "Iteration 9391 => Loss: 15.589786\n",
      "Iteration 9392 => Loss: 15.589277\n",
      "Iteration 9393 => Loss: 15.588770\n",
      "Iteration 9394 => Loss: 15.588265\n",
      "Iteration 9395 => Loss: 15.587762\n",
      "Iteration 9396 => Loss: 15.587261\n",
      "Iteration 9397 => Loss: 15.586762\n",
      "Iteration 9398 => Loss: 15.586265\n",
      "Iteration 9399 => Loss: 15.585770\n",
      "Iteration 9400 => Loss: 15.585277\n",
      "Iteration 9401 => Loss: 15.584786\n",
      "Iteration 9402 => Loss: 15.584297\n",
      "Iteration 9403 => Loss: 15.583810\n",
      "Iteration 9404 => Loss: 15.583325\n",
      "Iteration 9405 => Loss: 15.582842\n",
      "Iteration 9406 => Loss: 15.582361\n",
      "Iteration 9407 => Loss: 15.581882\n",
      "Iteration 9408 => Loss: 15.581405\n",
      "Iteration 9409 => Loss: 15.581393\n",
      "Iteration 9410 => Loss: 15.580893\n",
      "Iteration 9411 => Loss: 15.580395\n",
      "Iteration 9412 => Loss: 15.579898\n",
      "Iteration 9413 => Loss: 15.579404\n",
      "Iteration 9414 => Loss: 15.578912\n",
      "Iteration 9415 => Loss: 15.578421\n",
      "Iteration 9416 => Loss: 15.577933\n",
      "Iteration 9417 => Loss: 15.577447\n",
      "Iteration 9418 => Loss: 15.576962\n",
      "Iteration 9419 => Loss: 15.576480\n",
      "Iteration 9420 => Loss: 15.576000\n",
      "Iteration 9421 => Loss: 15.575521\n",
      "Iteration 9422 => Loss: 15.575045\n",
      "Iteration 9423 => Loss: 15.574571\n",
      "Iteration 9424 => Loss: 15.574098\n",
      "Iteration 9425 => Loss: 15.573628\n",
      "Iteration 9426 => Loss: 15.573160\n",
      "Iteration 9427 => Loss: 15.573156\n",
      "Iteration 9428 => Loss: 15.572664\n",
      "Iteration 9429 => Loss: 15.572174\n",
      "Iteration 9430 => Loss: 15.571687\n",
      "Iteration 9431 => Loss: 15.571201\n",
      "Iteration 9432 => Loss: 15.570717\n",
      "Iteration 9433 => Loss: 15.570236\n",
      "Iteration 9434 => Loss: 15.569756\n",
      "Iteration 9435 => Loss: 15.569278\n",
      "Iteration 9436 => Loss: 15.568803\n",
      "Iteration 9437 => Loss: 15.568329\n",
      "Iteration 9438 => Loss: 15.567857\n",
      "Iteration 9439 => Loss: 15.567388\n",
      "Iteration 9440 => Loss: 15.566920\n",
      "Iteration 9441 => Loss: 15.566454\n",
      "Iteration 9442 => Loss: 15.565991\n",
      "Iteration 9443 => Loss: 15.565529\n",
      "Iteration 9444 => Loss: 15.565069\n",
      "Iteration 9445 => Loss: 15.564612\n",
      "Iteration 9446 => Loss: 15.564589\n",
      "Iteration 9447 => Loss: 15.564108\n",
      "Iteration 9448 => Loss: 15.563629\n",
      "Iteration 9449 => Loss: 15.563152\n",
      "Iteration 9450 => Loss: 15.562677\n",
      "Iteration 9451 => Loss: 15.562204\n",
      "Iteration 9452 => Loss: 15.561733\n",
      "Iteration 9453 => Loss: 15.561264\n",
      "Iteration 9454 => Loss: 15.560797\n",
      "Iteration 9455 => Loss: 15.560332\n",
      "Iteration 9456 => Loss: 15.559869\n",
      "Iteration 9457 => Loss: 15.559408\n",
      "Iteration 9458 => Loss: 15.558949\n",
      "Iteration 9459 => Loss: 15.558492\n",
      "Iteration 9460 => Loss: 15.558037\n",
      "Iteration 9461 => Loss: 15.557584\n",
      "Iteration 9462 => Loss: 15.557133\n",
      "Iteration 9463 => Loss: 15.556684\n",
      "Iteration 9464 => Loss: 15.556669\n",
      "Iteration 9465 => Loss: 15.556196\n",
      "Iteration 9466 => Loss: 15.555726\n",
      "Iteration 9467 => Loss: 15.555258\n",
      "Iteration 9468 => Loss: 15.554791\n",
      "Iteration 9469 => Loss: 15.554327\n",
      "Iteration 9470 => Loss: 15.553865\n",
      "Iteration 9471 => Loss: 15.553404\n",
      "Iteration 9472 => Loss: 15.552946\n",
      "Iteration 9473 => Loss: 15.552490\n",
      "Iteration 9474 => Loss: 15.552035\n",
      "Iteration 9475 => Loss: 15.551583\n",
      "Iteration 9476 => Loss: 15.551133\n",
      "Iteration 9477 => Loss: 15.550684\n",
      "Iteration 9478 => Loss: 15.550238\n",
      "Iteration 9479 => Loss: 15.549794\n",
      "Iteration 9480 => Loss: 15.549351\n",
      "Iteration 9481 => Loss: 15.548911\n",
      "Iteration 9482 => Loss: 15.548902\n",
      "Iteration 9483 => Loss: 15.548439\n",
      "Iteration 9484 => Loss: 15.547977\n",
      "Iteration 9485 => Loss: 15.547517\n",
      "Iteration 9486 => Loss: 15.547060\n",
      "Iteration 9487 => Loss: 15.546604\n",
      "Iteration 9488 => Loss: 15.546150\n",
      "Iteration 9489 => Loss: 15.545699\n",
      "Iteration 9490 => Loss: 15.545249\n",
      "Iteration 9491 => Loss: 15.544801\n",
      "Iteration 9492 => Loss: 15.544356\n",
      "Iteration 9493 => Loss: 15.543912\n",
      "Iteration 9494 => Loss: 15.543470\n",
      "Iteration 9495 => Loss: 15.543031\n",
      "Iteration 9496 => Loss: 15.542593\n",
      "Iteration 9497 => Loss: 15.542157\n",
      "Iteration 9498 => Loss: 15.541724\n",
      "Iteration 9499 => Loss: 15.541292\n",
      "Iteration 9500 => Loss: 15.541290\n",
      "Iteration 9501 => Loss: 15.540835\n",
      "Iteration 9502 => Loss: 15.540382\n",
      "Iteration 9503 => Loss: 15.539931\n",
      "Iteration 9504 => Loss: 15.539482\n",
      "Iteration 9505 => Loss: 15.539035\n",
      "Iteration 9506 => Loss: 15.538590\n",
      "Iteration 9507 => Loss: 15.538147\n",
      "Iteration 9508 => Loss: 15.537706\n",
      "Iteration 9509 => Loss: 15.537267\n",
      "Iteration 9510 => Loss: 15.536830\n",
      "Iteration 9511 => Loss: 15.536395\n",
      "Iteration 9512 => Loss: 15.535962\n",
      "Iteration 9513 => Loss: 15.535531\n",
      "Iteration 9514 => Loss: 15.535102\n",
      "Iteration 9515 => Loss: 15.534675\n",
      "Iteration 9516 => Loss: 15.534250\n",
      "Iteration 9517 => Loss: 15.533827\n",
      "Iteration 9518 => Loss: 15.533406\n",
      "Iteration 9519 => Loss: 15.533386\n",
      "Iteration 9520 => Loss: 15.532942\n",
      "Iteration 9521 => Loss: 15.532499\n",
      "Iteration 9522 => Loss: 15.532059\n",
      "Iteration 9523 => Loss: 15.531621\n",
      "Iteration 9524 => Loss: 15.531184\n",
      "Iteration 9525 => Loss: 15.530750\n",
      "Iteration 9526 => Loss: 15.530318\n",
      "Iteration 9527 => Loss: 15.529887\n",
      "Iteration 9528 => Loss: 15.529459\n",
      "Iteration 9529 => Loss: 15.529033\n",
      "Iteration 9530 => Loss: 15.528608\n",
      "Iteration 9531 => Loss: 15.528186\n",
      "Iteration 9532 => Loss: 15.527766\n",
      "Iteration 9533 => Loss: 15.527347\n",
      "Iteration 9534 => Loss: 15.526931\n",
      "Iteration 9535 => Loss: 15.526517\n",
      "Iteration 9536 => Loss: 15.526104\n",
      "Iteration 9537 => Loss: 15.526091\n",
      "Iteration 9538 => Loss: 15.525655\n",
      "Iteration 9539 => Loss: 15.525222\n",
      "Iteration 9540 => Loss: 15.524790\n",
      "Iteration 9541 => Loss: 15.524360\n",
      "Iteration 9542 => Loss: 15.523933\n",
      "Iteration 9543 => Loss: 15.523507\n",
      "Iteration 9544 => Loss: 15.523083\n",
      "Iteration 9545 => Loss: 15.522662\n",
      "Iteration 9546 => Loss: 15.522242\n",
      "Iteration 9547 => Loss: 15.521824\n",
      "Iteration 9548 => Loss: 15.521409\n",
      "Iteration 9549 => Loss: 15.520995\n",
      "Iteration 9550 => Loss: 15.520583\n",
      "Iteration 9551 => Loss: 15.520174\n",
      "Iteration 9552 => Loss: 15.519766\n",
      "Iteration 9553 => Loss: 15.519360\n",
      "Iteration 9554 => Loss: 15.518957\n",
      "Iteration 9555 => Loss: 15.518951\n",
      "Iteration 9556 => Loss: 15.518524\n",
      "Iteration 9557 => Loss: 15.518099\n",
      "Iteration 9558 => Loss: 15.517676\n",
      "Iteration 9559 => Loss: 15.517255\n",
      "Iteration 9560 => Loss: 15.516836\n",
      "Iteration 9561 => Loss: 15.516419\n",
      "Iteration 9562 => Loss: 15.516004\n",
      "Iteration 9563 => Loss: 15.515591\n",
      "Iteration 9564 => Loss: 15.515180\n",
      "Iteration 9565 => Loss: 15.514771\n",
      "Iteration 9566 => Loss: 15.514364\n",
      "Iteration 9567 => Loss: 15.513959\n",
      "Iteration 9568 => Loss: 15.513556\n",
      "Iteration 9569 => Loss: 15.513155\n",
      "Iteration 9570 => Loss: 15.512756\n",
      "Iteration 9571 => Loss: 15.512359\n",
      "Iteration 9572 => Loss: 15.511964\n",
      "Iteration 9573 => Loss: 15.511571\n",
      "Iteration 9574 => Loss: 15.511546\n",
      "Iteration 9575 => Loss: 15.511130\n",
      "Iteration 9576 => Loss: 15.510715\n",
      "Iteration 9577 => Loss: 15.510303\n",
      "Iteration 9578 => Loss: 15.509893\n",
      "Iteration 9579 => Loss: 15.509484\n",
      "Iteration 9580 => Loss: 15.509078\n",
      "Iteration 9581 => Loss: 15.508674\n",
      "Iteration 9582 => Loss: 15.508271\n",
      "Iteration 9583 => Loss: 15.507871\n",
      "Iteration 9584 => Loss: 15.507473\n",
      "Iteration 9585 => Loss: 15.507076\n",
      "Iteration 9586 => Loss: 15.506682\n",
      "Iteration 9587 => Loss: 15.506290\n",
      "Iteration 9588 => Loss: 15.505899\n",
      "Iteration 9589 => Loss: 15.505511\n",
      "Iteration 9590 => Loss: 15.505125\n",
      "Iteration 9591 => Loss: 15.504740\n",
      "Iteration 9592 => Loss: 15.504722\n",
      "Iteration 9593 => Loss: 15.504315\n",
      "Iteration 9594 => Loss: 15.503909\n",
      "Iteration 9595 => Loss: 15.503505\n",
      "Iteration 9596 => Loss: 15.503104\n",
      "Iteration 9597 => Loss: 15.502704\n",
      "Iteration 9598 => Loss: 15.502306\n",
      "Iteration 9599 => Loss: 15.501911\n",
      "Iteration 9600 => Loss: 15.501517\n",
      "Iteration 9601 => Loss: 15.501125\n",
      "Iteration 9602 => Loss: 15.500736\n",
      "Iteration 9603 => Loss: 15.500348\n",
      "Iteration 9604 => Loss: 15.499962\n",
      "Iteration 9605 => Loss: 15.499579\n",
      "Iteration 9606 => Loss: 15.499197\n",
      "Iteration 9607 => Loss: 15.498817\n",
      "Iteration 9608 => Loss: 15.498440\n",
      "Iteration 9609 => Loss: 15.498064\n",
      "Iteration 9610 => Loss: 15.498053\n",
      "Iteration 9611 => Loss: 15.497654\n",
      "Iteration 9612 => Loss: 15.497257\n",
      "Iteration 9613 => Loss: 15.496862\n",
      "Iteration 9614 => Loss: 15.496469\n",
      "Iteration 9615 => Loss: 15.496078\n",
      "Iteration 9616 => Loss: 15.495689\n",
      "Iteration 9617 => Loss: 15.495302\n",
      "Iteration 9618 => Loss: 15.494917\n",
      "Iteration 9619 => Loss: 15.494534\n",
      "Iteration 9620 => Loss: 15.494153\n",
      "Iteration 9621 => Loss: 15.493774\n",
      "Iteration 9622 => Loss: 15.493397\n",
      "Iteration 9623 => Loss: 15.493022\n",
      "Iteration 9624 => Loss: 15.492649\n",
      "Iteration 9625 => Loss: 15.492278\n",
      "Iteration 9626 => Loss: 15.491909\n",
      "Iteration 9627 => Loss: 15.491542\n",
      "Iteration 9628 => Loss: 15.491538\n",
      "Iteration 9629 => Loss: 15.491148\n",
      "Iteration 9630 => Loss: 15.490760\n",
      "Iteration 9631 => Loss: 15.490373\n",
      "Iteration 9632 => Loss: 15.489989\n",
      "Iteration 9633 => Loss: 15.489607\n",
      "Iteration 9634 => Loss: 15.489226\n",
      "Iteration 9635 => Loss: 15.488848\n",
      "Iteration 9636 => Loss: 15.488472\n",
      "Iteration 9637 => Loss: 15.488097\n",
      "Iteration 9638 => Loss: 15.487725\n",
      "Iteration 9639 => Loss: 15.487355\n",
      "Iteration 9640 => Loss: 15.486986\n",
      "Iteration 9641 => Loss: 15.486620\n",
      "Iteration 9642 => Loss: 15.486256\n",
      "Iteration 9643 => Loss: 15.485893\n",
      "Iteration 9644 => Loss: 15.485533\n",
      "Iteration 9645 => Loss: 15.485175\n",
      "Iteration 9646 => Loss: 15.484818\n",
      "Iteration 9647 => Loss: 15.484796\n",
      "Iteration 9648 => Loss: 15.484417\n",
      "Iteration 9649 => Loss: 15.484039\n",
      "Iteration 9650 => Loss: 15.483663\n",
      "Iteration 9651 => Loss: 15.483290\n",
      "Iteration 9652 => Loss: 15.482918\n",
      "Iteration 9653 => Loss: 15.482548\n",
      "Iteration 9654 => Loss: 15.482181\n",
      "Iteration 9655 => Loss: 15.481815\n",
      "Iteration 9656 => Loss: 15.481451\n",
      "Iteration 9657 => Loss: 15.481090\n",
      "Iteration 9658 => Loss: 15.480730\n",
      "Iteration 9659 => Loss: 15.480372\n",
      "Iteration 9660 => Loss: 15.480017\n",
      "Iteration 9661 => Loss: 15.479663\n",
      "Iteration 9662 => Loss: 15.479311\n",
      "Iteration 9663 => Loss: 15.478962\n",
      "Iteration 9664 => Loss: 15.478614\n",
      "Iteration 9665 => Loss: 15.478599\n",
      "Iteration 9666 => Loss: 15.478228\n",
      "Iteration 9667 => Loss: 15.477859\n",
      "Iteration 9668 => Loss: 15.477492\n",
      "Iteration 9669 => Loss: 15.477127\n",
      "Iteration 9670 => Loss: 15.476764\n",
      "Iteration 9671 => Loss: 15.476403\n",
      "Iteration 9672 => Loss: 15.476044\n",
      "Iteration 9673 => Loss: 15.475687\n",
      "Iteration 9674 => Loss: 15.475332\n",
      "Iteration 9675 => Loss: 15.474979\n",
      "Iteration 9676 => Loss: 15.474628\n",
      "Iteration 9677 => Loss: 15.474279\n",
      "Iteration 9678 => Loss: 15.473932\n",
      "Iteration 9679 => Loss: 15.473587\n",
      "Iteration 9680 => Loss: 15.473244\n",
      "Iteration 9681 => Loss: 15.472903\n",
      "Iteration 9682 => Loss: 15.472564\n",
      "Iteration 9683 => Loss: 15.472555\n",
      "Iteration 9684 => Loss: 15.472193\n",
      "Iteration 9685 => Loss: 15.471832\n",
      "Iteration 9686 => Loss: 15.471474\n",
      "Iteration 9687 => Loss: 15.471118\n",
      "Iteration 9688 => Loss: 15.470763\n",
      "Iteration 9689 => Loss: 15.470411\n",
      "Iteration 9690 => Loss: 15.470061\n",
      "Iteration 9691 => Loss: 15.469712\n",
      "Iteration 9692 => Loss: 15.469366\n",
      "Iteration 9693 => Loss: 15.469022\n",
      "Iteration 9694 => Loss: 15.468679\n",
      "Iteration 9695 => Loss: 15.468339\n",
      "Iteration 9696 => Loss: 15.468001\n",
      "Iteration 9697 => Loss: 15.467664\n",
      "Iteration 9698 => Loss: 15.467330\n",
      "Iteration 9699 => Loss: 15.466998\n",
      "Iteration 9700 => Loss: 15.466667\n",
      "Iteration 9701 => Loss: 15.466666\n",
      "Iteration 9702 => Loss: 15.466312\n",
      "Iteration 9703 => Loss: 15.465961\n",
      "Iteration 9704 => Loss: 15.465611\n",
      "Iteration 9705 => Loss: 15.465263\n",
      "Iteration 9706 => Loss: 15.464918\n",
      "Iteration 9707 => Loss: 15.464574\n",
      "Iteration 9708 => Loss: 15.464232\n",
      "Iteration 9709 => Loss: 15.463893\n",
      "Iteration 9710 => Loss: 15.463555\n",
      "Iteration 9711 => Loss: 15.463219\n",
      "Iteration 9712 => Loss: 15.462886\n",
      "Iteration 9713 => Loss: 15.462554\n",
      "Iteration 9714 => Loss: 15.462224\n",
      "Iteration 9715 => Loss: 15.461897\n",
      "Iteration 9716 => Loss: 15.461571\n",
      "Iteration 9717 => Loss: 15.461247\n",
      "Iteration 9718 => Loss: 15.460926\n",
      "Iteration 9719 => Loss: 15.460606\n",
      "Iteration 9720 => Loss: 15.460586\n",
      "Iteration 9721 => Loss: 15.460243\n",
      "Iteration 9722 => Loss: 15.459902\n",
      "Iteration 9723 => Loss: 15.459563\n",
      "Iteration 9724 => Loss: 15.459226\n",
      "Iteration 9725 => Loss: 15.458891\n",
      "Iteration 9726 => Loss: 15.458558\n",
      "Iteration 9727 => Loss: 15.458227\n",
      "Iteration 9728 => Loss: 15.457898\n",
      "Iteration 9729 => Loss: 15.457571\n",
      "Iteration 9730 => Loss: 15.457246\n",
      "Iteration 9731 => Loss: 15.456923\n",
      "Iteration 9732 => Loss: 15.456602\n",
      "Iteration 9733 => Loss: 15.456283\n",
      "Iteration 9734 => Loss: 15.455966\n",
      "Iteration 9735 => Loss: 15.455651\n",
      "Iteration 9736 => Loss: 15.455338\n",
      "Iteration 9737 => Loss: 15.455027\n",
      "Iteration 9738 => Loss: 15.455014\n",
      "Iteration 9739 => Loss: 15.454680\n",
      "Iteration 9740 => Loss: 15.454348\n",
      "Iteration 9741 => Loss: 15.454017\n",
      "Iteration 9742 => Loss: 15.453689\n",
      "Iteration 9743 => Loss: 15.453363\n",
      "Iteration 9744 => Loss: 15.453038\n",
      "Iteration 9745 => Loss: 15.452716\n",
      "Iteration 9746 => Loss: 15.452396\n",
      "Iteration 9747 => Loss: 15.452077\n",
      "Iteration 9748 => Loss: 15.451761\n",
      "Iteration 9749 => Loss: 15.451447\n",
      "Iteration 9750 => Loss: 15.451134\n",
      "Iteration 9751 => Loss: 15.450824\n",
      "Iteration 9752 => Loss: 15.450516\n",
      "Iteration 9753 => Loss: 15.450209\n",
      "Iteration 9754 => Loss: 15.449905\n",
      "Iteration 9755 => Loss: 15.449603\n",
      "Iteration 9756 => Loss: 15.449597\n",
      "Iteration 9757 => Loss: 15.449271\n",
      "Iteration 9758 => Loss: 15.448947\n",
      "Iteration 9759 => Loss: 15.448626\n",
      "Iteration 9760 => Loss: 15.448306\n",
      "Iteration 9761 => Loss: 15.447988\n",
      "Iteration 9762 => Loss: 15.447673\n",
      "Iteration 9763 => Loss: 15.447359\n",
      "Iteration 9764 => Loss: 15.447047\n",
      "Iteration 9765 => Loss: 15.446738\n",
      "Iteration 9766 => Loss: 15.446430\n",
      "Iteration 9767 => Loss: 15.446124\n",
      "Iteration 9768 => Loss: 15.445821\n",
      "Iteration 9769 => Loss: 15.445519\n",
      "Iteration 9770 => Loss: 15.445219\n",
      "Iteration 9771 => Loss: 15.444922\n",
      "Iteration 9772 => Loss: 15.444626\n",
      "Iteration 9773 => Loss: 15.444332\n",
      "Iteration 9774 => Loss: 15.444041\n",
      "Iteration 9775 => Loss: 15.444016\n",
      "Iteration 9776 => Loss: 15.443701\n",
      "Iteration 9777 => Loss: 15.443388\n",
      "Iteration 9778 => Loss: 15.443077\n",
      "Iteration 9779 => Loss: 15.442768\n",
      "Iteration 9780 => Loss: 15.442461\n",
      "Iteration 9781 => Loss: 15.442156\n",
      "Iteration 9782 => Loss: 15.441853\n",
      "Iteration 9783 => Loss: 15.441552\n",
      "Iteration 9784 => Loss: 15.441253\n",
      "Iteration 9785 => Loss: 15.440956\n",
      "Iteration 9786 => Loss: 15.440661\n",
      "Iteration 9787 => Loss: 15.440368\n",
      "Iteration 9788 => Loss: 15.440077\n",
      "Iteration 9789 => Loss: 15.439788\n",
      "Iteration 9790 => Loss: 15.439501\n",
      "Iteration 9791 => Loss: 15.439216\n",
      "Iteration 9792 => Loss: 15.438933\n",
      "Iteration 9793 => Loss: 15.438916\n",
      "Iteration 9794 => Loss: 15.438609\n",
      "Iteration 9795 => Loss: 15.438305\n",
      "Iteration 9796 => Loss: 15.438003\n",
      "Iteration 9797 => Loss: 15.437702\n",
      "Iteration 9798 => Loss: 15.437404\n",
      "Iteration 9799 => Loss: 15.437108\n",
      "Iteration 9800 => Loss: 15.436813\n",
      "Iteration 9801 => Loss: 15.436521\n",
      "Iteration 9802 => Loss: 15.436231\n",
      "Iteration 9803 => Loss: 15.435942\n",
      "Iteration 9804 => Loss: 15.435656\n",
      "Iteration 9805 => Loss: 15.435372\n",
      "Iteration 9806 => Loss: 15.435089\n",
      "Iteration 9807 => Loss: 15.434809\n",
      "Iteration 9808 => Loss: 15.434531\n",
      "Iteration 9809 => Loss: 15.434254\n",
      "Iteration 9810 => Loss: 15.433980\n",
      "Iteration 9811 => Loss: 15.433969\n",
      "Iteration 9812 => Loss: 15.433672\n",
      "Iteration 9813 => Loss: 15.433376\n",
      "Iteration 9814 => Loss: 15.433082\n",
      "Iteration 9815 => Loss: 15.432791\n",
      "Iteration 9816 => Loss: 15.432501\n",
      "Iteration 9817 => Loss: 15.432213\n",
      "Iteration 9818 => Loss: 15.431928\n",
      "Iteration 9819 => Loss: 15.431644\n",
      "Iteration 9820 => Loss: 15.431362\n",
      "Iteration 9821 => Loss: 15.431083\n",
      "Iteration 9822 => Loss: 15.430805\n",
      "Iteration 9823 => Loss: 15.430529\n",
      "Iteration 9824 => Loss: 15.430256\n",
      "Iteration 9825 => Loss: 15.429984\n",
      "Iteration 9826 => Loss: 15.429714\n",
      "Iteration 9827 => Loss: 15.429447\n",
      "Iteration 9828 => Loss: 15.429181\n",
      "Iteration 9829 => Loss: 15.429178\n",
      "Iteration 9830 => Loss: 15.428889\n",
      "Iteration 9831 => Loss: 15.428602\n",
      "Iteration 9832 => Loss: 15.428317\n",
      "Iteration 9833 => Loss: 15.428034\n",
      "Iteration 9834 => Loss: 15.427753\n",
      "Iteration 9835 => Loss: 15.427474\n",
      "Iteration 9836 => Loss: 15.427197\n",
      "Iteration 9837 => Loss: 15.426922\n",
      "Iteration 9838 => Loss: 15.426649\n",
      "Iteration 9839 => Loss: 15.426378\n",
      "Iteration 9840 => Loss: 15.426109\n",
      "Iteration 9841 => Loss: 15.425842\n",
      "Iteration 9842 => Loss: 15.425577\n",
      "Iteration 9843 => Loss: 15.425314\n",
      "Iteration 9844 => Loss: 15.425053\n",
      "Iteration 9845 => Loss: 15.424794\n",
      "Iteration 9846 => Loss: 15.424537\n",
      "Iteration 9847 => Loss: 15.424282\n",
      "Iteration 9848 => Loss: 15.424260\n",
      "Iteration 9849 => Loss: 15.423981\n",
      "Iteration 9850 => Loss: 15.423705\n",
      "Iteration 9851 => Loss: 15.423431\n",
      "Iteration 9852 => Loss: 15.423158\n",
      "Iteration 9853 => Loss: 15.422888\n",
      "Iteration 9854 => Loss: 15.422620\n",
      "Iteration 9855 => Loss: 15.422353\n",
      "Iteration 9856 => Loss: 15.422089\n",
      "Iteration 9857 => Loss: 15.421827\n",
      "Iteration 9858 => Loss: 15.421566\n",
      "Iteration 9859 => Loss: 15.421308\n",
      "Iteration 9860 => Loss: 15.421052\n",
      "Iteration 9861 => Loss: 15.420797\n",
      "Iteration 9862 => Loss: 15.420545\n",
      "Iteration 9863 => Loss: 15.420295\n",
      "Iteration 9864 => Loss: 15.420046\n",
      "Iteration 9865 => Loss: 15.419800\n",
      "Iteration 9866 => Loss: 15.419785\n",
      "Iteration 9867 => Loss: 15.419515\n",
      "Iteration 9868 => Loss: 15.419247\n",
      "Iteration 9869 => Loss: 15.418982\n",
      "Iteration 9870 => Loss: 15.418718\n",
      "Iteration 9871 => Loss: 15.418456\n",
      "Iteration 9872 => Loss: 15.418197\n",
      "Iteration 9873 => Loss: 15.417939\n",
      "Iteration 9874 => Loss: 15.417683\n",
      "Iteration 9875 => Loss: 15.417430\n",
      "Iteration 9876 => Loss: 15.417178\n",
      "Iteration 9877 => Loss: 15.416928\n",
      "Iteration 9878 => Loss: 15.416681\n",
      "Iteration 9879 => Loss: 15.416435\n",
      "Iteration 9880 => Loss: 15.416191\n",
      "Iteration 9881 => Loss: 15.415950\n",
      "Iteration 9882 => Loss: 15.415710\n",
      "Iteration 9883 => Loss: 15.415472\n",
      "Iteration 9884 => Loss: 15.415464\n",
      "Iteration 9885 => Loss: 15.415203\n",
      "Iteration 9886 => Loss: 15.414944\n",
      "Iteration 9887 => Loss: 15.414687\n",
      "Iteration 9888 => Loss: 15.414432\n",
      "Iteration 9889 => Loss: 15.414179\n",
      "Iteration 9890 => Loss: 15.413928\n",
      "Iteration 9891 => Loss: 15.413679\n",
      "Iteration 9892 => Loss: 15.413432\n",
      "Iteration 9893 => Loss: 15.413187\n",
      "Iteration 9894 => Loss: 15.412944\n",
      "Iteration 9895 => Loss: 15.412703\n",
      "Iteration 9896 => Loss: 15.412464\n",
      "Iteration 9897 => Loss: 15.412227\n",
      "Iteration 9898 => Loss: 15.411992\n",
      "Iteration 9899 => Loss: 15.411759\n",
      "Iteration 9900 => Loss: 15.411528\n",
      "Iteration 9901 => Loss: 15.411299\n",
      "Iteration 9902 => Loss: 15.411298\n",
      "Iteration 9903 => Loss: 15.411046\n",
      "Iteration 9904 => Loss: 15.410795\n",
      "Iteration 9905 => Loss: 15.410547\n",
      "Iteration 9906 => Loss: 15.410301\n",
      "Iteration 9907 => Loss: 15.410056\n",
      "Iteration 9908 => Loss: 15.409814\n",
      "Iteration 9909 => Loss: 15.409574\n",
      "Iteration 9910 => Loss: 15.409335\n",
      "Iteration 9911 => Loss: 15.409099\n",
      "Iteration 9912 => Loss: 15.408865\n",
      "Iteration 9913 => Loss: 15.408632\n",
      "Iteration 9914 => Loss: 15.408402\n",
      "Iteration 9915 => Loss: 15.408174\n",
      "Iteration 9916 => Loss: 15.407947\n",
      "Iteration 9917 => Loss: 15.407723\n",
      "Iteration 9918 => Loss: 15.407501\n",
      "Iteration 9919 => Loss: 15.407280\n",
      "Iteration 9920 => Loss: 15.407062\n",
      "Iteration 9921 => Loss: 15.407043\n",
      "Iteration 9922 => Loss: 15.406801\n",
      "Iteration 9923 => Loss: 15.406561\n",
      "Iteration 9924 => Loss: 15.406324\n",
      "Iteration 9925 => Loss: 15.406088\n",
      "Iteration 9926 => Loss: 15.405854\n",
      "Iteration 9927 => Loss: 15.405623\n",
      "Iteration 9928 => Loss: 15.405393\n",
      "Iteration 9929 => Loss: 15.405165\n",
      "Iteration 9930 => Loss: 15.404940\n",
      "Iteration 9931 => Loss: 15.404716\n",
      "Iteration 9932 => Loss: 15.404494\n",
      "Iteration 9933 => Loss: 15.404275\n",
      "Iteration 9934 => Loss: 15.404057\n",
      "Iteration 9935 => Loss: 15.403841\n",
      "Iteration 9936 => Loss: 15.403628\n",
      "Iteration 9937 => Loss: 15.403416\n",
      "Iteration 9938 => Loss: 15.403206\n",
      "Iteration 9939 => Loss: 15.403194\n",
      "Iteration 9940 => Loss: 15.402961\n",
      "Iteration 9941 => Loss: 15.402730\n",
      "Iteration 9942 => Loss: 15.402501\n",
      "Iteration 9943 => Loss: 15.402274\n",
      "Iteration 9944 => Loss: 15.402049\n",
      "Iteration 9945 => Loss: 15.401826\n",
      "Iteration 9946 => Loss: 15.401605\n",
      "Iteration 9947 => Loss: 15.401386\n",
      "Iteration 9948 => Loss: 15.401169\n",
      "Iteration 9949 => Loss: 15.400954\n",
      "Iteration 9950 => Loss: 15.400741\n",
      "Iteration 9951 => Loss: 15.400530\n",
      "Iteration 9952 => Loss: 15.400321\n",
      "Iteration 9953 => Loss: 15.400114\n",
      "Iteration 9954 => Loss: 15.399909\n",
      "Iteration 9955 => Loss: 15.399706\n",
      "Iteration 9956 => Loss: 15.399505\n",
      "Iteration 9957 => Loss: 15.399499\n",
      "Iteration 9958 => Loss: 15.399274\n",
      "Iteration 9959 => Loss: 15.399052\n",
      "Iteration 9960 => Loss: 15.398832\n",
      "Iteration 9961 => Loss: 15.398613\n",
      "Iteration 9962 => Loss: 15.398397\n",
      "Iteration 9963 => Loss: 15.398183\n",
      "Iteration 9964 => Loss: 15.397970\n",
      "Iteration 9965 => Loss: 15.397760\n",
      "Iteration 9966 => Loss: 15.397552\n",
      "Iteration 9967 => Loss: 15.397345\n",
      "Iteration 9968 => Loss: 15.397141\n",
      "Iteration 9969 => Loss: 15.396939\n",
      "Iteration 9970 => Loss: 15.396738\n",
      "Iteration 9971 => Loss: 15.396540\n",
      "Iteration 9972 => Loss: 15.396344\n",
      "Iteration 9973 => Loss: 15.396149\n",
      "Iteration 9974 => Loss: 15.395957\n",
      "Iteration 9975 => Loss: 15.395767\n",
      "Iteration 9976 => Loss: 15.395743\n",
      "Iteration 9977 => Loss: 15.395529\n",
      "Iteration 9978 => Loss: 15.395317\n",
      "Iteration 9979 => Loss: 15.395108\n",
      "Iteration 9980 => Loss: 15.394900\n",
      "Iteration 9981 => Loss: 15.394694\n",
      "Iteration 9982 => Loss: 15.394491\n",
      "Iteration 9983 => Loss: 15.394289\n",
      "Iteration 9984 => Loss: 15.394089\n",
      "Iteration 9985 => Loss: 15.393892\n",
      "Iteration 9986 => Loss: 15.393696\n",
      "Iteration 9987 => Loss: 15.393502\n",
      "Iteration 9988 => Loss: 15.393311\n",
      "Iteration 9989 => Loss: 15.393121\n",
      "Iteration 9990 => Loss: 15.392933\n",
      "Iteration 9991 => Loss: 15.392748\n",
      "Iteration 9992 => Loss: 15.392564\n",
      "Iteration 9993 => Loss: 15.392382\n",
      "Iteration 9994 => Loss: 15.392365\n",
      "Iteration 9995 => Loss: 15.392160\n",
      "Iteration 9996 => Loss: 15.391957\n",
      "Iteration 9997 => Loss: 15.391756\n",
      "Iteration 9998 => Loss: 15.391557\n",
      "Iteration 9999 => Loss: 15.391360\n",
      "Iteration 10000 => Loss: 15.391165\n",
      "Iteration 10001 => Loss: 15.390972\n",
      "Iteration 10002 => Loss: 15.390781\n",
      "Iteration 10003 => Loss: 15.390592\n",
      "Iteration 10004 => Loss: 15.390405\n",
      "Iteration 10005 => Loss: 15.390220\n",
      "Iteration 10006 => Loss: 15.390037\n",
      "Iteration 10007 => Loss: 15.389856\n",
      "Iteration 10008 => Loss: 15.389677\n",
      "Iteration 10009 => Loss: 15.389500\n",
      "Iteration 10010 => Loss: 15.389325\n",
      "Iteration 10011 => Loss: 15.389152\n",
      "Iteration 10012 => Loss: 15.389142\n",
      "Iteration 10013 => Loss: 15.388946\n",
      "Iteration 10014 => Loss: 15.388751\n",
      "Iteration 10015 => Loss: 15.388559\n",
      "Iteration 10016 => Loss: 15.388369\n",
      "Iteration 10017 => Loss: 15.388180\n",
      "Iteration 10018 => Loss: 15.387994\n",
      "Iteration 10019 => Loss: 15.387810\n",
      "Iteration 10020 => Loss: 15.387627\n",
      "Iteration 10021 => Loss: 15.387447\n",
      "Iteration 10022 => Loss: 15.387269\n",
      "Iteration 10023 => Loss: 15.387092\n",
      "Iteration 10024 => Loss: 15.386918\n",
      "Iteration 10025 => Loss: 15.386746\n",
      "Iteration 10026 => Loss: 15.386575\n",
      "Iteration 10027 => Loss: 15.386407\n",
      "Iteration 10028 => Loss: 15.386241\n",
      "Iteration 10029 => Loss: 15.386076\n",
      "Iteration 10030 => Loss: 15.386073\n",
      "Iteration 10031 => Loss: 15.385885\n",
      "Iteration 10032 => Loss: 15.385700\n",
      "Iteration 10033 => Loss: 15.385516\n",
      "Iteration 10034 => Loss: 15.385334\n",
      "Iteration 10035 => Loss: 15.385155\n",
      "Iteration 10036 => Loss: 15.384977\n",
      "Iteration 10037 => Loss: 15.384801\n",
      "Iteration 10038 => Loss: 15.384628\n",
      "Iteration 10039 => Loss: 15.384456\n",
      "Iteration 10040 => Loss: 15.384286\n",
      "Iteration 10041 => Loss: 15.384119\n",
      "Iteration 10042 => Loss: 15.383953\n",
      "Iteration 10043 => Loss: 15.383789\n",
      "Iteration 10044 => Loss: 15.383628\n",
      "Iteration 10045 => Loss: 15.383468\n",
      "Iteration 10046 => Loss: 15.383310\n",
      "Iteration 10047 => Loss: 15.383155\n",
      "Iteration 10048 => Loss: 15.383001\n",
      "Iteration 10049 => Loss: 15.382979\n",
      "Iteration 10050 => Loss: 15.382802\n",
      "Iteration 10051 => Loss: 15.382627\n",
      "Iteration 10052 => Loss: 15.382454\n",
      "Iteration 10053 => Loss: 15.382283\n",
      "Iteration 10054 => Loss: 15.382114\n",
      "Iteration 10055 => Loss: 15.381947\n",
      "Iteration 10056 => Loss: 15.381782\n",
      "Iteration 10057 => Loss: 15.381619\n",
      "Iteration 10058 => Loss: 15.381458\n",
      "Iteration 10059 => Loss: 15.381299\n",
      "Iteration 10060 => Loss: 15.381142\n",
      "Iteration 10061 => Loss: 15.380987\n",
      "Iteration 10062 => Loss: 15.380834\n",
      "Iteration 10063 => Loss: 15.380683\n",
      "Iteration 10064 => Loss: 15.380534\n",
      "Iteration 10065 => Loss: 15.380387\n",
      "Iteration 10066 => Loss: 15.380242\n",
      "Iteration 10067 => Loss: 15.380227\n",
      "Iteration 10068 => Loss: 15.380059\n",
      "Iteration 10069 => Loss: 15.379893\n",
      "Iteration 10070 => Loss: 15.379728\n",
      "Iteration 10071 => Loss: 15.379566\n",
      "Iteration 10072 => Loss: 15.379406\n",
      "Iteration 10073 => Loss: 15.379247\n",
      "Iteration 10074 => Loss: 15.379091\n",
      "Iteration 10075 => Loss: 15.378937\n",
      "Iteration 10076 => Loss: 15.378784\n",
      "Iteration 10077 => Loss: 15.378634\n",
      "Iteration 10078 => Loss: 15.378486\n",
      "Iteration 10079 => Loss: 15.378339\n",
      "Iteration 10080 => Loss: 15.378195\n",
      "Iteration 10081 => Loss: 15.378053\n",
      "Iteration 10082 => Loss: 15.377912\n",
      "Iteration 10083 => Loss: 15.377774\n",
      "Iteration 10084 => Loss: 15.377638\n",
      "Iteration 10085 => Loss: 15.377630\n",
      "Iteration 10086 => Loss: 15.377470\n",
      "Iteration 10087 => Loss: 15.377312\n",
      "Iteration 10088 => Loss: 15.377157\n",
      "Iteration 10089 => Loss: 15.377003\n",
      "Iteration 10090 => Loss: 15.376851\n",
      "Iteration 10091 => Loss: 15.376702\n",
      "Iteration 10092 => Loss: 15.376554\n",
      "Iteration 10093 => Loss: 15.376408\n",
      "Iteration 10094 => Loss: 15.376265\n",
      "Iteration 10095 => Loss: 15.376123\n",
      "Iteration 10096 => Loss: 15.375983\n",
      "Iteration 10097 => Loss: 15.375846\n",
      "Iteration 10098 => Loss: 15.375710\n",
      "Iteration 10099 => Loss: 15.375576\n",
      "Iteration 10100 => Loss: 15.375445\n",
      "Iteration 10101 => Loss: 15.375315\n",
      "Iteration 10102 => Loss: 15.375187\n",
      "Iteration 10103 => Loss: 15.375187\n",
      "Iteration 10104 => Loss: 15.375036\n",
      "Iteration 10105 => Loss: 15.374887\n",
      "Iteration 10106 => Loss: 15.374740\n",
      "Iteration 10107 => Loss: 15.374595\n",
      "Iteration 10108 => Loss: 15.374452\n",
      "Iteration 10109 => Loss: 15.374311\n",
      "Iteration 10110 => Loss: 15.374172\n",
      "Iteration 10111 => Loss: 15.374035\n",
      "Iteration 10112 => Loss: 15.373900\n",
      "Iteration 10113 => Loss: 15.373767\n",
      "Iteration 10114 => Loss: 15.373636\n",
      "Iteration 10115 => Loss: 15.373507\n",
      "Iteration 10116 => Loss: 15.373380\n",
      "Iteration 10117 => Loss: 15.373255\n",
      "Iteration 10118 => Loss: 15.373132\n",
      "Iteration 10119 => Loss: 15.373011\n",
      "Iteration 10120 => Loss: 15.372892\n",
      "Iteration 10121 => Loss: 15.372775\n",
      "Iteration 10122 => Loss: 15.372755\n",
      "Iteration 10123 => Loss: 15.372615\n",
      "Iteration 10124 => Loss: 15.372477\n",
      "Iteration 10125 => Loss: 15.372340\n",
      "Iteration 10126 => Loss: 15.372206\n",
      "Iteration 10127 => Loss: 15.372074\n",
      "Iteration 10128 => Loss: 15.371943\n",
      "Iteration 10129 => Loss: 15.371815\n",
      "Iteration 10130 => Loss: 15.371689\n",
      "Iteration 10131 => Loss: 15.371564\n",
      "Iteration 10132 => Loss: 15.371442\n",
      "Iteration 10133 => Loss: 15.371322\n",
      "Iteration 10134 => Loss: 15.371203\n",
      "Iteration 10135 => Loss: 15.371087\n",
      "Iteration 10136 => Loss: 15.370973\n",
      "Iteration 10137 => Loss: 15.370860\n",
      "Iteration 10138 => Loss: 15.370750\n",
      "Iteration 10139 => Loss: 15.370642\n",
      "Iteration 10140 => Loss: 15.370629\n",
      "Iteration 10141 => Loss: 15.370497\n",
      "Iteration 10142 => Loss: 15.370368\n",
      "Iteration 10143 => Loss: 15.370240\n",
      "Iteration 10144 => Loss: 15.370114\n",
      "Iteration 10145 => Loss: 15.369991\n",
      "Iteration 10146 => Loss: 15.369869\n",
      "Iteration 10147 => Loss: 15.369749\n",
      "Iteration 10148 => Loss: 15.369632\n",
      "Iteration 10149 => Loss: 15.369516\n",
      "Iteration 10150 => Loss: 15.369402\n",
      "Iteration 10151 => Loss: 15.369291\n",
      "Iteration 10152 => Loss: 15.369181\n",
      "Iteration 10153 => Loss: 15.369073\n",
      "Iteration 10154 => Loss: 15.368968\n",
      "Iteration 10155 => Loss: 15.368864\n",
      "Iteration 10156 => Loss: 15.368762\n",
      "Iteration 10157 => Loss: 15.368663\n",
      "Iteration 10158 => Loss: 15.368657\n",
      "Iteration 10159 => Loss: 15.368534\n",
      "Iteration 10160 => Loss: 15.368413\n",
      "Iteration 10161 => Loss: 15.368294\n",
      "Iteration 10162 => Loss: 15.368177\n",
      "Iteration 10163 => Loss: 15.368062\n",
      "Iteration 10164 => Loss: 15.367949\n",
      "Iteration 10165 => Loss: 15.367838\n",
      "Iteration 10166 => Loss: 15.367729\n",
      "Iteration 10167 => Loss: 15.367622\n",
      "Iteration 10168 => Loss: 15.367517\n",
      "Iteration 10169 => Loss: 15.367414\n",
      "Iteration 10170 => Loss: 15.367313\n",
      "Iteration 10171 => Loss: 15.367214\n",
      "Iteration 10172 => Loss: 15.367117\n",
      "Iteration 10173 => Loss: 15.367022\n",
      "Iteration 10174 => Loss: 15.366929\n",
      "Iteration 10175 => Loss: 15.366838\n",
      "Iteration 10176 => Loss: 15.366749\n",
      "Iteration 10177 => Loss: 15.366725\n",
      "Iteration 10178 => Loss: 15.366613\n",
      "Iteration 10179 => Loss: 15.366503\n",
      "Iteration 10180 => Loss: 15.366394\n",
      "Iteration 10181 => Loss: 15.366288\n",
      "Iteration 10182 => Loss: 15.366184\n",
      "Iteration 10183 => Loss: 15.366081\n",
      "Iteration 10184 => Loss: 15.365981\n",
      "Iteration 10185 => Loss: 15.365883\n",
      "Iteration 10186 => Loss: 15.365786\n",
      "Iteration 10187 => Loss: 15.365692\n",
      "Iteration 10188 => Loss: 15.365600\n",
      "Iteration 10189 => Loss: 15.365509\n",
      "Iteration 10190 => Loss: 15.365421\n",
      "Iteration 10191 => Loss: 15.365335\n",
      "Iteration 10192 => Loss: 15.365250\n",
      "Iteration 10193 => Loss: 15.365168\n",
      "Iteration 10194 => Loss: 15.365088\n",
      "Iteration 10195 => Loss: 15.365071\n",
      "Iteration 10196 => Loss: 15.364967\n",
      "Iteration 10197 => Loss: 15.364866\n",
      "Iteration 10198 => Loss: 15.364766\n",
      "Iteration 10199 => Loss: 15.364668\n",
      "Iteration 10200 => Loss: 15.364573\n",
      "Iteration 10201 => Loss: 15.364479\n",
      "Iteration 10202 => Loss: 15.364387\n",
      "Iteration 10203 => Loss: 15.364298\n",
      "Iteration 10204 => Loss: 15.364210\n",
      "Iteration 10205 => Loss: 15.364124\n",
      "Iteration 10206 => Loss: 15.364041\n",
      "Iteration 10207 => Loss: 15.363959\n",
      "Iteration 10208 => Loss: 15.363879\n",
      "Iteration 10209 => Loss: 15.363802\n",
      "Iteration 10210 => Loss: 15.363726\n",
      "Iteration 10211 => Loss: 15.363652\n",
      "Iteration 10212 => Loss: 15.363581\n",
      "Iteration 10213 => Loss: 15.363571\n",
      "Iteration 10214 => Loss: 15.363476\n",
      "Iteration 10215 => Loss: 15.363383\n",
      "Iteration 10216 => Loss: 15.363292\n",
      "Iteration 10217 => Loss: 15.363203\n",
      "Iteration 10218 => Loss: 15.363116\n",
      "Iteration 10219 => Loss: 15.363031\n",
      "Iteration 10220 => Loss: 15.362948\n",
      "Iteration 10221 => Loss: 15.362867\n",
      "Iteration 10222 => Loss: 15.362788\n",
      "Iteration 10223 => Loss: 15.362711\n",
      "Iteration 10224 => Loss: 15.362636\n",
      "Iteration 10225 => Loss: 15.362563\n",
      "Iteration 10226 => Loss: 15.362492\n",
      "Iteration 10227 => Loss: 15.362423\n",
      "Iteration 10228 => Loss: 15.362356\n",
      "Iteration 10229 => Loss: 15.362291\n",
      "Iteration 10230 => Loss: 15.362228\n",
      "Iteration 10231 => Loss: 15.362224\n",
      "Iteration 10232 => Loss: 15.362138\n",
      "Iteration 10233 => Loss: 15.362054\n",
      "Iteration 10234 => Loss: 15.361971\n",
      "Iteration 10235 => Loss: 15.361891\n",
      "Iteration 10236 => Loss: 15.361813\n",
      "Iteration 10237 => Loss: 15.361736\n",
      "Iteration 10238 => Loss: 15.361662\n",
      "Iteration 10239 => Loss: 15.361590\n",
      "Iteration 10240 => Loss: 15.361519\n",
      "Iteration 10241 => Loss: 15.361451\n",
      "Iteration 10242 => Loss: 15.361385\n",
      "Iteration 10243 => Loss: 15.361320\n",
      "Iteration 10244 => Loss: 15.361258\n",
      "Iteration 10245 => Loss: 15.361198\n",
      "Iteration 10246 => Loss: 15.361139\n",
      "Iteration 10247 => Loss: 15.361083\n",
      "Iteration 10248 => Loss: 15.361029\n",
      "Iteration 10249 => Loss: 15.360976\n",
      "Iteration 10250 => Loss: 15.360955\n",
      "Iteration 10251 => Loss: 15.360879\n",
      "Iteration 10252 => Loss: 15.360806\n",
      "Iteration 10253 => Loss: 15.360734\n",
      "Iteration 10254 => Loss: 15.360664\n",
      "Iteration 10255 => Loss: 15.360597\n",
      "Iteration 10256 => Loss: 15.360531\n",
      "Iteration 10257 => Loss: 15.360467\n",
      "Iteration 10258 => Loss: 15.360406\n",
      "Iteration 10259 => Loss: 15.360346\n",
      "Iteration 10260 => Loss: 15.360288\n",
      "Iteration 10261 => Loss: 15.360233\n",
      "Iteration 10262 => Loss: 15.360179\n",
      "Iteration 10263 => Loss: 15.360127\n",
      "Iteration 10264 => Loss: 15.360078\n",
      "Iteration 10265 => Loss: 15.360030\n",
      "Iteration 10266 => Loss: 15.359984\n",
      "Iteration 10267 => Loss: 15.359941\n",
      "Iteration 10268 => Loss: 15.359926\n",
      "Iteration 10269 => Loss: 15.359859\n",
      "Iteration 10270 => Loss: 15.359794\n",
      "Iteration 10271 => Loss: 15.359731\n",
      "Iteration 10272 => Loss: 15.359670\n",
      "Iteration 10273 => Loss: 15.359611\n",
      "Iteration 10274 => Loss: 15.359554\n",
      "Iteration 10275 => Loss: 15.359499\n",
      "Iteration 10276 => Loss: 15.359446\n",
      "Iteration 10277 => Loss: 15.359395\n",
      "Iteration 10278 => Loss: 15.359346\n",
      "Iteration 10279 => Loss: 15.359299\n",
      "Iteration 10280 => Loss: 15.359254\n",
      "Iteration 10281 => Loss: 15.359211\n",
      "Iteration 10282 => Loss: 15.359170\n",
      "Iteration 10283 => Loss: 15.359131\n",
      "Iteration 10284 => Loss: 15.359094\n",
      "Iteration 10285 => Loss: 15.359059\n",
      "Iteration 10286 => Loss: 15.359052\n",
      "Iteration 10287 => Loss: 15.358993\n",
      "Iteration 10288 => Loss: 15.358937\n",
      "Iteration 10289 => Loss: 15.358883\n",
      "Iteration 10290 => Loss: 15.358830\n",
      "Iteration 10291 => Loss: 15.358780\n",
      "Iteration 10292 => Loss: 15.358732\n",
      "Iteration 10293 => Loss: 15.358685\n",
      "Iteration 10294 => Loss: 15.358641\n",
      "Iteration 10295 => Loss: 15.358599\n",
      "Iteration 10296 => Loss: 15.358558\n",
      "Iteration 10297 => Loss: 15.358520\n",
      "Iteration 10298 => Loss: 15.358484\n",
      "Iteration 10299 => Loss: 15.358449\n",
      "Iteration 10300 => Loss: 15.358417\n",
      "Iteration 10301 => Loss: 15.358387\n",
      "Iteration 10302 => Loss: 15.358358\n",
      "Iteration 10303 => Loss: 15.358332\n",
      "Iteration 10304 => Loss: 15.358331\n",
      "Iteration 10305 => Loss: 15.358282\n",
      "Iteration 10306 => Loss: 15.358234\n",
      "Iteration 10307 => Loss: 15.358188\n",
      "Iteration 10308 => Loss: 15.358145\n",
      "Iteration 10309 => Loss: 15.358103\n",
      "Iteration 10310 => Loss: 15.358063\n",
      "Iteration 10311 => Loss: 15.358026\n",
      "Iteration 10312 => Loss: 15.357990\n",
      "Iteration 10313 => Loss: 15.357956\n",
      "Iteration 10314 => Loss: 15.357925\n",
      "Iteration 10315 => Loss: 15.357895\n",
      "Iteration 10316 => Loss: 15.357867\n",
      "Iteration 10317 => Loss: 15.357842\n",
      "Iteration 10318 => Loss: 15.357818\n",
      "Iteration 10319 => Loss: 15.357796\n",
      "Iteration 10320 => Loss: 15.357777\n",
      "Iteration 10321 => Loss: 15.357759\n",
      "Iteration 10322 => Loss: 15.357743\n",
      "Iteration 10323 => Loss: 15.357724\n",
      "Iteration 10324 => Loss: 15.357685\n",
      "Iteration 10325 => Loss: 15.357648\n",
      "Iteration 10326 => Loss: 15.357613\n",
      "Iteration 10327 => Loss: 15.357580\n",
      "Iteration 10328 => Loss: 15.357549\n",
      "Iteration 10329 => Loss: 15.357520\n",
      "Iteration 10330 => Loss: 15.357493\n",
      "Iteration 10331 => Loss: 15.357468\n",
      "Iteration 10332 => Loss: 15.357445\n",
      "Iteration 10333 => Loss: 15.357424\n",
      "Iteration 10334 => Loss: 15.357405\n",
      "Iteration 10335 => Loss: 15.357388\n",
      "Iteration 10336 => Loss: 15.357373\n",
      "Iteration 10337 => Loss: 15.357360\n",
      "Iteration 10338 => Loss: 15.357349\n",
      "Iteration 10339 => Loss: 15.357340\n",
      "Iteration 10340 => Loss: 15.357333\n",
      "Iteration 10341 => Loss: 15.357321\n",
      "Iteration 10342 => Loss: 15.357291\n",
      "Iteration 10343 => Loss: 15.357262\n",
      "Iteration 10344 => Loss: 15.357236\n",
      "Iteration 10345 => Loss: 15.357212\n",
      "Iteration 10346 => Loss: 15.357189\n",
      "Iteration 10347 => Loss: 15.357169\n",
      "Iteration 10348 => Loss: 15.357151\n",
      "Iteration 10349 => Loss: 15.357134\n",
      "Iteration 10350 => Loss: 15.357120\n",
      "Iteration 10351 => Loss: 15.357108\n",
      "Iteration 10352 => Loss: 15.357097\n",
      "Iteration 10353 => Loss: 15.357089\n",
      "Iteration 10354 => Loss: 15.357083\n",
      "Iteration 10355 => Loss: 15.357078\n",
      "Iteration 10356 => Loss: 15.357076\n",
      "Iteration 10357 => Loss: 15.357076\n"
     ]
    }
   ],
   "source": [
    "w, b = train(X, Y, 100000, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.779999999999915"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.687000000000902"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel(\"Temperature\", fontsize=20)\n",
    "plt.ylabel(\"AC Bill\", fontsize=20)\n",
    "plt.axis([0, 50, 0, 50])\n",
    "plt.plot(X, Y, \"bo\")\n",
    "\n",
    "\n",
    "plt.plot([0, 50], [b, predict(50, w, b)], color=\"g\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43.29\n"
     ]
    }
   ],
   "source": [
    "temperature = 20\n",
    "print(f\"{predict(temperature, w, b):.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([-20.  , -19.99, -19.98, ...,  19.97,  19.98,  19.99])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# MSE loss function\n",
    "def mse_loss(y_pred, y_true):\n",
    "    squared_error = (y_pred - y_true) ** 2\n",
    "    sum_squared_error = np.sum(squared_error)\n",
    "    loss = sum_squared_error / y_true.size\n",
    "    return loss\n",
    "    \n",
    "# Plotting\n",
    "\n",
    "x_vals = np.arange(-20, 20, 0.01)\n",
    "y_vals = np.square(x_vals)\n",
    "\n",
    "plt.plot(x_vals, y_vals, \"blue\")\n",
    "plt.grid(True, which=\"major\")\n",
    "plt.show()\n",
    "x_vals"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAE Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def mae_loss(y_pred, y_true):\n",
    "    abs_error = np.abs(y_pred - y_true)\n",
    "    sum_abs_error = np.sum(abs_error)\n",
    "    loss = sum_abs_error / y_true.size\n",
    "    return loss\n",
    "    \n",
    "# Plotting\n",
    "x_vals = np.arange(-100, 100, 0.01)\n",
    "y_vals = np.abs(x_vals)\n",
    "\n",
    "plt.plot(x_vals, y_vals, \"red\")\n",
    "plt.grid(True, which=\"major\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Huber Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Huber loss function\n",
    "def huber_loss(y_pred, y, delta=1.0):\n",
    "    huber_mse = 0.5*(y-y_pred)**2\n",
    "    huber_mae = delta * (np.abs(y - y_pred) - 0.5 * delta)\n",
    "    return np.where(np.abs(y - y_pred) <= delta, huber_mse, huber_mae)\n",
    "    \n",
    "# Plotting\n",
    "x_vals = np.arange(-65, 65, 0.01)\n",
    "\n",
    "delta = 1.5\n",
    "huber_mse = 0.5*np.square(x_vals)\n",
    "huber_mae = delta * (np.abs(x_vals) - 0.5 * delta)\n",
    "y_vals = np.where(np.abs(x_vals) <= delta, huber_mse, huber_mae)\n",
    "\n",
    "plt.plot(x_vals, y_vals, \"green\")\n",
    "plt.grid(True, which=\"major\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2112.5    , 2111.85005, 2111.2002 , ..., 2110.55045, 2111.2002 ,\n",
       "       2111.85005])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "huber_mse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([96.375, 96.36 , 96.345, ..., 96.33 , 96.345, 96.36 ])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "huber_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-65.  , -64.99, -64.98, ...,  64.97,  64.98,  64.99]),\n",
       " array([96.375, 96.36 , 96.345, ..., 96.33 , 96.345, 96.36 ]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_vals, y_vals"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#np.random.seed(42)\n",
    "\n",
    "N = 75\n",
    "x = np.random.randn(N, 2)\n",
    "w = np.array([1.5, -0.46])\n",
    "y = 1 / (1 + np.exp(-x.dot(w) + np.random.randn(N) * 0.1))\n",
    "\n",
    "# Define log loss function\n",
    "def log_loss(y_true, y_pred):\n",
    "    eps = 1e-15\n",
    "    y_pred = np.clip(y_pred, eps, 1-eps)\n",
    "    return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
    "\n",
    "\n",
    "y_pred = x.dot(w)\n",
    "ll = log_loss(y, y_pred)\n",
    "\n",
    "# Plot the data and the sigmoid curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_pred, y, s=50, alpha=0.5)\n",
    "plt.xlabel('Predicted value')\n",
    "plt.ylabel('True value')\n",
    "plt.title(f'Log loss: {ll:.3f}')\n",
    "\n",
    "x_plot = np.linspace(y_pred.min(), y_pred.max(), 100)\n",
    "y_plot = 1 / (1 + np.exp(-x_plot))  # use the logistic function\n",
    "plt.plot(x_plot, y_plot, color='r')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.495494  , -4.41556475, -4.3356355 , -4.25570625, -4.175777  ,\n",
       "       -4.09584775, -4.0159185 , -3.93598925, -3.85606   , -3.77613075,\n",
       "       -3.69620149, -3.61627224, -3.53634299, -3.45641374, -3.37648449,\n",
       "       -3.29655524, -3.21662599, -3.13669674, -3.05676749, -2.97683824,\n",
       "       -2.89690899, -2.81697974, -2.73705049, -2.65712124, -2.57719198,\n",
       "       -2.49726273, -2.41733348, -2.33740423, -2.25747498, -2.17754573,\n",
       "       -2.09761648, -2.01768723, -1.93775798, -1.85782873, -1.77789948,\n",
       "       -1.69797023, -1.61804098, -1.53811173, -1.45818247, -1.37825322,\n",
       "       -1.29832397, -1.21839472, -1.13846547, -1.05853622, -0.97860697,\n",
       "       -0.89867772, -0.81874847, -0.73881922, -0.65888997, -0.57896072,\n",
       "       -0.49903147, -0.41910222, -0.33917296, -0.25924371, -0.17931446,\n",
       "       -0.09938521, -0.01945596,  0.06047329,  0.14040254,  0.22033179,\n",
       "        0.30026104,  0.38019029,  0.46011954,  0.54004879,  0.61997804,\n",
       "        0.69990729,  0.77983655,  0.8597658 ,  0.93969505,  1.0196243 ,\n",
       "        1.09955355,  1.1794828 ,  1.25941205,  1.3393413 ,  1.41927055,\n",
       "        1.4991998 ,  1.57912905,  1.6590583 ,  1.73898755,  1.8189168 ,\n",
       "        1.89884606,  1.97877531,  2.05870456,  2.13863381,  2.21856306,\n",
       "        2.29849231,  2.37842156,  2.45835081,  2.53828006,  2.61820931,\n",
       "        2.69813856,  2.77806781,  2.85799706,  2.93792631,  3.01785557,\n",
       "        3.09778482,  3.17771407,  3.25764332,  3.33757257,  3.41750182])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01103601, 0.01194336, 0.01292433, 0.01398472, 0.01513079,\n",
       "       0.01636922, 0.01770719, 0.0191524 , 0.02071307, 0.022398  ,\n",
       "       0.02421662, 0.02617894, 0.02829566, 0.03057816, 0.03303852,\n",
       "       0.03568955, 0.03854483, 0.04161868, 0.0449262 , 0.04848328,\n",
       "       0.05230657, 0.05641349, 0.06082217, 0.06555145, 0.07062081,\n",
       "       0.0760503 , 0.08186045, 0.08807217, 0.09470664, 0.10178509,\n",
       "       0.1093287 , 0.11735835, 0.12589437, 0.13495633, 0.1445627 ,\n",
       "       0.15473055, 0.16547522, 0.17680994, 0.18874547, 0.20128969,\n",
       "       0.21444722, 0.22821907, 0.24260221, 0.25758928, 0.27316828,\n",
       "       0.2893223 , 0.30602939, 0.3232624 , 0.34098901, 0.35917177,\n",
       "       0.3777683 , 0.3967316 , 0.41601039, 0.43554963, 0.45529112,\n",
       "       0.47517413, 0.49513616, 0.51511372, 0.53504309, 0.55486119,\n",
       "       0.57450633, 0.593919  , 0.61304253, 0.63182377, 0.65021355,\n",
       "       0.66816722, 0.68564488, 0.70261172, 0.71903805, 0.73489941,\n",
       "       0.75017644, 0.7648548 , 0.77892488, 0.7923816 , 0.80522404,\n",
       "       0.8174551 , 0.82908114, 0.84011155, 0.85055842, 0.8604361 ,\n",
       "       0.86976087, 0.87855055, 0.88682422, 0.89460186, 0.90190414,\n",
       "       0.9087521 , 0.91516697, 0.92116999, 0.9267822 , 0.93202435,\n",
       "       0.93691672, 0.94147908, 0.94573059, 0.94968974, 0.95337429,\n",
       "       0.95680128, 0.95998695, 0.9629468 , 0.96569552, 0.96824706])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_plot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
